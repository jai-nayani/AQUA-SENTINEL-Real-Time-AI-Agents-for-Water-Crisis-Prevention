{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":121144,"databundleVersionId":14484960,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ðŸŒŠ AQUA SENTINEL: Real-Time AI Agents for Water Crisis Prevention\n\n**Kaggle AI Agents Capstone** | **Track: Agents for Good**\n\n---\n\n## âš¡ THIS PROJECT USES LIVE DATA\n\nUnlike simulated demos, AQUA SENTINEL connects to **real APIs** that return **real-time data**:\n\n| Data Source | API | Updates |\n|-------------|-----|--------|\n| ðŸŒ¦ï¸ Weather & Forecasts | Open-Meteo | Every 15 min |\n| ðŸ’§ US Water Levels | USGS Water Services | Real-time |\n| ðŸ›°ï¸ Natural Disasters | NASA EONET | Daily |\n| ðŸŒ Country Data | REST Countries | Static |\n\n**Run this notebook anytime and you'll get CURRENT conditions.**\n\n---\n\n## ðŸ’§ The Story Behind This Project\n\n### The Spark: #TeamWater\n\nIn 2023, I discovered MrBeast and Mark Rober's [#TeamWater campaign](https://teamwater.org) â€” a massive fundraiser that raised over $20 million to bring clean drinking water to millions. Watching their videos, I learned about the **Horn of Africa drought**, where **20 million people** faced acute hunger. Children walked 8 hours to find water. Crops failed. Livestock died.\n\nWhat struck me wasn't just the tragedy; it was that **we saw it coming months in advance**. Satellite data showed the drought forming. Weather models predicted it. Sensors detected dropping groundwater. Yet the response came too late.\n\n### Why This Matters to Me\n\nI'm Jai Adithya Ram Nayani, a 22-year-old international student pursuing my Master's in Computer Science. Coming from a middle-class background and working hard to make ends meet abroad, I donated what I could to #TeamWaterâ€”but I never felt the direct impact I was making.\n\nAs someone with a strong grip on AI developments and a passion for learning and deploying cutting-edge technology, I kept asking: *\"What if I could contribute more than just money? What if I could build something?\"*\n\nWhen this Agents Capstone came along, I saw my chance. **AQUA SENTINEL is my attempt to do what MrBeast doesâ€”but with AI agents instead of fundraising videos.**\n\n### The Core Problem\n\n> **The problem isn't data â€” it's coordination.**\n\nInformation exists in silos. By the time humans synthesize satellite imagery, sensor readings, weather forecasts, and social reports, the crisis has already hit. The 2023 Horn of Africa drought proved this:\n\n- **UNICEF**: Reported 5 consecutive failed rainy seasons ([source](https://www.unicef.org/stories/climate-drought-horn-of-africa))\n- **CNN**: Documented the climate change connection ([source](https://www.cnn.com/2023/04/27/africa/drought-horn-of-africa-climate-change-intl))\n- **CDP**: Tracked the humanitarian response gap ([source](https://disasterphilanthropy.org/disasters/horn-of-africa-hunger-crisis/))\n\nAll this data existed. The tragedy wasn't lack of informationâ€”it was lack of **intelligent coordination**.\n\n**This is exactly what AI agents are built for.**\n\n---\n\n## ðŸŽ¯ Features Demonstrated\n\n### ADK Concepts Coverage:\n| Concept | Implementation | Status |\n|---------|---------------|--------|\n| LlmAgent | HydroOrchestrator + 6 specialists | âœ… |\n| ParallelAgent | SentinelAgent (3 concurrent) | âœ… |\n| SequentialAgent | GuardianAgent (state passing) | âœ… |\n| LoopAgent | ResponderAgent (5 iterations) | âœ… |\n| Custom Tools | 5 real-time APIs | âœ… |\n| Sessions | InMemorySessionService | âœ… |\n| Observability | Logging, Tracing, Metrics | âœ… |\n| Evaluation | 12 test cases, multi-dimensional | âœ… |\n| MCP Pattern | Tool server architecture | âœ… |\n| Long-Running Ops | Async with status tracking | âœ… |\n| A2A Protocol | Agent-to-Agent messaging | âœ… |\n\n### Additional Features:\n- **Timing Comparison**: Sequential vs Parallel execution benchmarks\n- **Advanced Concepts**: MCP Integration Pattern, Long-Running Operations, A2A Protocol\n- **12 Evaluation Test Cases** across 4 categories (happy_path, error_handling, multi_agent, edge_case)","metadata":{}},{"cell_type":"markdown","source":"---\n\n# Â§1. Setup & Installation","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# CELL 1: INSTALLATION & WARNINGS\n# ============================================================================\n# Uncomment for local setup:\n# !pip install -q google-genai google-adk requests\n\nimport warnings\nimport logging\n\nwarnings.filterwarnings('ignore')\nlogging.getLogger('google_genai.types').setLevel(logging.ERROR)\nlogging.getLogger('asyncio').setLevel(logging.ERROR)\n\nprint(\"Warnings suppressed for cleaner output\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T18:09:22.011721Z","iopub.execute_input":"2025-12-03T18:09:22.012047Z","iopub.status.idle":"2025-12-03T18:09:22.020301Z","shell.execute_reply.started":"2025-12-03T18:09:22.012016Z","shell.execute_reply":"2025-12-03T18:09:22.019119Z"}},"outputs":[{"name":"stdout","text":"Warnings suppressed for cleaner output\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ============================================================================\n# CELL 2: IMPORTS\n# ============================================================================\n\nimport os\nimport json\nimport asyncio\nimport requests\nimport time\nimport uuid\nfrom datetime import datetime, timedelta\nfrom typing import Optional, List, Dict, Any, Callable\nfrom dataclasses import dataclass, field\nfrom functools import wraps\nfrom enum import Enum\nfrom concurrent.futures import ThreadPoolExecutor\nimport threading\n\n# Google ADK - Agent framework\nfrom google.adk.agents import (\n    LlmAgent,\n    ParallelAgent,\n    SequentialAgent,\n    LoopAgent,\n)\nfrom google.adk.runners import Runner\nfrom google.adk.sessions import InMemorySessionService\n\n# Google GenAI\nfrom google import genai\nfrom google.genai import types\n\nprint(\"All imports successful\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T18:09:22.025190Z","iopub.execute_input":"2025-12-03T18:09:22.025584Z","iopub.status.idle":"2025-12-03T18:09:22.048544Z","shell.execute_reply.started":"2025-12-03T18:09:22.025547Z","shell.execute_reply":"2025-12-03T18:09:22.047099Z"}},"outputs":[{"name":"stdout","text":"All imports successful\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"---\n\n# Â§2. Observability Framework\n\nAQUA SENTINEL implements a comprehensive observability system that provides:\n- **Structured Logging**: With severity levels (INFO, WARN, ERROR, DEBUG)\n- **Distributed Tracing**: With trace IDs and spans for request tracking\n- **Metrics Collection**: For performance monitoring and analysis","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# CELL 3: OBSERVABILITY FRAMEWORK - Logging, Tracing, Metrics\n# ============================================================================\n\nclass AquaSentinelObservability:\n    \"\"\"\n    Comprehensive observability system for AQUA SENTINEL.\n    Implements: Logging, Tracing, and Metrics collection.\n    \n    This addresses the ADK Observability requirement by providing:\n    - Structured logging with severity levels\n    - Distributed tracing with trace IDs and spans\n    - Metrics collection for performance monitoring\n    \"\"\"\n    \n    def __init__(self):\n        self.logs: List[Dict] = []\n        self.traces: List[Dict] = []\n        self.metrics: Dict[str, Any] = {\n            \"api_latency\": [],\n            \"agent_execution_time\": [],\n            \"tool_calls\": [],\n            \"error_count\": 0,\n            \"success_count\": 0,\n            \"parallel_vs_sequential\": [],  # NEW: Timing comparisons\n        }\n        self.current_trace_id: Optional[str] = None\n        self.span_stack: List[Dict] = []\n    \n    def _generate_trace_id(self) -> str:\n        \"\"\"Generate unique trace ID for distributed tracing.\"\"\"\n        return f\"trace-{datetime.utcnow().strftime('%Y%m%d%H%M%S%f')}\"\n    \n    def _generate_span_id(self) -> str:\n        \"\"\"Generate unique span ID.\"\"\"\n        return f\"span-{datetime.utcnow().strftime('%H%M%S%f')}\"\n    \n    def start_trace(self, operation: str) -> str:\n        \"\"\"Start a new trace for an operation.\"\"\"\n        self.current_trace_id = self._generate_trace_id()\n        trace = {\n            \"trace_id\": self.current_trace_id,\n            \"operation\": operation,\n            \"start_time\": datetime.utcnow().isoformat(),\n            \"spans\": [],\n        }\n        self.traces.append(trace)\n        self.log(\"INFO\", f\"Started trace for: {operation}\", {\"trace_id\": self.current_trace_id})\n        return self.current_trace_id\n    \n    def start_span(self, name: str, attributes: Dict = None) -> str:\n        \"\"\"Start a new span within the current trace.\"\"\"\n        span_id = self._generate_span_id()\n        span = {\n            \"span_id\": span_id,\n            \"name\": name,\n            \"start_time\": time.time(),\n            \"start_timestamp\": datetime.utcnow().isoformat(),\n            \"attributes\": attributes or {},\n            \"parent_span\": self.span_stack[-1][\"span_id\"] if self.span_stack else None,\n        }\n        self.span_stack.append(span)\n        return span_id\n    \n    def end_span(self, status: str = \"OK\", attributes: Dict = None):\n        \"\"\"End the current span and record duration.\"\"\"\n        if not self.span_stack:\n            return\n        \n        span = self.span_stack.pop()\n        span[\"end_time\"] = time.time()\n        span[\"duration_ms\"] = round((span[\"end_time\"] - span[\"start_time\"]) * 1000, 2)\n        span[\"status\"] = status\n        if attributes:\n            span[\"attributes\"].update(attributes)\n        \n        if self.traces:\n            self.traces[-1][\"spans\"].append(span)\n        \n        self.metrics[\"agent_execution_time\"].append({\n            \"span\": span[\"name\"],\n            \"duration_ms\": span[\"duration_ms\"],\n            \"timestamp\": datetime.utcnow().isoformat(),\n        })\n    \n    def log(self, level: str, message: str, context: Dict = None):\n        \"\"\"Structured logging with context.\"\"\"\n        log_entry = {\n            \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n            \"level\": level,\n            \"message\": message,\n            \"trace_id\": self.current_trace_id,\n            \"context\": context or {},\n        }\n        self.logs.append(log_entry)\n        print(f\"[{log_entry['timestamp'][:19]}] {level}: {message}\")\n    \n    def record_api_call(self, api_name: str, latency_ms: float, success: bool):\n        \"\"\"Record API call metrics.\"\"\"\n        self.metrics[\"api_latency\"].append({\n            \"api\": api_name,\n            \"latency_ms\": latency_ms,\n            \"success\": success,\n            \"timestamp\": datetime.utcnow().isoformat(),\n        })\n        self.metrics[\"tool_calls\"].append(api_name)\n        if success:\n            self.metrics[\"success_count\"] += 1\n        else:\n            self.metrics[\"error_count\"] += 1\n    \n    def record_timing_comparison(self, operation: str, sequential_ms: float, parallel_ms: float):\n        \"\"\"Record parallel vs sequential timing comparison.\"\"\"\n        speedup = sequential_ms / parallel_ms if parallel_ms > 0 else 0\n        self.metrics[\"parallel_vs_sequential\"].append({\n            \"operation\": operation,\n            \"sequential_ms\": round(sequential_ms, 2),\n            \"parallel_ms\": round(parallel_ms, 2),\n            \"speedup\": round(speedup, 2),\n            \"timestamp\": datetime.utcnow().isoformat(),\n        })\n        self.log(\"INFO\", f\"Timing comparison: {operation}\", {\n            \"sequential_ms\": round(sequential_ms, 2),\n            \"parallel_ms\": round(parallel_ms, 2),\n            \"speedup\": f\"{speedup:.2f}x\"\n        })\n    \n    def get_metrics_summary(self) -> Dict:\n        \"\"\"Get summary of collected metrics.\"\"\"\n        api_latencies = self.metrics[\"api_latency\"]\n        avg_latency = sum(m[\"latency_ms\"] for m in api_latencies) / len(api_latencies) if api_latencies else 0\n        \n        return {\n            \"total_api_calls\": len(api_latencies),\n            \"average_latency_ms\": round(avg_latency, 2),\n            \"success_rate\": f\"{(self.metrics['success_count'] / max(1, len(api_latencies))) * 100:.1f}%\",\n            \"error_count\": self.metrics[\"error_count\"],\n            \"unique_tools_used\": list(set(self.metrics[\"tool_calls\"])),\n            \"traces_collected\": len(self.traces),\n            \"timing_comparisons\": len(self.metrics[\"parallel_vs_sequential\"]),\n        }\n    \n    def get_trace_summary(self) -> Dict:\n        \"\"\"Get summary of the most recent trace.\"\"\"\n        if not self.traces:\n            return {\"status\": \"no traces\"}\n        \n        trace = self.traces[-1]\n        total_duration = sum(s.get(\"duration_ms\", 0) for s in trace[\"spans\"])\n        \n        return {\n            \"trace_id\": trace[\"trace_id\"],\n            \"operation\": trace[\"operation\"],\n            \"total_spans\": len(trace[\"spans\"]),\n            \"total_duration_ms\": round(total_duration, 2),\n            \"spans\": [{\"name\": s[\"name\"], \"duration_ms\": s.get(\"duration_ms\", 0)} for s in trace[\"spans\"]],\n        }\n    \n    def get_timing_comparison_summary(self) -> List[Dict]:\n        \"\"\"Get all timing comparisons.\"\"\"\n        return self.metrics[\"parallel_vs_sequential\"]\n\n\n# Initialize global observability instance\nobservability = AquaSentinelObservability()\n\nprint(\" Observability Framework initialized\")\nprint(\"   â€¢ Structured logging with trace context\")\nprint(\"   â€¢ Distributed tracing with spans\")\nprint(\"   â€¢ Metrics collection for API calls and agent execution\")\nprint(\"   â€¢ Timing comparison tracking (parallel vs sequential)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T18:09:22.053357Z","iopub.execute_input":"2025-12-03T18:09:22.053676Z","iopub.status.idle":"2025-12-03T18:09:22.087108Z","shell.execute_reply.started":"2025-12-03T18:09:22.053652Z","shell.execute_reply":"2025-12-03T18:09:22.086049Z"}},"outputs":[{"name":"stdout","text":" Observability Framework initialized\n   â€¢ Structured logging with trace context\n   â€¢ Distributed tracing with spans\n   â€¢ Metrics collection for API calls and agent execution\n   â€¢ Timing comparison tracking (parallel vs sequential)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"---\n\n# Â§3. Advanced ADK Concepts\n\nThis section demonstrates advanced patterns from the ADK ecosystem:\n\n### Model Context Protocol (MCP)\nA standardized way for AI agents to interact with external tools and data sources.\n\n### Long-Running Operations\nAsync processing with status tracking for operations that may take extended time.\n\n### Agent-to-Agent (A2A) Protocol\nEnables structured communication between agents including message passing, task handoffs, and broadcasts.","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# CELL 4: ADVANCED ADK CONCEPTS - MCP, Long-Running Ops, A2A Protocol\n# ============================================================================\n\n# -----------------------------------------------------------------------------\n# MODEL CONTEXT PROTOCOL (MCP) - Tool Server Architecture\n# -----------------------------------------------------------------------------\n\nclass MCPToolServer:\n    \"\"\"\n    Model Context Protocol (MCP) Tool Server Implementation.\n    \n    MCP provides a standardized way for AI agents to interact with external tools\n    and data sources. This implementation demonstrates:\n    - Tool registration and discovery\n    - Standardized request/response format\n    - Tool capability advertisement\n    \n    Reference: https://modelcontextprotocol.io/\n    \"\"\"\n    \n    def __init__(self, server_name: str):\n        self.server_name = server_name\n        self.tools: Dict[str, Dict] = {}\n        self.capabilities = {\n            \"tools\": True,\n            \"resources\": True,\n            \"prompts\": False,\n        }\n    \n    def register_tool(self, name: str, description: str, handler: Callable, parameters: Dict):\n        \"\"\"Register a tool with the MCP server.\"\"\"\n        self.tools[name] = {\n            \"name\": name,\n            \"description\": description,\n            \"handler\": handler,\n            \"parameters\": parameters,\n            \"registered_at\": datetime.utcnow().isoformat(),\n        }\n        observability.log(\"INFO\", f\"MCP: Registered tool '{name}'\")\n    \n    def list_tools(self) -> List[Dict]:\n        \"\"\"List all available tools (MCP tools/list).\"\"\"\n        return [\n            {\n                \"name\": t[\"name\"],\n                \"description\": t[\"description\"],\n                \"inputSchema\": t[\"parameters\"],\n            }\n            for t in self.tools.values()\n        ]\n    \n    def call_tool(self, name: str, arguments: Dict) -> Dict:\n        \"\"\"Execute a tool (MCP tools/call).\"\"\"\n        if name not in self.tools:\n            return {\"error\": f\"Tool '{name}' not found\"}\n        \n        tool = self.tools[name]\n        try:\n            result = tool[\"handler\"](**arguments)\n            return {\n                \"content\": [{\"type\": \"text\", \"text\": json.dumps(result)}],\n                \"isError\": False,\n            }\n        except Exception as e:\n            return {\n                \"content\": [{\"type\": \"text\", \"text\": str(e)}],\n                \"isError\": True,\n            }\n    \n    def get_server_info(self) -> Dict:\n        \"\"\"Get MCP server information.\"\"\"\n        return {\n            \"name\": self.server_name,\n            \"version\": \"1.0.0\",\n            \"capabilities\": self.capabilities,\n            \"tools_count\": len(self.tools),\n        }\n\n\n# Initialize MCP Tool Server\nmcp_server = MCPToolServer(\"aqua-sentinel-mcp\")\n\n\n# -----------------------------------------------------------------------------\n# LONG-RUNNING OPERATIONS - Async Processing with Status Tracking\n# -----------------------------------------------------------------------------\n\nclass OperationStatus(Enum):\n    \"\"\"Status states for long-running operations.\"\"\"\n    PENDING = \"pending\"\n    RUNNING = \"running\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n    PAUSED = \"paused\"\n    CANCELLED = \"cancelled\"\n\n\nclass LongRunningOperation:\n    \"\"\"\n    Long-Running Operation Manager.\n    \n    Demonstrates ADK pattern for operations that may take extended time:\n    - Operation creation with unique ID\n    - Status polling and updates\n    - Pause/Resume capability\n    - Progress tracking\n    \"\"\"\n    \n    def __init__(self):\n        self.operations: Dict[str, Dict] = {}\n    \n    def create_operation(self, operation_type: str, params: Dict) -> str:\n        \"\"\"Create a new long-running operation.\"\"\"\n        op_id = f\"op-{uuid.uuid4().hex[:8]}\"\n        self.operations[op_id] = {\n            \"id\": op_id,\n            \"type\": operation_type,\n            \"params\": params,\n            \"status\": OperationStatus.PENDING.value,\n            \"progress\": 0,\n            \"created_at\": datetime.utcnow().isoformat(),\n            \"updated_at\": datetime.utcnow().isoformat(),\n            \"result\": None,\n            \"error\": None,\n        }\n        observability.log(\"INFO\", f\"LRO: Created operation {op_id} ({operation_type})\")\n        return op_id\n    \n    def get_status(self, op_id: str) -> Dict:\n        \"\"\"Get operation status.\"\"\"\n        if op_id not in self.operations:\n            return {\"error\": \"Operation not found\"}\n        return self.operations[op_id]\n    \n    def update_progress(self, op_id: str, progress: int, status: OperationStatus = None):\n        \"\"\"Update operation progress.\"\"\"\n        if op_id in self.operations:\n            self.operations[op_id][\"progress\"] = progress\n            self.operations[op_id][\"updated_at\"] = datetime.utcnow().isoformat()\n            if status:\n                self.operations[op_id][\"status\"] = status.value\n    \n    def complete_operation(self, op_id: str, result: Any):\n        \"\"\"Mark operation as completed.\"\"\"\n        if op_id in self.operations:\n            self.operations[op_id][\"status\"] = OperationStatus.COMPLETED.value\n            self.operations[op_id][\"progress\"] = 100\n            self.operations[op_id][\"result\"] = result\n            self.operations[op_id][\"updated_at\"] = datetime.utcnow().isoformat()\n            observability.log(\"INFO\", f\"LRO: Completed operation {op_id}\")\n    \n    def pause_operation(self, op_id: str) -> bool:\n        \"\"\"Pause a running operation.\"\"\"\n        if op_id in self.operations and self.operations[op_id][\"status\"] == OperationStatus.RUNNING.value:\n            self.operations[op_id][\"status\"] = OperationStatus.PAUSED.value\n            observability.log(\"INFO\", f\"LRO: Paused operation {op_id}\")\n            return True\n        return False\n    \n    def resume_operation(self, op_id: str) -> bool:\n        \"\"\"Resume a paused operation.\"\"\"\n        if op_id in self.operations and self.operations[op_id][\"status\"] == OperationStatus.PAUSED.value:\n            self.operations[op_id][\"status\"] = OperationStatus.RUNNING.value\n            observability.log(\"INFO\", f\"LRO: Resumed operation {op_id}\")\n            return True\n        return False\n\n\n# Initialize Long-Running Operations Manager\nlro_manager = LongRunningOperation()\n\n\n# -----------------------------------------------------------------------------\n# AGENT-TO-AGENT (A2A) PROTOCOL - Inter-Agent Communication\n# -----------------------------------------------------------------------------\n\nclass A2AMessage:\n    \"\"\"Agent-to-Agent message format.\"\"\"\n    def __init__(self, sender: str, recipient: str, message_type: str, payload: Dict):\n        self.id = f\"msg-{uuid.uuid4().hex[:8]}\"\n        self.sender = sender\n        self.recipient = recipient\n        self.message_type = message_type  # request, response, broadcast, handoff\n        self.payload = payload\n        self.timestamp = datetime.utcnow().isoformat()\n        self.status = \"pending\"\n\n\nclass A2AProtocol:\n    \"\"\"\n    Agent-to-Agent (A2A) Protocol Implementation.\n    \n    Enables structured communication between agents:\n    - Message passing with typed payloads\n    - Request/Response patterns\n    - Task handoff between agents\n    - Broadcast messaging\n    \n    Reference: Google ADK A2A Protocol specification\n    \"\"\"\n    \n    def __init__(self):\n        self.agents: Dict[str, Dict] = {}\n        self.message_queue: List[A2AMessage] = []\n        self.message_history: List[Dict] = []\n    \n    def register_agent(self, agent_id: str, capabilities: List[str], endpoint: str = None):\n        \"\"\"Register an agent with the A2A network.\"\"\"\n        self.agents[agent_id] = {\n            \"id\": agent_id,\n            \"capabilities\": capabilities,\n            \"endpoint\": endpoint,\n            \"registered_at\": datetime.utcnow().isoformat(),\n            \"status\": \"active\",\n        }\n        observability.log(\"INFO\", f\"A2A: Registered agent '{agent_id}' with capabilities: {capabilities}\")\n    \n    def send_message(self, sender: str, recipient: str, message_type: str, payload: Dict) -> A2AMessage:\n        \"\"\"Send a message from one agent to another.\"\"\"\n        msg = A2AMessage(sender, recipient, message_type, payload)\n        self.message_queue.append(msg)\n        self.message_history.append({\n            \"id\": msg.id,\n            \"sender\": sender,\n            \"recipient\": recipient,\n            \"type\": message_type,\n            \"timestamp\": msg.timestamp,\n        })\n        observability.log(\"DEBUG\", f\"A2A: Message {msg.id} from {sender} to {recipient}\")\n        return msg\n    \n    def handoff_task(self, from_agent: str, to_agent: str, task: Dict, context: Dict) -> A2AMessage:\n        \"\"\"Handoff a task from one agent to another.\"\"\"\n        payload = {\n            \"task\": task,\n            \"context\": context,\n            \"handoff_reason\": task.get(\"reason\", \"capability match\"),\n        }\n        msg = self.send_message(from_agent, to_agent, \"handoff\", payload)\n        observability.log(\"INFO\", f\"A2A: Task handoff from {from_agent} to {to_agent}\")\n        return msg\n    \n    def broadcast(self, sender: str, payload: Dict) -> List[A2AMessage]:\n        \"\"\"Broadcast a message to all registered agents.\"\"\"\n        messages = []\n        for agent_id in self.agents:\n            if agent_id != sender:\n                msg = self.send_message(sender, agent_id, \"broadcast\", payload)\n                messages.append(msg)\n        observability.log(\"INFO\", f\"A2A: Broadcast from {sender} to {len(messages)} agents\")\n        return messages\n    \n    def get_agent_by_capability(self, capability: str) -> Optional[str]:\n        \"\"\"Find an agent with a specific capability.\"\"\"\n        for agent_id, agent_info in self.agents.items():\n            if capability in agent_info[\"capabilities\"]:\n                return agent_id\n        return None\n    \n    def get_communication_summary(self) -> Dict:\n        \"\"\"Get summary of A2A communications.\"\"\"\n        return {\n            \"registered_agents\": len(self.agents),\n            \"total_messages\": len(self.message_history),\n            \"message_types\": list(set(m[\"type\"] for m in self.message_history)),\n            \"agents\": list(self.agents.keys()),\n        }\n\n\n# Initialize A2A Protocol\na2a_protocol = A2AProtocol()\n\n# Register AQUA SENTINEL agents with A2A\na2a_protocol.register_agent(\"HydroOrchestrator\", [\"orchestration\", \"routing\", \"coordination\"])\na2a_protocol.register_agent(\"WeatherAgent\", [\"weather\", \"forecast\", \"precipitation\"])\na2a_protocol.register_agent(\"WaterLevelAgent\", [\"water_level\", \"usgs\", \"rivers\"])\na2a_protocol.register_agent(\"DisasterAgent\", [\"disasters\", \"nasa\", \"events\"])\na2a_protocol.register_agent(\"AlertAgent\", [\"alerts\", \"notifications\", \"emergency\"])\na2a_protocol.register_agent(\"AnalysisAgent\", [\"analysis\", \"recommendations\", \"synthesis\"])\n\nprint(\"\\n Advanced ADK Concepts initialized:\")\nprint(\"   â€¢ MCP Tool Server (Model Context Protocol)\")\nprint(\"   â€¢ Long-Running Operations Manager\")\nprint(\"   â€¢ A2A Protocol (Agent-to-Agent Communication)\")\nprint(f\"   â€¢ {len(a2a_protocol.agents)} agents registered in A2A network\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T18:10:00.282875Z","iopub.execute_input":"2025-12-03T18:10:00.283203Z","iopub.status.idle":"2025-12-03T18:10:00.316821Z","shell.execute_reply.started":"2025-12-03T18:10:00.283179Z","shell.execute_reply":"2025-12-03T18:10:00.315484Z"}},"outputs":[{"name":"stdout","text":"[2025-12-03T18:10:00] INFO: A2A: Registered agent 'HydroOrchestrator' with capabilities: ['orchestration', 'routing', 'coordination']\n[2025-12-03T18:10:00] INFO: A2A: Registered agent 'WeatherAgent' with capabilities: ['weather', 'forecast', 'precipitation']\n[2025-12-03T18:10:00] INFO: A2A: Registered agent 'WaterLevelAgent' with capabilities: ['water_level', 'usgs', 'rivers']\n[2025-12-03T18:10:00] INFO: A2A: Registered agent 'DisasterAgent' with capabilities: ['disasters', 'nasa', 'events']\n[2025-12-03T18:10:00] INFO: A2A: Registered agent 'AlertAgent' with capabilities: ['alerts', 'notifications', 'emergency']\n[2025-12-03T18:10:00] INFO: A2A: Registered agent 'AnalysisAgent' with capabilities: ['analysis', 'recommendations', 'synthesis']\n\n Advanced ADK Concepts initialized:\n   â€¢ MCP Tool Server (Model Context Protocol)\n   â€¢ Long-Running Operations Manager\n   â€¢ A2A Protocol (Agent-to-Agent Communication)\n   â€¢ 6 agents registered in A2A network\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"---\n\n# Â§4. API Configuration & Real-Time Tools\n\nAQUA SENTINEL connects to **real APIs** that return **real-time data**:\n\n| Tool | API Source | Data Type |\n|------|------------|----------|\n| `get_realtime_weather` | Open-Meteo | Weather forecasts, precipitation |\n| `get_realtime_water_level` | USGS Water Services | River/stream levels (US only) |\n| `get_realtime_disasters` | NASA EONET | Active natural disasters |\n| `get_country_info` | REST Countries | Population, region data |\n| `send_water_alert` | Internal | Alert generation & tracking |","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# CELL 5: API CONFIGURATION\n# ============================================================================\n\nGOOGLE_API_KEY = None\n\n# Method 1: Try Kaggle Secrets\ntry:\n    from kaggle_secrets import UserSecretsClient\n    secrets = UserSecretsClient()\n    GOOGLE_API_KEY = secrets.get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"Google API key loaded from Kaggle Secrets\")\nexcept Exception as e:\n    print(f\" Kaggle Secrets not available: {e}\")\n\n# Method 2: Environment variable\nif not GOOGLE_API_KEY:\n    GOOGLE_API_KEY = os.environ.get(\"GOOGLE_API_KEY\")\n    if GOOGLE_API_KEY:\n        print(\" Google API key loaded from environment variable\")\n\nif GOOGLE_API_KEY:\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(f\"\\n API Key Status: Configured (ends with ...{GOOGLE_API_KEY[-4:]})\")\nelse:\n    print(\"\\n API Key Status: NOT SET - Agent queries will fail!\")\n\n# Model configuration\nMODEL = \"gemini-2.0-flash\"\n\n# External API endpoints\nAPI_ENDPOINTS = {\n    \"open_meteo\": \"https://api.open-meteo.com/v1/forecast\",\n    \"usgs_water\": \"https://waterservices.usgs.gov/nwis/iv/\",\n    \"nasa_eonet\": \"https://eonet.gsfc.nasa.gov/api/v3/events\",\n    \"rest_countries\": \"https://restcountries.com/v3.1\",\n}\n\nprint(f\"\\n Model: {MODEL}\")\nprint(\"\\n External APIs configured (all FREE, no keys needed):\")\nfor name, url in API_ENDPOINTS.items():\n    print(f\"   â€¢ {name}: {url[:45]}...\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T18:10:25.452356Z","iopub.execute_input":"2025-12-03T18:10:25.453398Z","iopub.status.idle":"2025-12-03T18:10:25.591246Z","shell.execute_reply.started":"2025-12-03T18:10:25.453350Z","shell.execute_reply":"2025-12-03T18:10:25.590379Z"}},"outputs":[{"name":"stdout","text":"Google API key loaded from Kaggle Secrets\n\n API Key Status: Configured (ends with ...M01k)\n\n Model: gemini-2.0-flash\n\n External APIs configured (all FREE, no keys needed):\n   â€¢ open_meteo: https://api.open-meteo.com/v1/forecast...\n   â€¢ usgs_water: https://waterservices.usgs.gov/nwis/iv/...\n   â€¢ nasa_eonet: https://eonet.gsfc.nasa.gov/api/v3/events...\n   â€¢ rest_countries: https://restcountries.com/v3.1...\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# ============================================================================\n# CELL 6: REAL-TIME TOOLS WITH OBSERVABILITY & MCP REGISTRATION\n# ============================================================================\n\n# Extended location database\nLOCATIONS = {\n    \"california\": {\"lat\": 36.7783, \"lon\": -119.4179, \"name\": \"California, USA\"},\n    \"bangladesh\": {\"lat\": 23.6850, \"lon\": 90.3563, \"name\": \"Dhaka, Bangladesh\"},\n    \"kenya\": {\"lat\": -1.2921, \"lon\": 36.8219, \"name\": \"Nairobi, Kenya\"},\n    \"india\": {\"lat\": 28.6139, \"lon\": 77.2090, \"name\": \"Delhi, India\"},\n    \"brazil\": {\"lat\": -15.7975, \"lon\": -47.8919, \"name\": \"Brasilia, Brazil\"},\n    \"australia\": {\"lat\": -33.8688, \"lon\": 151.2093, \"name\": \"Sydney, Australia\"},\n    \"ethiopia\": {\"lat\": 9.1450, \"lon\": 40.4897, \"name\": \"Addis Ababa, Ethiopia\"},\n    \"somalia\": {\"lat\": 5.1521, \"lon\": 46.1996, \"name\": \"Mogadishu, Somalia\"},\n    \"texas\": {\"lat\": 31.9686, \"lon\": -99.9018, \"name\": \"Texas, USA\"},\n    \"florida\": {\"lat\": 27.6648, \"lon\": -81.5158, \"name\": \"Florida, USA\"},\n}\n\n\ndef get_realtime_weather(region: str) -> dict:\n    \"\"\"Get REAL-TIME weather data from Open-Meteo API with observability.\"\"\"\n    span_id = observability.start_span(\"get_realtime_weather\", {\"region\": region})\n    start_time = time.time()\n    \n    region_lower = region.lower().strip()\n    \n    if region_lower not in LOCATIONS:\n        for key in LOCATIONS:\n            if key in region_lower or region_lower in key:\n                region_lower = key\n                break\n        else:\n            observability.end_span(\"ERROR\", {\"error\": \"unknown_region\"})\n            return {\n                \"status\": \"error\",\n                \"message\": f\"Unknown region: {region}\",\n                \"available_regions\": list(LOCATIONS.keys()),\n            }\n    \n    loc = LOCATIONS[region_lower]\n    \n    try:\n        params = {\n            \"latitude\": loc[\"lat\"],\n            \"longitude\": loc[\"lon\"],\n            \"current_weather\": \"true\",\n            \"daily\": \"precipitation_sum,temperature_2m_max,temperature_2m_min,precipitation_probability_max\",\n            \"timezone\": \"auto\",\n            \"forecast_days\": 7,\n        }\n        \n        response = requests.get(API_ENDPOINTS[\"open_meteo\"], params=params, timeout=10)\n        response.raise_for_status()\n        data = response.json()\n        \n        latency_ms = (time.time() - start_time) * 1000\n        observability.record_api_call(\"open_meteo\", latency_ms, True)\n        \n        current = data.get(\"current_weather\", {})\n        daily = data.get(\"daily\", {})\n        precip_7d = sum(daily.get(\"precipitation_sum\", [0]) or [0])\n        \n        if precip_7d > 100:\n            flood_risk, drought_risk = \"HIGH\", \"LOW\"\n        elif precip_7d > 50:\n            flood_risk, drought_risk = \"MODERATE\", \"LOW\"\n        elif precip_7d < 5:\n            flood_risk, drought_risk = \"LOW\", \"HIGH\"\n        else:\n            flood_risk, drought_risk = \"LOW\", \"MODERATE\"\n        \n        observability.end_span(\"OK\", {\"flood_risk\": flood_risk, \"drought_risk\": drought_risk})\n        observability.log(\"INFO\", f\"Weather data fetched for {region}\", {\"latency_ms\": round(latency_ms, 2)})\n        \n        return {\n            \"status\": \"success\",\n            \"source\": \"Open-Meteo API (LIVE)\",\n            \"region\": region,\n            \"location\": loc[\"name\"],\n            \"coordinates\": {\"lat\": loc[\"lat\"], \"lon\": loc[\"lon\"]},\n            \"fetched_at\": datetime.utcnow().isoformat() + \"Z\",\n            \"current\": {\n                \"temperature_c\": current.get(\"temperature\"),\n                \"windspeed_kmh\": current.get(\"windspeed\"),\n                \"weather_code\": current.get(\"weathercode\"),\n            },\n            \"forecast_7d\": {\n                \"dates\": daily.get(\"time\", []),\n                \"precipitation_mm\": daily.get(\"precipitation_sum\", []),\n                \"total_precipitation_mm\": round(precip_7d, 1),\n            },\n            \"water_impact\": {\"flood_risk\": flood_risk, \"drought_risk\": drought_risk},\n            \"_observability\": {\"latency_ms\": round(latency_ms, 2)},\n        }\n        \n    except Exception as e:\n        latency_ms = (time.time() - start_time) * 1000\n        observability.record_api_call(\"open_meteo\", latency_ms, False)\n        observability.end_span(\"ERROR\", {\"error\": str(e)})\n        return {\"status\": \"error\", \"message\": f\"Error: {str(e)}\"}\n\n\nUSGS_SITES = {\n    \"california\": {\"site_id\": \"11447650\", \"name\": \"Sacramento River at Freeport, CA\"},\n    \"colorado\": {\"site_id\": \"09380000\", \"name\": \"Colorado River at Lees Ferry, AZ\"},\n    \"mississippi\": {\"site_id\": \"07374000\", \"name\": \"Mississippi River at Baton Rouge, LA\"},\n    \"texas\": {\"site_id\": \"08158000\", \"name\": \"Colorado River at Austin, TX\"},\n    \"florida\": {\"site_id\": \"02323500\", \"name\": \"Suwannee River near Wilcox, FL\"},\n}\n\n\ndef get_realtime_water_level(region: str) -> dict:\n    \"\"\"Get REAL-TIME water level data from USGS sensors.\"\"\"\n    span_id = observability.start_span(\"get_realtime_water_level\", {\"region\": region})\n    start_time = time.time()\n    \n    region_lower = region.lower().strip()\n    \n    if region_lower not in USGS_SITES:\n        observability.end_span(\"ERROR\", {\"error\": \"no_usgs_site\"})\n        return {\n            \"status\": \"error\",\n            \"message\": f\"No USGS site for: {region}\",\n            \"available_regions\": list(USGS_SITES.keys()),\n            \"note\": \"USGS only covers US water bodies\",\n        }\n    \n    site = USGS_SITES[region_lower]\n    \n    try:\n        params = {\n            \"sites\": site[\"site_id\"],\n            \"format\": \"json\",\n            \"parameterCd\": \"00065,00060\",\n            \"siteStatus\": \"active\",\n        }\n        \n        response = requests.get(API_ENDPOINTS[\"usgs_water\"], params=params, timeout=10)\n        response.raise_for_status()\n        data = response.json()\n        \n        latency_ms = (time.time() - start_time) * 1000\n        observability.record_api_call(\"usgs_water\", latency_ms, True)\n        \n        time_series = data.get(\"value\", {}).get(\"timeSeries\", [])\n        readings = {}\n        \n        for series in time_series:\n            var_name = series.get(\"variable\", {}).get(\"variableName\", \"Unknown\")\n            values = series.get(\"values\", [{}])[0].get(\"value\", [])\n            if values:\n                latest = values[-1]\n                readings[var_name] = {\n                    \"value\": float(latest.get(\"value\", 0)),\n                    \"timestamp\": latest.get(\"dateTime\"),\n                }\n        \n        gage_height = readings.get(\"Gage height, ft\", {}).get(\"value\", 0)\n        \n        if gage_height > 20:\n            alert_level, alert_reason = \"RED\", \"Flood risk - water level elevated\"\n        elif gage_height > 15:\n            alert_level, alert_reason = \"ORANGE\", \"Water level above normal\"\n        elif gage_height < 5:\n            alert_level, alert_reason = \"ORANGE\", \"Drought conditions\"\n        else:\n            alert_level, alert_reason = \"GREEN\", \"Normal range\"\n        \n        observability.end_span(\"OK\", {\"alert_level\": alert_level})\n        observability.log(\"INFO\", f\"Water level data fetched for {region}\", {\"latency_ms\": round(latency_ms, 2)})\n        \n        return {\n            \"status\": \"success\",\n            \"source\": \"USGS Water Services (LIVE)\",\n            \"region\": region,\n            \"site_name\": site[\"name\"],\n            \"fetched_at\": datetime.utcnow().isoformat() + \"Z\",\n            \"readings\": readings,\n            \"alert_level\": alert_level,\n            \"alert_reason\": alert_reason,\n            \"_observability\": {\"latency_ms\": round(latency_ms, 2)},\n        }\n        \n    except Exception as e:\n        latency_ms = (time.time() - start_time) * 1000\n        observability.record_api_call(\"usgs_water\", latency_ms, False)\n        observability.end_span(\"ERROR\", {\"error\": str(e)})\n        return {\"status\": \"error\", \"message\": f\"Error: {str(e)}\"}\n\n\ndef get_realtime_disasters(category: str = \"all\", limit: int = 10) -> dict:\n    \"\"\"Get REAL-TIME disaster events from NASA EONET.\"\"\"\n    span_id = observability.start_span(\"get_realtime_disasters\", {\"category\": category})\n    start_time = time.time()\n    \n    try:\n        params = {\"status\": \"open\", \"limit\": limit}\n        \n        response = requests.get(API_ENDPOINTS[\"nasa_eonet\"], params=params, timeout=15)\n        response.raise_for_status()\n        data = response.json()\n        \n        latency_ms = (time.time() - start_time) * 1000\n        observability.record_api_call(\"nasa_eonet\", latency_ms, True)\n        \n        events = data.get(\"events\", [])\n        processed = []\n        water_related = 0\n        \n        for event in events:\n            cats = [c.get(\"title\", \"\") for c in event.get(\"categories\", [])]\n            is_water = any(c.lower() in [\"floods\", \"drought\", \"severe storms\"] for c in cats)\n            if is_water:\n                water_related += 1\n            processed.append({\n                \"id\": event.get(\"id\"),\n                \"title\": event.get(\"title\"),\n                \"categories\": cats,\n                \"is_water_related\": is_water,\n            })\n        \n        alert_level = \"RED\" if water_related > 3 else \"ORANGE\" if water_related > 0 else \"GREEN\"\n        \n        observability.end_span(\"OK\", {\"events\": len(processed)})\n        observability.log(\"INFO\", f\"Disaster data fetched: {len(processed)} events\", {\"latency_ms\": round(latency_ms, 2)})\n        \n        return {\n            \"status\": \"success\",\n            \"source\": \"NASA EONET (LIVE)\",\n            \"fetched_at\": datetime.utcnow().isoformat() + \"Z\",\n            \"total_events\": len(processed),\n            \"water_related_events\": water_related,\n            \"events\": processed,\n            \"alert_level\": alert_level,\n            \"_observability\": {\"latency_ms\": round(latency_ms, 2)},\n        }\n        \n    except Exception as e:\n        latency_ms = (time.time() - start_time) * 1000\n        observability.record_api_call(\"nasa_eonet\", latency_ms, False)\n        observability.end_span(\"ERROR\", {\"error\": str(e)})\n        return {\"status\": \"error\", \"message\": f\"Error: {str(e)}\"}\n\n\ndef get_country_info(country: str) -> dict:\n    \"\"\"Get country information.\"\"\"\n    start_time = time.time()\n    try:\n        response = requests.get(f\"{API_ENDPOINTS['rest_countries']}/name/{country}\", timeout=10)\n        response.raise_for_status()\n        data = response.json()[0]\n        latency_ms = (time.time() - start_time) * 1000\n        observability.record_api_call(\"rest_countries\", latency_ms, True)\n        return {\n            \"status\": \"success\",\n            \"country\": data.get(\"name\", {}).get(\"common\", country),\n            \"population\": data.get(\"population\", 0),\n            \"region\": data.get(\"region\", \"\"),\n        }\n    except Exception as e:\n        return {\"status\": \"error\", \"message\": str(e)}\n\n\nALERT_LOG = []\n\ndef send_water_alert(region: str, alert_type: str, message: str, priority: str = \"normal\") -> dict:\n    \"\"\"Send water alert.\"\"\"\n    span_id = observability.start_span(\"send_water_alert\", {\"region\": region})\n    \n    timestamp = datetime.utcnow()\n    alert_id = f\"AQUA-{timestamp.strftime('%Y%m%d%H%M%S')}-{len(ALERT_LOG)+1:04d}\"\n    verification_code = f\"VER-{timestamp.strftime('%H%M%S')}\"\n    \n    country_info = get_country_info(region)\n    population = country_info.get(\"population\", 1000000)\n    \n    reach_mult = {\"emergency\": 0.85, \"high\": 0.60, \"normal\": 0.30, \"low\": 0.10}\n    estimated_reach = int(population * reach_mult.get(priority, 0.30))\n    \n    channels = {\n        \"emergency\": [\"SMS\", \"Voice\", \"Radio\", \"TV\", \"Sirens\", \"MobileApp\"],\n        \"high\": [\"SMS\", \"MobileApp\", \"Email\", \"Radio\"],\n        \"normal\": [\"MobileApp\", \"Email\"],\n        \"low\": [\"MobileApp\"],\n    }\n    \n    alert_record = {\n        \"alert_id\": alert_id,\n        \"verification_code\": verification_code,\n        \"timestamp\": timestamp.isoformat() + \"Z\",\n        \"region\": region,\n        \"alert_type\": alert_type,\n        \"priority\": priority,\n        \"channels\": channels.get(priority, [\"MobileApp\"]),\n        \"estimated_reach\": estimated_reach,\n    }\n    \n    ALERT_LOG.append(alert_record)\n    \n    observability.end_span(\"OK\", {\"alert_id\": alert_id})\n    observability.log(\"INFO\", f\"Alert sent: {alert_id} to {region}\")\n    \n    return {\n        \"status\": \"success\",\n        \"alert_id\": alert_id,\n        \"verification_code\": verification_code,\n        \"timestamp\": timestamp.isoformat() + \"Z\",\n        \"region\": region,\n        \"alert_type\": alert_type,\n        \"priority\": priority,\n        \"channels\": channels.get(priority, [\"MobileApp\"]),\n        \"delivery\": {\n            \"estimated_reach\": estimated_reach,\n            \"status\": \"QUEUED_FOR_DELIVERY\",\n        },\n    }\n\n\n# Register tools with MCP Server\nmcp_server.register_tool(\n    \"get_realtime_weather\",\n    \"Fetch real-time weather data from Open-Meteo API\",\n    get_realtime_weather,\n    {\"type\": \"object\", \"properties\": {\"region\": {\"type\": \"string\"}}}\n)\nmcp_server.register_tool(\n    \"get_realtime_water_level\",\n    \"Fetch water level data from USGS\",\n    get_realtime_water_level,\n    {\"type\": \"object\", \"properties\": {\"region\": {\"type\": \"string\"}}}\n)\nmcp_server.register_tool(\n    \"get_realtime_disasters\",\n    \"Fetch disaster events from NASA EONET\",\n    get_realtime_disasters,\n    {\"type\": \"object\", \"properties\": {\"category\": {\"type\": \"string\"}, \"limit\": {\"type\": \"integer\"}}}\n)\nmcp_server.register_tool(\n    \"send_water_alert\",\n    \"Send water crisis alert\",\n    send_water_alert,\n    {\"type\": \"object\", \"properties\": {\"region\": {\"type\": \"string\"}, \"alert_type\": {\"type\": \"string\"}, \"message\": {\"type\": \"string\"}, \"priority\": {\"type\": \"string\"}}}\n)\n\nprint(\" Created 5 real-time tools with observability\")\nprint(\" Tools registered with MCP Server\")\nprint(f\"   MCP Server: {mcp_server.get_server_info()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T18:10:39.589839Z","iopub.execute_input":"2025-12-03T18:10:39.590171Z","iopub.status.idle":"2025-12-03T18:10:39.632969Z","shell.execute_reply.started":"2025-12-03T18:10:39.590147Z","shell.execute_reply":"2025-12-03T18:10:39.631509Z"}},"outputs":[{"name":"stdout","text":"[2025-12-03T18:10:39] INFO: MCP: Registered tool 'get_realtime_weather'\n[2025-12-03T18:10:39] INFO: MCP: Registered tool 'get_realtime_water_level'\n[2025-12-03T18:10:39] INFO: MCP: Registered tool 'get_realtime_disasters'\n[2025-12-03T18:10:39] INFO: MCP: Registered tool 'send_water_alert'\n Created 5 real-time tools with observability\n Tools registered with MCP Server\n   MCP Server: {'name': 'aqua-sentinel-mcp', 'version': '1.0.0', 'capabilities': {'tools': True, 'resources': True, 'prompts': False}, 'tools_count': 4}\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"---\n\n# Â§5. Timing Comparison: Sequential vs Parallel\n\nOne of the key benefits of the `ParallelAgent` pattern is **concurrent execution**. This section demonstrates the speedup achieved by running API calls in parallel rather than sequentially.","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# CELL 7: TIMING COMPARISON - Sequential vs Parallel Execution\n# ============================================================================\n\ndef run_sequential_fetch(region: str) -> tuple:\n    \"\"\"\n    Run API fetches SEQUENTIALLY (one after another).\n    Returns (results, total_time_ms)\n    \"\"\"\n    start = time.time()\n    \n    # Sequential execution - each waits for the previous\n    weather = get_realtime_weather(region)\n    water = get_realtime_water_level(region) if region in USGS_SITES else {\"status\": \"skipped\", \"reason\": \"no USGS site\"}\n    disasters = get_realtime_disasters()\n    \n    total_time = (time.time() - start) * 1000\n    \n    return {\n        \"weather\": weather.get(\"status\"),\n        \"water_level\": water.get(\"status\"),\n        \"disasters\": disasters.get(\"status\"),\n    }, total_time\n\n\ndef run_parallel_fetch(region: str) -> tuple:\n    \"\"\"\n    Run API fetches in PARALLEL (concurrent).\n    Returns (results, total_time_ms)\n    \"\"\"\n    start = time.time()\n    \n    results = {}\n    \n    # Parallel execution using ThreadPoolExecutor\n    with ThreadPoolExecutor(max_workers=3) as executor:\n        weather_future = executor.submit(get_realtime_weather, region)\n        water_future = executor.submit(\n            get_realtime_water_level, region\n        ) if region in USGS_SITES else None\n        disasters_future = executor.submit(get_realtime_disasters)\n        \n        results[\"weather\"] = weather_future.result().get(\"status\")\n        results[\"water_level\"] = water_future.result().get(\"status\") if water_future else \"skipped\"\n        results[\"disasters\"] = disasters_future.result().get(\"status\")\n    \n    total_time = (time.time() - start) * 1000\n    \n    return results, total_time\n\n\ndef demonstrate_parallel_speedup(region: str = \"california\"):\n    \"\"\"\n    Demonstrate the speedup achieved by ParallelAgent pattern.\n    \"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"  TIMING COMPARISON: Sequential vs Parallel Execution\")\n    print(\"=\"*70)\n    print(f\"\\nRegion: {region.upper()}\")\n    print(\"APIs: Open-Meteo (weather) + USGS (water) + NASA EONET (disasters)\")\n    print(\"\\n\" + \"-\"*70)\n    \n    # Run sequential\n    print(\"\\nðŸ”„ SEQUENTIAL EXECUTION (one after another):\")\n    seq_results, seq_time = run_sequential_fetch(region)\n    print(f\"   Results: {seq_results}\")\n    print(f\"   â±ï¸  Total Time: {seq_time:.2f}ms\")\n    \n    # Small delay between tests\n    time.sleep(0.5)\n    \n    # Run parallel\n    print(\"\\nâš¡ PARALLEL EXECUTION (concurrent):\")\n    par_results, par_time = run_parallel_fetch(region)\n    print(f\"   Results: {par_results}\")\n    print(f\"   Total Time: {par_time:.2f}ms\")\n    \n    # Calculate speedup\n    speedup = seq_time / par_time if par_time > 0 else 0\n    time_saved = seq_time - par_time\n    \n    # Record in observability\n    observability.record_timing_comparison(f\"fetch_{region}\", seq_time, par_time)\n    \n    print(\"\\n\" + \"-\"*70)\n    print(\" COMPARISON RESULTS:\")\n    print(\"-\"*70)\n    print(f\"   Sequential Time: {seq_time:.2f}ms\")\n    print(f\"   Parallel Time:   {par_time:.2f}ms\")\n    print(f\"   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n    print(f\"    Speedup:      {speedup:.2f}x faster\")\n    print(f\"    Time Saved:   {time_saved:.2f}ms\")\n    print(\"\\n\" + \"=\"*70)\n    \n    # A2A: Broadcast timing results to all agents\n    a2a_protocol.broadcast(\"HydroOrchestrator\", {\n        \"type\": \"timing_benchmark\",\n        \"sequential_ms\": seq_time,\n        \"parallel_ms\": par_time,\n        \"speedup\": speedup,\n    })\n    \n    return {\n        \"sequential_ms\": seq_time,\n        \"parallel_ms\": par_time,\n        \"speedup\": speedup,\n        \"time_saved_ms\": time_saved,\n    }\n\n\nprint(\" Timing comparison functions ready\")\nprint(\"   â€¢ run_sequential_fetch() - Execute APIs one by one\")\nprint(\"   â€¢ run_parallel_fetch() - Execute APIs concurrently\")\nprint(\"   â€¢ demonstrate_parallel_speedup() - Run comparison benchmark\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T18:11:22.142190Z","iopub.execute_input":"2025-12-03T18:11:22.142592Z","iopub.status.idle":"2025-12-03T18:11:22.157804Z","shell.execute_reply.started":"2025-12-03T18:11:22.142567Z","shell.execute_reply":"2025-12-03T18:11:22.156659Z"}},"outputs":[{"name":"stdout","text":" Timing comparison functions ready\n   â€¢ run_sequential_fetch() - Execute APIs one by one\n   â€¢ run_parallel_fetch() - Execute APIs concurrently\n   â€¢ demonstrate_parallel_speedup() - Run comparison benchmark\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"---\n\n# Â§6. Agent Implementation\n\n## Agent Architecture\n\n```\nHydroOrchestrator (LlmAgent)\nâ”‚\nâ”œâ”€â”€ SentinelAgent (ParallelAgent) â”€â”€â”€â”€ CONCURRENT EXECUTION\nâ”‚   â”œâ”€â”€ WeatherAgent      â†’ Open-Meteo    â”\nâ”‚   â”œâ”€â”€ WaterLevelAgent   â†’ USGS          â”œâ”€ Run in PARALLEL\nâ”‚   â””â”€â”€ DisasterAgent     â†’ NASA EONET    â”˜\nâ”‚\nâ”œâ”€â”€ GuardianAgent (SequentialAgent) â”€â”€ STATE PASSING\nâ”‚   â”œâ”€â”€ WeatherAgent      â†’ Structured Output (Step 1)\nâ”‚   â””â”€â”€ AnalysisAgent     â†’ Extracts & Recommends (Step 2)\nâ”‚\nâ””â”€â”€ ResponderAgent (LoopAgent) â”€â”€â”€â”€â”€â”€â”€â”€ RETRY MECHANISM\n    â”œâ”€â”€ AlertAgent        â†’ Send Alert\n    â””â”€â”€ VerifyAgent       â†’ 7-Point Validation (max 5 iterations)\n```\n\n### ADK Patterns Used:\n\n| Pattern | Agent | Purpose |\n|---------|-------|--------|\n| **LlmAgent** | HydroOrchestrator | Central coordinator with tools |\n| **ParallelAgent** | SentinelAgent | Concurrent API calls for speed |\n| **SequentialAgent** | GuardianAgent | Ordered pipeline with state passing |\n| **LoopAgent** | ResponderAgent | Retry until verification passes |","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# CELL 8: AGENT IMPLEMENTATION\n# ============================================================================\n\n# Weather Agent - FOR SENTINEL (Parallel)\nweather_agent_sentinel = LlmAgent(\n    name=\"WeatherAgentSentinel\",\n    model=MODEL,\n    instruction=\"\"\"You analyze REAL-TIME weather data for water impact.\n    \n    Steps:\n    1. Extract region from query (convert to lowercase)\n       Available: california, bangladesh, kenya, india, brazil, australia, ethiopia, somalia, texas, florida\n    2. Call get_realtime_weather(region=\"<region>\") IMMEDIATELY\n    3. Report: temperature, 7-day precipitation, flood/drought risk\n    4. Include fetched_at timestamp\n    \n    CRITICAL: You MUST call the function.\"\"\",\n    description=\"Fetches real-time weather data\",\n    tools=[get_realtime_weather],\n)\n\n# Weather Agent - FOR GUARDIAN (Sequential Step 1)\nweather_agent_guardian = LlmAgent(\n    name=\"WeatherAgentGuardian\",\n    model=MODEL,\n    instruction=\"\"\"You are STEP 1 of a sequential pipeline. Your output becomes input for AnalysisAgent.\n    \n    YOUR TASK: Fetch weather data and OUTPUT STRUCTURED DATA.\n    \n    Steps:\n    1. Extract region from query\n    2. Call get_realtime_weather(region=\"<region>\")\n    3. OUTPUT FORMAT:\n       \n       ---WEATHER_DATA_START---\n       Region: [name]\n       Temperature: [X]Â°C\n       7-Day Precipitation: [X] mm\n       Flood Risk: [HIGH/MODERATE/LOW]\n       Drought Risk: [HIGH/MODERATE/LOW]\n       Fetched At: [timestamp]\n       ---WEATHER_DATA_END---\n    \n    This structured output enables AnalysisAgent to extract the data.\"\"\",\n    description=\"Fetches weather data with structured output for sequential processing\",\n    tools=[get_realtime_weather],\n)\n\n# Water Level Agent\nwater_level_agent = LlmAgent(\n    name=\"WaterLevelAgent\",\n    model=MODEL,\n    instruction=\"\"\"You monitor REAL-TIME water levels from USGS sensors.\n    Call get_realtime_water_level for US regions.\n    Available: california, colorado, mississippi, texas, florida\n    Note: USGS only covers US water bodies.\"\"\",\n    description=\"Monitors water levels from USGS\",\n    tools=[get_realtime_water_level],\n)\n\n# Disaster Agent\ndisaster_agent = LlmAgent(\n    name=\"DisasterAgent\",\n    model=MODEL,\n    instruction=\"\"\"You monitor REAL-TIME disasters from NASA EONET.\n    Call get_realtime_disasters() to get global events.\n    Report: total events, water-related count, alert level.\"\"\",\n    description=\"Monitors disasters from NASA EONET\",\n    tools=[get_realtime_disasters],\n)\n\n# Analysis Agent (Sequential Step 2)\nanalysis_agent = LlmAgent(\n    name=\"AnalysisAgent\",\n    model=MODEL,\n    instruction=\"\"\"You are STEP 2 of a sequential pipeline. You RECEIVE data from WeatherAgentGuardian.\n    \n    SEQUENTIAL DEPENDENCY: Extract data from the ---WEATHER_DATA_START--- block.\n    \n    YOUR TASK:\n    1. EXTRACT: Temperature, Precipitation, Flood Risk, Drought Risk\n    2. ANALYZE:\n       - If Flood Risk HIGH: Recommend evacuation prep\n       - If Drought Risk HIGH: Recommend conservation\n       - If precipitation > 50mm: Warn about flooding\n       - If precipitation < 10mm: Warn about drought\n    \n    3. GENERATE RECOMMENDATIONS:\n       ðŸ”´ HIGH PRIORITY: [immediate actions]\n       ðŸŸ¡ MEDIUM PRIORITY: [preparatory actions]\n       ðŸŸ¢ LOW PRIORITY: [monitoring actions]\n    \n    4. CITE SPECIFIC DATA from WeatherAgentGuardian's output.\"\"\",\n    description=\"Synthesizes weather data into recommendations\",\n)\n\n# Alert Agent (Loop Step 1)\nalert_agent = LlmAgent(\n    name=\"AlertAgent\",\n    model=MODEL,\n    instruction=\"\"\"You send water-related alerts.\n    \n    Call send_water_alert with:\n    - region, alert_type, message, priority\n    \n    OUTPUT for verification:\n    - Alert ID, Verification Code, Region, Priority, Estimated Reach, Channels, Status\"\"\",\n    description=\"Sends water alerts\",\n    tools=[send_water_alert],\n)\n\n# Verify Agent (Loop Step 2)\nverify_agent = LlmAgent(\n    name=\"VerifyAgent\",\n    model=MODEL,\n    instruction=\"\"\"You verify alert delivery with 7-POINT VALIDATION.\n    \n    CHECKLIST:\n    âœ“ CHECK 1: Alert ID exists (AQUA-YYYYMMDDHHMMSS-####)\n    âœ“ CHECK 2: Verification Code exists (VER-HHMMSS)\n    âœ“ CHECK 3: Estimated reach > 0\n    âœ“ CHECK 4: Status is QUEUED_FOR_DELIVERY\n    âœ“ CHECK 5: Timestamp is recent\n    âœ“ CHECK 6: Channels list not empty\n    âœ“ CHECK 7: Region matches request\n    \n    OUTPUT:\n    Verification Status: [VERIFIED/FAILED]\n    Checks Passed: [X/7]\"\"\",\n    description=\"Verifies alerts with 7-point validation\",\n)\n\nprint(\" Created 7 specialist LlmAgents\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T18:11:32.147870Z","iopub.execute_input":"2025-12-03T18:11:32.148173Z","iopub.status.idle":"2025-12-03T18:11:32.159330Z","shell.execute_reply.started":"2025-12-03T18:11:32.148152Z","shell.execute_reply":"2025-12-03T18:11:32.157880Z"}},"outputs":[{"name":"stdout","text":" Created 7 specialist LlmAgents\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# ============================================================================\n# CELL 9: MULTI-AGENT ARCHITECTURES\n# ============================================================================\n\n# PARALLEL AGENT - SentinelAgent\nsentinel_agent = ParallelAgent(\n    name=\"SentinelAgent\",\n    sub_agents=[weather_agent_sentinel, water_level_agent, disaster_agent],\n    description=\"\"\"Real-time monitoring using PARALLEL EXECUTION.\n    \n    PARALLELISM BENEFIT (demonstrated in timing comparison):\n    - Sequential: ~2000-4000ms (APIs execute one by one)\n    - Parallel: ~800-1500ms (APIs execute concurrently)\n    - Speedup: ~2-3x faster\n    \"\"\",\n)\n\nprint(\" Created SentinelAgent (ParallelAgent)\")\nprint(\"   â€¢ 3 sub-agents execute CONCURRENTLY\")\n\n# SEQUENTIAL AGENT - GuardianAgent\nguardian_agent = SequentialAgent(\n    name=\"GuardianAgent\",\n    sub_agents=[weather_agent_guardian, analysis_agent],\n    description=\"\"\"Predictive analytics using SEQUENTIAL EXECUTION with state passing.\n    \n    Step 1: WeatherAgentGuardian â†’ Structured output\n    Step 2: AnalysisAgent â†’ Extracts data & recommends\n    \"\"\",\n)\n\nprint(\" Created GuardianAgent (SequentialAgent)\")\nprint(\"   â€¢ Step 1 â†’ Step 2 with state passing\")\n\n# LOOP AGENT - ResponderAgent\nresponder_agent = LoopAgent(\n    name=\"ResponderAgent\",\n    sub_agents=[alert_agent, verify_agent],\n    max_iterations=5,\n    description=\"\"\"Emergency response using LOOP EXECUTION.\n    \n    Loop: AlertAgent â†’ VerifyAgent (7-point check)\n    Exit: VERIFIED status or max 5 iterations\n    \"\"\",\n)\n\nprint(\" Created ResponderAgent (LoopAgent)\")\nprint(\"   â€¢ Max 5 iterations, 7-point verification\")\n\n# ROOT ORCHESTRATOR\nORCHESTRATOR_INSTRUCTION = \"\"\"\nYou are HYDRO ORCHESTRATOR, the central coordinator of AQUA SENTINEL.\n\n## REAL-TIME DATA\nAll tools fetch LIVE data from real APIs with observability tracking.\n\n## QUERY ROUTING\n\n1. **REGIONAL MONITORING** â†’ SentinelAgent (ParallelAgent)\n   Keywords: \"situation in [region]\", \"water status\"\n   \n2. **FORECAST & ANALYSIS** â†’ GuardianAgent (SequentialAgent)\n   Keywords: \"forecast\", \"predict\", \"analyze\", \"recommend\"\n   \n3. **EMERGENCY ALERTS** â†’ ResponderAgent (LoopAgent)\n   Keywords: \"send alert\", \"warn\", \"emergency\"\n   \n4. **GLOBAL DISASTERS** â†’ Call get_realtime_disasters() directly\n   Keywords: \"global\", \"worldwide\"\n\n## RESPONSE FORMAT\n- Data Source + Timestamp\n- Key Findings\n- Risk Level: ðŸŸ¢ GREEN / ðŸŸ¡ ORANGE / ðŸ”´ RED\n- Recommendations\n\"\"\"\n\nhydro_orchestrator = LlmAgent(\n    name=\"HydroOrchestrator\",\n    model=MODEL,\n    instruction=ORCHESTRATOR_INSTRUCTION,\n    description=\"Central coordinator\",\n    sub_agents=[sentinel_agent, guardian_agent, responder_agent],\n    tools=[get_realtime_disasters],\n)\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"AQUA SENTINEL AGENT HIERARCHY\")\nprint(\"=\"*70)\nprint(\"\"\"\nHydroOrchestrator (LlmAgent)\nâ”‚\nâ”œâ”€â”€ SentinelAgent (ParallelAgent) â”€â”€â”€â”€ CONCURRENT\nâ”‚   â”œâ”€â”€ WeatherAgent  â†’ Open-Meteo\nâ”‚   â”œâ”€â”€ WaterLevelAgent â†’ USGS\nâ”‚   â””â”€â”€ DisasterAgent â†’ NASA EONET\nâ”‚\nâ”œâ”€â”€ GuardianAgent (SequentialAgent) â”€â”€ STATE PASSING\nâ”‚   â”œâ”€â”€ WeatherAgent â†’ Structured Output\nâ”‚   â””â”€â”€ AnalysisAgent â†’ Extract & Recommend\nâ”‚\nâ””â”€â”€ ResponderAgent (LoopAgent) â”€â”€â”€â”€â”€â”€â”€ 5 ITERATIONS\n    â”œâ”€â”€ AlertAgent â†’ Send\n    â””â”€â”€ VerifyAgent â†’ 7-Point Check\n\"\"\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T18:11:45.615550Z","iopub.execute_input":"2025-12-03T18:11:45.615900Z","iopub.status.idle":"2025-12-03T18:11:45.626392Z","shell.execute_reply.started":"2025-12-03T18:11:45.615872Z","shell.execute_reply":"2025-12-03T18:11:45.625270Z"}},"outputs":[{"name":"stdout","text":" Created SentinelAgent (ParallelAgent)\n   â€¢ 3 sub-agents execute CONCURRENTLY\n Created GuardianAgent (SequentialAgent)\n   â€¢ Step 1 â†’ Step 2 with state passing\n Created ResponderAgent (LoopAgent)\n   â€¢ Max 5 iterations, 7-point verification\n\n======================================================================\nAQUA SENTINEL AGENT HIERARCHY\n======================================================================\n\nHydroOrchestrator (LlmAgent)\nâ”‚\nâ”œâ”€â”€ SentinelAgent (ParallelAgent) â”€â”€â”€â”€ CONCURRENT\nâ”‚   â”œâ”€â”€ WeatherAgent  â†’ Open-Meteo\nâ”‚   â”œâ”€â”€ WaterLevelAgent â†’ USGS\nâ”‚   â””â”€â”€ DisasterAgent â†’ NASA EONET\nâ”‚\nâ”œâ”€â”€ GuardianAgent (SequentialAgent) â”€â”€ STATE PASSING\nâ”‚   â”œâ”€â”€ WeatherAgent â†’ Structured Output\nâ”‚   â””â”€â”€ AnalysisAgent â†’ Extract & Recommend\nâ”‚\nâ””â”€â”€ ResponderAgent (LoopAgent) â”€â”€â”€â”€â”€â”€â”€ 5 ITERATIONS\n    â”œâ”€â”€ AlertAgent â†’ Send\n    â””â”€â”€ VerifyAgent â†’ 7-Point Check\n\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# ============================================================================\n# CELL 10: SESSION MANAGEMENT & QUERY FUNCTION\n# ============================================================================\n\nimport inspect\n\nsession_service = InMemorySessionService()\n\nAPP_NAME = \"aqua_sentinel_realtime\"\nUSER_ID = \"demo_user\"\nSESSION_ID = f\"session_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}\"\n\nrunner = Runner(\n    agent=hydro_orchestrator,\n    app_name=APP_NAME,\n    session_service=session_service,\n)\n\n\nasync def ensure_session():\n    \"\"\"Create session.\"\"\"\n    try:\n        result = session_service.create_session(\n            app_name=APP_NAME,\n            user_id=USER_ID,\n            session_id=SESSION_ID,\n        )\n        if inspect.iscoroutine(result):\n            await result\n        print(f\" Session created: {SESSION_ID}\")\n    except Exception as e:\n        print(f\" Session: {e}\")\n\n\nasync def query_aqua_sentinel(\n    query: str,\n    verbose: bool = True,\n    fresh_session: bool = True,\n    show_observability: bool = True\n) -> str:\n    \"\"\"Send query to AQUA SENTINEL with observability.\"\"\"\n    global SESSION_ID\n    \n    trace_id = observability.start_trace(f\"query: {query[:50]}...\")\n    \n    if fresh_session:\n        SESSION_ID = f\"session_{datetime.utcnow().strftime('%Y%m%d_%H%M%S%f')}\"\n        try:\n            result = session_service.create_session(\n                app_name=APP_NAME,\n                user_id=USER_ID,\n                session_id=SESSION_ID,\n            )\n            if inspect.iscoroutine(result):\n                await result\n        except:\n            pass\n    \n    if verbose:\n        print(f\"\\n{'='*70}\")\n        print(f\" QUERY: {query}\")\n        print(f\" Time: {datetime.utcnow().isoformat()}Z\")\n        print(f\" Trace ID: {trace_id}\")\n        print(f\"{'='*70}\")\n    \n    query_span = observability.start_span(\"agent_query\", {\"query\": query[:100]})\n    \n    content = types.Content(\n        role=\"user\",\n        parts=[types.Part(text=query)]\n    )\n    \n    response_text = \"\"\n    try:\n        async for event in runner.run_async(\n            user_id=USER_ID,\n            session_id=SESSION_ID,\n            new_message=content,\n        ):\n            if hasattr(event, 'content') and event.content:\n                for part in event.content.parts:\n                    if hasattr(part, 'text') and part.text:\n                        response_text += part.text + \"\\n\"\n    except Exception as e:\n        response_text = f\"Error: {str(e)}\"\n        observability.log(\"ERROR\", f\"Query failed: {str(e)}\")\n    \n    observability.end_span(\"OK\" if \"Error\" not in response_text else \"ERROR\")\n    \n    if verbose:\n        print(f\"\\n RESPONSE:\\n{response_text}\")\n        \n        if show_observability:\n            print(f\"\\n{'â”€'*70}\")\n            print(\" OBSERVABILITY SUMMARY\")\n            print(f\"{'â”€'*70}\")\n            trace = observability.get_trace_summary()\n            print(f\"   Trace ID: {trace.get('trace_id', 'N/A')}\")\n            print(f\"   Total Spans: {trace.get('total_spans', 0)}\")\n            print(f\"   Total Duration: {trace.get('total_duration_ms', 0):.2f}ms\")\n            metrics = observability.get_metrics_summary()\n            print(f\"   API Calls: {metrics.get('total_api_calls', 0)}\")\n            print(f\"   Avg Latency: {metrics.get('average_latency_ms', 0):.2f}ms\")\n            print(f\"   Success Rate: {metrics.get('success_rate', 'N/A')}\")\n            print(f\"   Tools Used: {', '.join(metrics.get('unique_tools_used', []))}\")\n    \n    return response_text.strip()\n\n\nprint(\" Query function ready with observability\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T18:12:12.323709Z","iopub.execute_input":"2025-12-03T18:12:12.324048Z","iopub.status.idle":"2025-12-03T18:12:12.339700Z","shell.execute_reply.started":"2025-12-03T18:12:12.324015Z","shell.execute_reply":"2025-12-03T18:12:12.338713Z"}},"outputs":[{"name":"stdout","text":" Query function ready with observability\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"---\n\n# Â§7. Evaluation Framework\n\nAQUA SENTINEL includes a comprehensive evaluation framework with **12 test cases** across 4 categories:\n\n| Category | Tests | Purpose |\n|----------|-------|--------|\n| **Happy Path** | 4 | Core functionality works correctly |\n| **Error Handling** | 3 | Graceful handling of invalid inputs |\n| **Multi-Agent** | 3 | Agent coordination and handoffs |\n| **Edge Cases** | 2 | Boundary conditions and special scenarios |\n\n### Scoring Dimensions:\n- **Validity (25%)**: Error-free response\n- **Relevance (35%)**: Contains expected elements\n- **Freshness (20%)**: Real-time data indicators\n- **Quality (20%)**: Response completeness\n- **Pass Threshold**: Overall Score â‰¥ 0.50","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# CELL 11: EVALUATION FRAMEWORK (12 Test Cases)\n# ============================================================================\n\n@dataclass\nclass TestCase:\n    id: str\n    name: str\n    category: str\n    query: str\n    expected_elements: List[str]\n    expected_agent: str\n\n\nGOLDEN_DATASET = [\n    # Happy Path (4)\n    TestCase(\"RT-001\", \"Real-Time Weather\", \"happy_path\",\n             \"What's the current weather in California?\",\n             [\"weather\", \"temperature\", \"california\"], \"WeatherAgent\"),\n    TestCase(\"RT-002\", \"USGS Water Level\", \"happy_path\",\n             \"What are the current water levels in California rivers?\",\n             [\"water\", \"level\", \"gage\"], \"WaterLevelAgent\"),\n    TestCase(\"RT-003\", \"NASA Disasters\", \"happy_path\",\n             \"What natural disasters are currently active?\",\n             [\"disaster\", \"event\", \"nasa\"], \"DisasterAgent\"),\n    TestCase(\"RT-004\", \"Alert Delivery\", \"happy_path\",\n             \"Send a water conservation alert to India with normal priority.\",\n             [\"alert\", \"india\", \"sent\"], \"ResponderAgent\"),\n    \n    # Error Handling (3)\n    TestCase(\"RT-005\", \"Invalid Region Error\", \"error_handling\",\n             \"What's the weather in Atlantis?\",\n             [\"error\", \"unknown\", \"available\"], \"WeatherAgent\"),\n    TestCase(\"RT-006\", \"Non-US Water Level Request\", \"error_handling\",\n             \"What's the water level in Kenya rivers?\",\n             [\"usgs\", \"us\", \"available\"], \"WaterLevelAgent\"),\n    TestCase(\"RT-007\", \"Ambiguous Region Query\", \"error_handling\",\n             \"What's the water situation?\",\n             [\"region\", \"specify\", \"available\"], \"HydroOrchestrator\"),\n    \n    # Multi-Agent (3)\n    TestCase(\"RT-008\", \"Sequential Forecast Analysis\", \"multi_agent\",\n             \"What's the weather forecast for Kenya? Analyze risks and recommend actions.\",\n             [\"forecast\", \"recommend\", \"risk\"], \"GuardianAgent\"),\n    TestCase(\"RT-009\", \"Parallel Regional Monitoring\", \"multi_agent\",\n             \"Give me a complete water situation report for California with all available data sources.\",\n             [\"weather\", \"water\", \"california\"], \"SentinelAgent\"),\n    TestCase(\"RT-010\", \"Global Disaster Overview\", \"multi_agent\",\n             \"What natural disasters are happening globally right now? Focus on water-related events.\",\n             [\"disaster\", \"global\", \"water\"], \"DisasterAgent\"),\n    \n    # Edge Cases (2)\n    TestCase(\"RT-011\", \"Emergency High Priority Alert\", \"edge_case\",\n             \"Send an EMERGENCY flood alert to Bangladesh immediately. Critical flooding situation!\",\n             [\"alert\", \"emergency\", \"bangladesh\"], \"ResponderAgent\"),\n    TestCase(\"RT-012\", \"Horn of Africa Drought Region\", \"edge_case\",\n             \"What's the drought situation in Ethiopia? This is for the Horn of Africa crisis response.\",\n             [\"weather\", \"drought\", \"ethiopia\"], \"WeatherAgent\"),\n]\n\nprint(f\"Golden Dataset: {len(GOLDEN_DATASET)} test cases\")\nprint(f\"   â€¢ Happy Path: {sum(1 for t in GOLDEN_DATASET if t.category == 'happy_path')}\")\nprint(f\"   â€¢ Error Handling: {sum(1 for t in GOLDEN_DATASET if t.category == 'error_handling')}\")\nprint(f\"   â€¢ Multi-Agent: {sum(1 for t in GOLDEN_DATASET if t.category == 'multi_agent')}\")\nprint(f\"   â€¢ Edge Cases: {sum(1 for t in GOLDEN_DATASET if t.category == 'edge_case')}\")\n\n\ndef evaluate_response(response: str, test_case: TestCase) -> dict:\n    \"\"\"Multi-dimensional evaluation.\"\"\"\n    response_lower = response.lower()\n    response_len = len(response)\n    \n    # Validity (25%)\n    error_indicators = [\n        \"error:\" in response_lower and test_case.category != \"error_handling\",\n        \"api key\" in response_lower,\n        response_len < 20,\n    ]\n    validity_score = 0.0 if any(error_indicators) else 1.0\n    \n    if test_case.category == \"error_handling\":\n        if any(x in response_lower for x in [\"error\", \"unknown\", \"available\", \"not\", \"usgs\"]):\n            validity_score = 1.0\n    \n    # Relevance (35%)\n    matches = sum(1 for elem in test_case.expected_elements if elem.lower() in response_lower)\n    relevance_score = min(1.0, matches / len(test_case.expected_elements))\n    \n    # Freshness (20%)\n    freshness = [\n        \"2025\" in response_lower or \"2024\" in response_lower,\n        any(x in response_lower for x in [\"live\", \"real-time\", \"current\"]),\n        any(x in response_lower for x in [\"open-meteo\", \"usgs\", \"nasa\", \"eonet\"]),\n    ]\n    freshness_score = min(1.0, sum(freshness) / 2)\n    \n    # Quality (20%)\n    quality_score = min(1.0, response_len / 200)\n    \n    overall = (validity_score * 0.25) + (relevance_score * 0.35) + (freshness_score * 0.20) + (quality_score * 0.20)\n    \n    return {\n        \"test_id\": test_case.id,\n        \"test_name\": test_case.name,\n        \"category\": test_case.category,\n        \"validity_score\": round(validity_score, 2),\n        \"relevance_score\": round(relevance_score, 2),\n        \"freshness_score\": round(freshness_score, 2),\n        \"quality_score\": round(quality_score, 2),\n        \"overall_score\": round(overall, 2),\n        \"passed\": overall >= 0.50,\n    }\n\n\nasync def run_evaluation(test_subset: str = \"all\"):\n    \"\"\"Run evaluation suite.\"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\" AQUA SENTINEL EVALUATION FRAMEWORK\")\n    print(\"=\"*70)\n    \n    tests = GOLDEN_DATASET if test_subset == \"all\" else [t for t in GOLDEN_DATASET if t.category == test_subset]\n    \n    print(f\"\\n Running {len(tests)} tests (subset: {test_subset})\")\n    print(\"\\n Scoring Dimensions:\")\n    print(\"   â€¢ Validity (25%): Error-free response\")\n    print(\"   â€¢ Relevance (35%): Contains expected elements\")\n    print(\"   â€¢ Freshness (20%): Real-time data indicators\")\n    print(\"   â€¢ Quality (20%): Response completeness\")\n    print(\"   â€¢ Pass Threshold: Overall Score â‰¥ 0.50\")\n    print(\"\\n\" + \"-\"*70)\n    \n    results = []\n    \n    for i, tc in enumerate(tests):\n        print(f\"\\n [{tc.id}] {tc.name}\")\n        print(f\"   Category: {tc.category}\")\n        print(f\"   Query: \\\"{tc.query[:60]}...\\\"\" if len(tc.query) > 60 else f\"   Query: \\\"{tc.query}\\\"\")\n        \n        if i > 0:\n            await asyncio.sleep(1)\n        \n        try:\n            response = await query_aqua_sentinel(tc.query, verbose=False, show_observability=False)\n            result = evaluate_response(response, tc)\n        except Exception as e:\n            result = {\n                \"test_id\": tc.id, \"test_name\": tc.name, \"category\": tc.category,\n                \"validity_score\": 0, \"relevance_score\": 0, \"freshness_score\": 0,\n                \"quality_score\": 0, \"overall_score\": 0, \"passed\": False,\n            }\n        \n        results.append(result)\n        status = \"PASS\" if result[\"passed\"] else \"FAIL\"\n        print(f\"   â”œâ”€ Validity:  {result['validity_score']:.2f}\")\n        print(f\"   â”œâ”€ Relevance: {result['relevance_score']:.2f}\")\n        print(f\"   â”œâ”€ Freshness: {result['freshness_score']:.2f}\")\n        print(f\"   â”œâ”€ Quality:   {result['quality_score']:.2f}\")\n        print(f\"   â””â”€ Overall:   {result['overall_score']:.2f} {status}\")\n    \n    # Summary\n    passed = sum(1 for r in results if r[\"passed\"])\n    avg = sum(r[\"overall_score\"] for r in results) / len(results)\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\" EVALUATION RESULTS SUMMARY\")\n    print(\"=\"*70)\n    print(f\"\\n   Tests Passed: {passed}/{len(results)}\")\n    print(f\"   Average Score: {avg:.2f}\")\n    print(f\"   Pass Rate: {(passed/len(results))*100:.1f}%\")\n    \n    print(\"\\n   Results by Category:\")\n    for cat in [\"happy_path\", \"error_handling\", \"multi_agent\", \"edge_case\"]:\n        cat_results = [r for r in results if r.get(\"category\") == cat]\n        if cat_results:\n            cat_passed = sum(1 for r in cat_results if r[\"passed\"])\n            cat_avg = sum(r[\"overall_score\"] for r in cat_results) / len(cat_results)\n            print(f\"   â€¢ {cat}: {cat_passed}/{len(cat_results)} passed (avg: {cat_avg:.2f})\")\n    \n    print(\"\\n\" + \"-\"*70)\n    if passed == len(results):\n        print(\"ALL TESTS PASSED - Evaluation Successful!\")\n    elif passed >= len(results) * 0.75:\n        print(\"EVALUATION PASSED - Most tests successful\")\n    else:\n        print(\"EVALUATION PARTIAL - Some tests failed\")\n    print(\"=\"*70)\n    \n    return results\n\n\nprint(\"Evaluation framework ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T18:13:00.675581Z","iopub.execute_input":"2025-12-03T18:13:00.675932Z","iopub.status.idle":"2025-12-03T18:13:00.702683Z","shell.execute_reply.started":"2025-12-03T18:13:00.675909Z","shell.execute_reply":"2025-12-03T18:13:00.701464Z"}},"outputs":[{"name":"stdout","text":"Golden Dataset: 12 test cases\n   â€¢ Happy Path: 4\n   â€¢ Error Handling: 3\n   â€¢ Multi-Agent: 3\n   â€¢ Edge Cases: 2\nEvaluation framework ready\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"---\n\n# Â§8. Execution & Demonstrations\n\nNow let's run the system and demonstrate all capabilities.","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# CELL 12: EXECUTE - Timing Comparison Demo\n# ============================================================================\n\n# Run timing comparison to demonstrate ParallelAgent speedup\ntiming_results = demonstrate_parallel_speedup(\"california\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T18:13:05.722788Z","iopub.execute_input":"2025-12-03T18:13:05.723079Z","iopub.status.idle":"2025-12-03T18:13:08.439144Z","shell.execute_reply.started":"2025-12-03T18:13:05.723053Z","shell.execute_reply":"2025-12-03T18:13:08.437982Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\n  TIMING COMPARISON: Sequential vs Parallel Execution\n======================================================================\n\nRegion: CALIFORNIA\nAPIs: Open-Meteo (weather) + USGS (water) + NASA EONET (disasters)\n\n----------------------------------------------------------------------\n\nðŸ”„ SEQUENTIAL EXECUTION (one after another):\n[2025-12-03T18:13:06] INFO: Weather data fetched for california\n[2025-12-03T18:13:06] INFO: Water level data fetched for california\n[2025-12-03T18:13:07] INFO: Disaster data fetched: 10 events\n   Results: {'weather': 'success', 'water_level': 'success', 'disasters': 'success'}\n   â±ï¸  Total Time: 1603.62ms\n\nâš¡ PARALLEL EXECUTION (concurrent):\n[2025-12-03T18:13:08] INFO: Water level data fetched for california\n[2025-12-03T18:13:08] INFO: Disaster data fetched: 10 events\n[2025-12-03T18:13:08] INFO: Weather data fetched for california\n   Results: {'weather': 'success', 'water_level': 'success', 'disasters': 'success'}\n   Total Time: 607.39ms\n[2025-12-03T18:13:08] INFO: Timing comparison: fetch_california\n\n----------------------------------------------------------------------\n COMPARISON RESULTS:\n----------------------------------------------------------------------\n   Sequential Time: 1603.62ms\n   Parallel Time:   607.39ms\n   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    Speedup:      2.64x faster\n    Time Saved:   996.23ms\n\n======================================================================\n[2025-12-03T18:13:08] DEBUG: A2A: Message msg-3e23d80e from HydroOrchestrator to WeatherAgent\n[2025-12-03T18:13:08] DEBUG: A2A: Message msg-4221232d from HydroOrchestrator to WaterLevelAgent\n[2025-12-03T18:13:08] DEBUG: A2A: Message msg-5f9e8223 from HydroOrchestrator to DisasterAgent\n[2025-12-03T18:13:08] DEBUG: A2A: Message msg-543030a0 from HydroOrchestrator to AlertAgent\n[2025-12-03T18:13:08] DEBUG: A2A: Message msg-6dbe5651 from HydroOrchestrator to AnalysisAgent\n[2025-12-03T18:13:08] INFO: A2A: Broadcast from HydroOrchestrator to 5 agents\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# ============================================================================\n# CELL 13: EXECUTE - Agent Demonstrations\n# ============================================================================\n\nasync def run_demos():\n    \"\"\"Run all agent pattern demonstrations.\"\"\"\n    await ensure_session()\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"AQUA SENTINEL - LIVE DEMONSTRATIONS\")\n    print(\"=\"*70)\n    \n    # Demo 1: ParallelAgent\n    print(\"\\n\" + \"-\"*70)\n    print(\"DEMO 1: ParallelAgent (SentinelAgent)\")\n    print(\"-\"*70)\n    await query_aqua_sentinel(\"What is the current water situation in California?\")\n    \n    await asyncio.sleep(2)\n    \n    # Demo 2: SequentialAgent\n    print(\"\\n\" + \"-\"*70)\n    print(\"DEMO 2: SequentialAgent (GuardianAgent)\")\n    print(\"-\"*70)\n    await query_aqua_sentinel(\"What's the forecast for India? Analyze risks and recommend actions.\")\n    \n    await asyncio.sleep(2)\n    \n    # Demo 3: LoopAgent\n    print(\"\\n\" + \"-\"*70)\n    print(\"DEMO 3: LoopAgent (ResponderAgent)\")\n    print(\"-\"*70)\n    await query_aqua_sentinel(\"Send drought alert to Kenya\")\n    \n    await asyncio.sleep(2)\n    \n    # Demo 4: Global Disasters\n    print(\"\\n\" + \"-\"*70)\n    print(\"DEMO 4: Global Disasters (Direct Tool)\")\n    print(\"-\"*70)\n    await query_aqua_sentinel(\"What disasters are happening globally?\")\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"ALL DEMONSTRATIONS COMPLETE\")\n    print(\"=\"*70)\n\n\nawait run_demos()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T18:13:31.180224Z","iopub.execute_input":"2025-12-03T18:13:31.180588Z","iopub.status.idle":"2025-12-03T18:14:06.691262Z","shell.execute_reply.started":"2025-12-03T18:13:31.180564Z","shell.execute_reply":"2025-12-03T18:14:06.690219Z"}},"outputs":[{"name":"stdout","text":" Session created: session_20251203_181212\n\n======================================================================\nAQUA SENTINEL - LIVE DEMONSTRATIONS\n======================================================================\n\n----------------------------------------------------------------------\nDEMO 1: ParallelAgent (SentinelAgent)\n----------------------------------------------------------------------\n[2025-12-03T18:13:31] INFO: Started trace for: query: What is the current water situation in California?...\n\n======================================================================\n QUERY: What is the current water situation in California?\n Time: 2025-12-03T18:13:31.183889Z\n Trace ID: trace-20251203181331183774\n======================================================================\n[2025-12-03T18:13:34] INFO: Weather data fetched for california\n[2025-12-03T18:13:35] INFO: Water level data fetched for california\n\n RESPONSE:\nI cannot assess the water situation in California using this tool. I can only monitor disasters from NASA EONET. Do you want me to check for any current water-related events globally?\n\nThe water level in the Sacramento River at Freeport, CA is elevated, indicating a flood risk. The gage height is 102.87 ft and the streamflow is 12700 ftÂ³/s.\n\nOK. Here's the current water situation in California, according to the Open-Meteo API:\n\n*   **Temperature:** 7.7Â°C\n*   **7-day Precipitation:** 0mm\n*   **Flood Risk:** LOW\n*   **Drought Risk:** HIGH\n*   **Fetched At:** 2025-12-03T18:13:34.443053Z\n\n\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n OBSERVABILITY SUMMARY\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n   Trace ID: trace-20251203181331183774\n   Total Spans: 3\n   Total Duration: 7551.49ms\n   API Calls: 8\n   Avg Latency: 544.74ms\n   Success Rate: 100.0%\n   Tools Used: nasa_eonet, usgs_water, open_meteo\n\n----------------------------------------------------------------------\nDEMO 2: SequentialAgent (GuardianAgent)\n----------------------------------------------------------------------\n[2025-12-03T18:13:39] INFO: Started trace for: query: What's the forecast for India? Analyze risks and r...\n\n======================================================================\n QUERY: What's the forecast for India? Analyze risks and recommend actions.\n Time: 2025-12-03T18:13:39.250806Z\n Trace ID: trace-20251203181339246541\n======================================================================\n[2025-12-03T18:13:41] INFO: Weather data fetched for India\n\n RESPONSE:\n```text\n---WEATHER_DATA_START---\nRegion: India\nTemperature: 12.6Â°C\n7-Day Precipitation: 0 mm\nFlood Risk: LOW\nDrought Risk: HIGH\nFetched At: 2025-12-03T18:13:41.883491Z\n---WEATHER_DATA_END---\n```\nOkay, I have analyzed the weather data for India.\n\n**Analysis:**\n\n*   **Temperature:** 12.6Â°C is relatively mild.\n*   **Precipitation:** 0mm of precipitation is forecast for the next 7 days. This is very low.\n*   **Flood Risk:** LOW\n*   **Drought Risk:** HIGH\n\nGiven the complete lack of precipitation and HIGH drought risk, water conservation is critical.\n\n**Recommendations:**\n\nðŸ”´ **HIGH PRIORITY:** Implement immediate water conservation measures across all sectors (agriculture, industry, residential). [Cited: 7-Day Precipitation: 0 mm, Drought Risk: HIGH]\n\nðŸŸ¡ **MEDIUM PRIORITY:** Develop and execute a drought management plan. This should include strategies for water rationing, alternative water sources, and public awareness campaigns. [Cited: Drought Risk: HIGH]\n\nðŸŸ¢ **LOW PRIORITY:** Continuously monitor the drought situation and assess the effectiveness of implemented measures. Prepare for potential water shortages and their impacts on agriculture and public health. [Cited: Drought Risk: HIGH, 7-Day Precipitation: 0 mm]\n\n\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n OBSERVABILITY SUMMARY\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n   Trace ID: trace-20251203181339246541\n   Total Spans: 2\n   Total Duration: 7392.65ms\n   API Calls: 9\n   Avg Latency: 550.59ms\n   Success Rate: 100.0%\n   Tools Used: nasa_eonet, usgs_water, open_meteo\n\n----------------------------------------------------------------------\nDEMO 3: LoopAgent (ResponderAgent)\n----------------------------------------------------------------------\n[2025-12-03T18:13:48] INFO: Started trace for: query: Send drought alert to Kenya...\n\n======================================================================\n QUERY: Send drought alert to Kenya\n Time: 2025-12-03T18:13:48.051515Z\n Trace ID: trace-20251203181348049609\n======================================================================\n[2025-12-03T18:13:50] INFO: Alert sent: AQUA-20251203181350-0001 to Kenya\n\n RESPONSE:\nOK. I have sent a high priority drought alert to Kenya. Alert ID is AQUA-20251203181350-0001 and the verification code is VER-181350. The alert will be sent via SMS, MobileApp, Email, and Radio, reaching an estimated 31998586 people.\n\nOkay, I will verify the alert with the following details:\n\n*   **Alert ID:** AQUA-20251203181350-0001\n*   **Verification Code:** VER-181350\n*   **Timestamp:** 2025-12-03T18:13:50.179173Z\n*   **Region:** Kenya\n*   **Channels:** SMS, MobileApp, Email, Radio\n*   **Estimated Reach:** 31998586\n*   **Delivery Status:** QUEUED\\_FOR\\_DELIVERY\n\nHere's the 7-point validation:\n\n*   âœ“ **CHECK 1:** Alert ID exists and is in the correct format.\n*   âœ“ **CHECK 2:** Verification Code exists and is in the correct format.\n*   âœ“ **CHECK 3:** Estimated reach (31998586) > 0.\n*   âœ“ **CHECK 4:** Status is QUEUED\\_FOR\\_DELIVERY.\n*   âœ“ **CHECK 5:** Timestamp is recent (2025-12-03T18:13:50.179173Z).\n*   âœ“ **CHECK 6:** Channels list (SMS, MobileApp, Email, Radio) is not empty.\n*   âœ“ **CHECK 7:** Region (Kenya) matches the request.\n\n**OUTPUT:**\n\nVerification Status: VERIFIED\nChecks Passed: 7/7\n\nOK. The alert has been verified.\n\nOkay, I understand. The alert has been verified.\n\nOK.\n\nAcknowledged.\n\nOK.\n\nUnderstood.\n\nOK.\n\nOK.\n\n\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n OBSERVABILITY SUMMARY\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n   Trace ID: trace-20251203181348049609\n   Total Spans: 2\n   Total Duration: 13358.91ms\n   API Calls: 10\n   Avg Latency: 526.45ms\n   Success Rate: 100.0%\n   Tools Used: nasa_eonet, rest_countries, usgs_water, open_meteo\n\n----------------------------------------------------------------------\nDEMO 4: Global Disasters (Direct Tool)\n----------------------------------------------------------------------\n[2025-12-03T18:14:03] INFO: Started trace for: query: What disasters are happening globally?...\n\n======================================================================\n QUERY: What disasters are happening globally?\n Time: 2025-12-03T18:14:03.105098Z\n Trace ID: trace-20251203181403103048\n======================================================================\n[2025-12-03T18:14:04] INFO: Disaster data fetched: 10 events\n\n RESPONSE:\n**Data Source**: NASA EONET (LIVE) + 2025-12-03T18:14:04.460818Z\n\n**Key Findings**:\n*   **Tropical Cyclone Ditwah** (Severe Storms, Water-Related)\n*   **Typhoon Koto** (Severe Storms, Water-Related)\n*   Multiple wildfires reported in Texas, Oregon, Alabama, Louisiana, North Carolina, Missouri and Virginia.\n\n**Risk Level**: ðŸŸ¡ ORANGE (due to multiple ongoing events)\n\n**Recommendations**: Monitor weather updates and wildfire conditions in affected regions.\n\n\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n OBSERVABILITY SUMMARY\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n   Trace ID: trace-20251203181403103048\n   Total Spans: 2\n   Total Duration: 4062.08ms\n   API Calls: 11\n   Avg Latency: 522.19ms\n   Success Rate: 100.0%\n   Tools Used: nasa_eonet, rest_countries, usgs_water, open_meteo\n\n======================================================================\nALL DEMONSTRATIONS COMPLETE\n======================================================================\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# ============================================================================\n# CELL 14: EXECUTE - Full Evaluation (12 Test Cases)\n# ============================================================================\n\neval_results = await run_evaluation(\"all\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T18:14:14.814592Z","iopub.execute_input":"2025-12-03T18:14:14.814917Z","iopub.status.idle":"2025-12-03T18:15:32.256057Z","shell.execute_reply.started":"2025-12-03T18:14:14.814892Z","shell.execute_reply":"2025-12-03T18:15:32.254881Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\n AQUA SENTINEL EVALUATION FRAMEWORK\n======================================================================\n\n Running 12 tests (subset: all)\n\n Scoring Dimensions:\n   â€¢ Validity (25%): Error-free response\n   â€¢ Relevance (35%): Contains expected elements\n   â€¢ Freshness (20%): Real-time data indicators\n   â€¢ Quality (20%): Response completeness\n   â€¢ Pass Threshold: Overall Score â‰¥ 0.50\n\n----------------------------------------------------------------------\n\n [RT-001] Real-Time Weather\n   Category: happy_path\n   Query: \"What's the current weather in California?\"\n[2025-12-03T18:14:14] INFO: Started trace for: query: What's the current weather in California?...\n[2025-12-03T18:14:18] INFO: Weather data fetched for california\n   â”œâ”€ Validity:  1.00\n   â”œâ”€ Relevance: 1.00\n   â”œâ”€ Freshness: 1.00\n   â”œâ”€ Quality:   1.00\n   â””â”€ Overall:   1.00 PASS\n\n [RT-002] USGS Water Level\n   Category: happy_path\n   Query: \"What are the current water levels in California rivers?\"\n[2025-12-03T18:14:21] INFO: Started trace for: query: What are the current water levels in California ri...\n[2025-12-03T18:14:23] INFO: Water level data fetched for california\n   â”œâ”€ Validity:  1.00\n   â”œâ”€ Relevance: 1.00\n   â”œâ”€ Freshness: 1.00\n   â”œâ”€ Quality:   1.00\n   â””â”€ Overall:   1.00 PASS\n\n [RT-003] NASA Disasters\n   Category: happy_path\n   Query: \"What natural disasters are currently active?\"\n[2025-12-03T18:14:26] INFO: Started trace for: query: What natural disasters are currently active?...\n[2025-12-03T18:14:27] INFO: Disaster data fetched: 10 events\n   â”œâ”€ Validity:  1.00\n   â”œâ”€ Relevance: 0.33\n   â”œâ”€ Freshness: 1.00\n   â”œâ”€ Quality:   1.00\n   â””â”€ Overall:   0.77 PASS\n\n [RT-004] Alert Delivery\n   Category: happy_path\n   Query: \"Send a water conservation alert to India with normal priorit...\"\n[2025-12-03T18:14:30] INFO: Started trace for: query: Send a water conservation alert to India with norm...\n[2025-12-03T18:14:32] INFO: Alert sent: AQUA-20251203181432-0002 to India\n   â”œâ”€ Validity:  1.00\n   â”œâ”€ Relevance: 1.00\n   â”œâ”€ Freshness: 1.00\n   â”œâ”€ Quality:   1.00\n   â””â”€ Overall:   1.00 PASS\n\n [RT-005] Invalid Region Error\n   Category: error_handling\n   Query: \"What's the weather in Atlantis?\"\n[2025-12-03T18:14:43] INFO: Started trace for: query: What's the weather in Atlantis?...\n   â”œâ”€ Validity:  1.00\n   â”œâ”€ Relevance: 0.00\n   â”œâ”€ Freshness: 0.00\n   â”œâ”€ Quality:   0.65\n   â””â”€ Overall:   0.38 FAIL\n\n [RT-006] Non-US Water Level Request\n   Category: error_handling\n   Query: \"What's the water level in Kenya rivers?\"\n[2025-12-03T18:14:45] INFO: Started trace for: query: What's the water level in Kenya rivers?...\n[2025-12-03T18:14:48] INFO: Weather data fetched for kenya\n   â”œâ”€ Validity:  1.00\n   â”œâ”€ Relevance: 0.67\n   â”œâ”€ Freshness: 1.00\n   â”œâ”€ Quality:   1.00\n   â””â”€ Overall:   0.88 PASS\n\n [RT-007] Ambiguous Region Query\n   Category: error_handling\n   Query: \"What's the water situation?\"\n[2025-12-03T18:14:51] INFO: Started trace for: query: What's the water situation?...\n[2025-12-03T18:14:53] INFO: Disaster data fetched: 10 events\n   â”œâ”€ Validity:  1.00\n   â”œâ”€ Relevance: 0.67\n   â”œâ”€ Freshness: 0.00\n   â”œâ”€ Quality:   1.00\n   â””â”€ Overall:   0.68 PASS\n\n [RT-008] Sequential Forecast Analysis\n   Category: multi_agent\n   Query: \"What's the weather forecast for Kenya? Analyze risks and rec...\"\n[2025-12-03T18:14:55] INFO: Started trace for: query: What's the weather forecast for Kenya? Analyze ris...\n[2025-12-03T18:14:58] INFO: Weather data fetched for Kenya\n   â”œâ”€ Validity:  1.00\n   â”œâ”€ Relevance: 1.00\n   â”œâ”€ Freshness: 0.50\n   â”œâ”€ Quality:   1.00\n   â””â”€ Overall:   0.90 PASS\n\n [RT-009] Parallel Regional Monitoring\n   Category: multi_agent\n   Query: \"Give me a complete water situation report for California wit...\"\n[2025-12-03T18:15:02] INFO: Started trace for: query: Give me a complete water situation report for Cali...\n[2025-12-03T18:15:05] INFO: Water level data fetched for california\n[2025-12-03T18:15:06] INFO: Weather data fetched for california\n[2025-12-03T18:15:06] INFO: Disaster data fetched: 10 events\n   â”œâ”€ Validity:  1.00\n   â”œâ”€ Relevance: 1.00\n   â”œâ”€ Freshness: 1.00\n   â”œâ”€ Quality:   1.00\n   â””â”€ Overall:   1.00 PASS\n\n [RT-010] Global Disaster Overview\n   Category: multi_agent\n   Query: \"What natural disasters are happening globally right now? Foc...\"\n[2025-12-03T18:15:09] INFO: Started trace for: query: What natural disasters are happening globally righ...\n[2025-12-03T18:15:11] INFO: Disaster data fetched: 10 events\n   â”œâ”€ Validity:  1.00\n   â”œâ”€ Relevance: 0.00\n   â”œâ”€ Freshness: 1.00\n   â”œâ”€ Quality:   1.00\n   â””â”€ Overall:   0.65 PASS\n\n [RT-011] Emergency High Priority Alert\n   Category: edge_case\n   Query: \"Send an EMERGENCY flood alert to Bangladesh immediately. Cri...\"\n[2025-12-03T18:15:13] INFO: Started trace for: query: Send an EMERGENCY flood alert to Bangladesh immedi...\n[2025-12-03T18:15:16] INFO: Alert sent: AQUA-20251203181515-0003 to Bangladesh\n   â”œâ”€ Validity:  1.00\n   â”œâ”€ Relevance: 1.00\n   â”œâ”€ Freshness: 1.00\n   â”œâ”€ Quality:   1.00\n   â””â”€ Overall:   1.00 PASS\n\n [RT-012] Horn of Africa Drought Region\n   Category: edge_case\n   Query: \"What's the drought situation in Ethiopia? This is for the Ho...\"\n[2025-12-03T18:15:27] INFO: Started trace for: query: What's the drought situation in Ethiopia? This is ...\n[2025-12-03T18:15:29] INFO: Disaster data fetched: 10 events\n[2025-12-03T18:15:30] INFO: Weather data fetched for ethiopia\n   â”œâ”€ Validity:  1.00\n   â”œâ”€ Relevance: 1.00\n   â”œâ”€ Freshness: 1.00\n   â”œâ”€ Quality:   1.00\n   â””â”€ Overall:   1.00 PASS\n\n======================================================================\n EVALUATION RESULTS SUMMARY\n======================================================================\n\n   Tests Passed: 11/12\n   Average Score: 0.85\n   Pass Rate: 91.7%\n\n   Results by Category:\n   â€¢ happy_path: 4/4 passed (avg: 0.94)\n   â€¢ error_handling: 2/3 passed (avg: 0.65)\n   â€¢ multi_agent: 3/3 passed (avg: 0.85)\n   â€¢ edge_case: 2/2 passed (avg: 1.00)\n\n----------------------------------------------------------------------\nEVALUATION PASSED - Most tests successful\n======================================================================\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# ============================================================================\n# CELL 15: ADVANCED CONCEPTS DEMONSTRATION\n# ============================================================================\n\nprint(\"=\"*70)\nprint(\"ADVANCED ADK CONCEPTS SUMMARY\")\nprint(\"=\"*70)\n\n# MCP Server Info\nprint(\"\\nMCP (Model Context Protocol) Server:\")\nmcp_info = mcp_server.get_server_info()\nprint(f\"   Server Name: {mcp_info['name']}\")\nprint(f\"   Version: {mcp_info['version']}\")\nprint(f\"   Tools Registered: {mcp_info['tools_count']}\")\nprint(\"   Available Tools:\")\nfor tool in mcp_server.list_tools():\n    print(f\"      â€¢ {tool['name']}: {tool['description'][:50]}...\")\n\n# Long-Running Operations\nprint(\"\\nLong-Running Operations:\")\n# Create a sample operation\nop_id = lro_manager.create_operation(\"regional_analysis\", {\"region\": \"california\", \"depth\": \"comprehensive\"})\nlro_manager.update_progress(op_id, 50, OperationStatus.RUNNING)\nlro_manager.complete_operation(op_id, {\"status\": \"analysis_complete\", \"findings\": 5})\nop_status = lro_manager.get_status(op_id)\nprint(f\"   Operation ID: {op_status['id']}\")\nprint(f\"   Type: {op_status['type']}\")\nprint(f\"   Status: {op_status['status']}\")\nprint(f\"   Progress: {op_status['progress']}%\")\n\n# A2A Protocol\nprint(\"\\nA2A (Agent-to-Agent) Protocol:\")\na2a_summary = a2a_protocol.get_communication_summary()\nprint(f\"   Registered Agents: {a2a_summary['registered_agents']}\")\nprint(f\"   Total Messages: {a2a_summary['total_messages']}\")\nprint(f\"   Message Types: {a2a_summary['message_types']}\")\nprint(f\"   Agents: {', '.join(a2a_summary['agents'])}\")\n\n# Demonstrate A2A handoff\nprint(\"\\n Demonstrating A2A Task Handoff:\")\nhandoff_msg = a2a_protocol.handoff_task(\n    \"HydroOrchestrator\",\n    \"WeatherAgent\",\n    {\"type\": \"weather_analysis\", \"region\": \"kenya\"},\n    {\"priority\": \"high\", \"reason\": \"drought_monitoring\"}\n)\nprint(f\"   Handoff Message ID: {handoff_msg.id}\")\nprint(f\"   From: {handoff_msg.sender} â†’ To: {handoff_msg.recipient}\")\n\n# Timing Comparisons\nprint(\"\\nTiming Comparisons (Sequential vs Parallel):\")\ntiming_data = observability.get_timing_comparison_summary()\nfor t in timing_data:\n    print(f\"   Operation: {t['operation']}\")\n    print(f\"      Sequential: {t['sequential_ms']:.2f}ms\")\n    print(f\"      Parallel:   {t['parallel_ms']:.2f}ms\")\n    print(f\"      Speedup:    {t['speedup']:.2f}x\")\n\nprint(\"\\n\" + \"=\"*70)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T18:19:08.292320Z","iopub.execute_input":"2025-12-03T18:19:08.292722Z","iopub.status.idle":"2025-12-03T18:19:08.306464Z","shell.execute_reply.started":"2025-12-03T18:19:08.292694Z","shell.execute_reply":"2025-12-03T18:19:08.305463Z"}},"outputs":[{"name":"stdout","text":"======================================================================\nADVANCED ADK CONCEPTS SUMMARY\n======================================================================\n\nMCP (Model Context Protocol) Server:\n   Server Name: aqua-sentinel-mcp\n   Version: 1.0.0\n   Tools Registered: 4\n   Available Tools:\n      â€¢ get_realtime_weather: Fetch real-time weather data from Open-Meteo API...\n      â€¢ get_realtime_water_level: Fetch water level data from USGS...\n      â€¢ get_realtime_disasters: Fetch disaster events from NASA EONET...\n      â€¢ send_water_alert: Send water crisis alert...\n\nLong-Running Operations:\n[2025-12-03T18:19:08] INFO: LRO: Created operation op-700de861 (regional_analysis)\n[2025-12-03T18:19:08] INFO: LRO: Completed operation op-700de861\n   Operation ID: op-700de861\n   Type: regional_analysis\n   Status: completed\n   Progress: 100%\n\nA2A (Agent-to-Agent) Protocol:\n   Registered Agents: 6\n   Total Messages: 5\n   Message Types: ['broadcast']\n   Agents: HydroOrchestrator, WeatherAgent, WaterLevelAgent, DisasterAgent, AlertAgent, AnalysisAgent\n\n Demonstrating A2A Task Handoff:\n[2025-12-03T18:19:08] DEBUG: A2A: Message msg-75030dfb from HydroOrchestrator to WeatherAgent\n[2025-12-03T18:19:08] INFO: A2A: Task handoff from HydroOrchestrator to WeatherAgent\n   Handoff Message ID: msg-75030dfb\n   From: HydroOrchestrator â†’ To: WeatherAgent\n\nTiming Comparisons (Sequential vs Parallel):\n   Operation: fetch_california\n      Sequential: 1603.62ms\n      Parallel:   607.39ms\n      Speedup:    2.64x\n\n======================================================================\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# ============================================================================\n# CELL 16: FINAL OBSERVABILITY DATA\n# ============================================================================\n\nprint(\"=\"*70)\nprint(\"FINAL OBSERVABILITY REPORT\")\nprint(\"=\"*70)\n\n# Metrics Summary\nprint(\"\\nMETRICS SUMMARY:\")\nmetrics = observability.get_metrics_summary()\nfor key, value in metrics.items():\n    print(f\"   {key}: {value}\")\n\n# Recent Trace\nprint(\"\\nMOST RECENT TRACE:\")\ntrace = observability.get_trace_summary()\nfor key, value in trace.items():\n    if key != \"spans\":\n        print(f\"   {key}: {value}\")\n\n# Recent Logs\nprint(\"\\nRECENT LOGS:\")\nfor log in observability.logs[-5:]:\n    print(f\"   [{log['level']}] {log['message']}\")\n\n# Sent Alerts\nprint(\"\\nSENT ALERTS:\")\nfor alert in ALERT_LOG:\n    print(f\"   {alert['alert_id']}: {alert['alert_type']} to {alert['region']} ({alert['priority']})\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"AQUA SENTINEL COMPLETE\")\nprint(\"=\"*70)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T18:19:30.355028Z","iopub.execute_input":"2025-12-03T18:19:30.355429Z","iopub.status.idle":"2025-12-03T18:19:30.364443Z","shell.execute_reply.started":"2025-12-03T18:19:30.355383Z","shell.execute_reply":"2025-12-03T18:19:30.363240Z"}},"outputs":[{"name":"stdout","text":"======================================================================\nFINAL OBSERVABILITY REPORT\n======================================================================\n\nMETRICS SUMMARY:\n   total_api_calls: 25\n   average_latency_ms: 522.72\n   success_rate: 100.0%\n   error_count: 0\n   unique_tools_used: ['nasa_eonet', 'rest_countries', 'usgs_water', 'open_meteo']\n   traces_collected: 16\n   timing_comparisons: 1\n\nMOST RECENT TRACE:\n   trace_id: trace-20251203181527390383\n   operation: query: What's the drought situation in Ethiopia? This is ...\n   total_spans: 3\n   total_duration_ms: 5899.59\n\nRECENT LOGS:\n   [INFO] Weather data fetched for ethiopia\n   [INFO] LRO: Created operation op-700de861 (regional_analysis)\n   [INFO] LRO: Completed operation op-700de861\n   [DEBUG] A2A: Message msg-75030dfb from HydroOrchestrator to WeatherAgent\n   [INFO] A2A: Task handoff from HydroOrchestrator to WeatherAgent\n\nSENT ALERTS:\n   AQUA-20251203181350-0001: drought to Kenya (high)\n   AQUA-20251203181432-0002: conservation to India (normal)\n   AQUA-20251203181515-0003: flood to Bangladesh (emergency)\n\n======================================================================\nAQUA SENTINEL COMPLETE\n======================================================================\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"---\n\n# Â§9. Deployment\n\nAQUA SENTINEL deployment was attempted to **Vertex AI Agent Engine**.\n\n### Deployment Evidence\n- **Platform**: Google Cloud - Vertex AI Agent Engine\n- **Project ID**: `aqua-sentinel-480105`\n- **Region**: `us-central1`\n- **Resource ID**: `projects/127921942048/locations/us-central1/reasoningEngines/4347921975016947712`\n- **Staging Bucket**: `gs://aqua-sentinel-staging`\n\n### Deployment Process\n1. Created GCP project with $300 free credits\n2. Enabled Vertex AI API\n3. Created Cloud Storage staging bucket\n4. Structured agent code for ADK deployment\n5. Executed `adk deploy agent_engine` command\n\n### Deployment Configuration\n```json\n{\n    \"min_instances\": 0,\n    \"max_instances\": 1,\n    \"resource_limits\": {\"cpu\": \"1\", \"memory\": \"1Gi\"}\n}\n```\n\n> **Note**: The agent was created but encountered a startup issue. See [GCP troubleshooting docs](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/troubleshooting/deploy).","metadata":{}},{"cell_type":"markdown","source":"---\n\n# Â§10. Project Journey\n\nThis section documents the development process, challenges overcome, and lessons learned.\n\n---\n\n## ðŸš€ Initial Vision vs. Reality\n\n### Original Architecture (What I Planned)\n\nMy initial design was a **serverless microservices architecture** with AWS Lambda, DynamoDB, and API Gateway. This would have been 40+ files across multiple cloud services.\n\n### The Pivot (What I Built)\n\nWhen I discovered Kaggle's requirement for **single notebook submissions**, I had to completely redesign using ADK patterns:\n- LlmAgent (orchestration)\n- ParallelAgent (concurrent API calls)\n- SequentialAgent (ordered pipelines)\n- LoopAgent (retry mechanisms)\n\n**Lesson learned**: Understand platform constraints BEFORE designing architecture.\n\n---\n\n## ðŸ”§ Challenges Overcome\n\n### Challenge 1: Agent Parent Conflict\n\n**Problem**: ADK requires each agent to have exactly ONE parent. My initial design reused agents across patterns.\n\n**Solution**: Create separate agent instances that share the same tools:\n```python\nweather_agent_sentinel = LlmAgent(name=\"WeatherAgentSentinel\", tools=[get_realtime_weather])\nweather_agent_guardian = LlmAgent(name=\"WeatherAgentGuardian\", tools=[get_realtime_weather])\n```\n\n### Challenge 2: Rate Limiting\n\n**Problem**: Gemini's free tier has 15 requests/minute limit.\n\n**Solution**: Switched to `gemini-2.0-flash` (2000 RPM) and added delays between evaluation tests.\n\n### Challenge 3: Evaluation Consistency\n\n**Problem**: LLM responses vary with each run. Keyword matching failed.\n\n**Solution**: Shifted from keyword matching to **response validation** with multi-dimensional scoring.\n\n---\n\n## ðŸ“š What I Learned\n\n| Topic | Key Insight |\n|-------|------------|\n| **ADK Agent Patterns** | Each pattern has a specific use caseâ€”don't force patterns where they don't fit |\n| **Tool Design** | Tools should do ONE thing well; let the agent orchestrate complexity |\n| **Real APIs vs. Mocks** | Real APIs add credibility but require robust error handling |\n| **Evaluation Design** | Testing LLM outputs requires flexible, semantic evaluation |\n\n---\n\n## ðŸ”„ What I'd Do Differently\n\n| Area | What I Did | What I'd Do Instead |\n|------|-----------|---------------------|\n| **Architecture** | Started with serverless design | Start with notebook-first approach |\n| **API Testing** | Tested APIs after building agents | Test APIs BEFORE any agent code |\n| **Documentation** | Added at the end | Document while building |\n\n---\n\n## ðŸ™ Acknowledgments\n\n- **Google & Kaggle** - For creating this intensive course and capstone opportunity\n- **MrBeast & Mark Rober** - #TeamWater campaign inspired this project's focus\n- **UNICEF, CNN, CDP** - For documenting the Horn of Africa crisis\n- **Open-Meteo, USGS, NASA EONET** - For providing free, accessible APIs\n\n---\n\n## ðŸ“– References\n\n1. UNICEF - Climate and Drought in Horn of Africa: https://www.unicef.org/stories/climate-drought-horn-of-africa\n2. CNN - Horn of Africa Climate Change: https://www.cnn.com/2023/04/27/africa/drought-horn-of-africa-climate-change-intl\n3. Center for Disaster Philanthropy: https://disasterphilanthropy.org/disasters/horn-of-africa-hunger-crisis/\n4. #TeamWater Campaign: https://teamwater.org\n5. Google ADK Documentation: https://google.github.io/adk-docs/\n6. Vertex AI Agent Engine: https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/overview\n7. Model Context Protocol: https://modelcontextprotocol.io/\n\n---\n\n## ðŸ‘¨â€ðŸ’» Author\n\n**Jai Adithya Ram Nayani**  \nComputer Science Master's Student  \nKaggle AI Agents Intensive 2025\n\n---","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}