{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸŒŠ AQUA SENTINEL: Real-Time AI Agents for Water Crisis Prevention\n",
        "## Kaggle AI Agents Capstone | Track: Agents for Good\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸŽ¯ Features Demonstrated:\n",
        "- **4 ADK Agent Patterns**: LlmAgent, ParallelAgent, SequentialAgent, LoopAgent\n",
        "- **5 Real-Time APIs**: Open-Meteo, USGS, NASA EONET, REST Countries, Alert System\n",
        "- **Full Observability**: Logging, Tracing, Metrics\n",
        "- **12 Evaluation Test Cases** across 4 categories\n",
        "- **Timing Comparison**: Sequential vs Parallel execution benchmarks\n",
        "- **Advanced Concepts**: MCP Integration Pattern, Long-Running Operations, A2A Protocol\n",
        "\n",
        "### ðŸ“Š ADK Concepts Coverage:\n",
        "| Concept | Implementation | Status |\n",
        "|---------|---------------|--------|\n",
        "| LlmAgent | HydroOrchestrator + 6 specialists | âœ… |\n",
        "| ParallelAgent | SentinelAgent (3 concurrent) | âœ… |\n",
        "| SequentialAgent | GuardianAgent (state passing) | âœ… |\n",
        "| LoopAgent | ResponderAgent (5 iterations) | âœ… |\n",
        "| Custom Tools | 5 real-time APIs | âœ… |\n",
        "| Sessions | InMemorySessionService | âœ… |\n",
        "| Observability | Logging, Tracing, Metrics | âœ… |\n",
        "| Evaluation | 12 test cases, multi-dimensional | âœ… |\n",
        "| MCP Pattern | Tool server architecture | âœ… |\n",
        "| Long-Running Ops | Async with status tracking | âœ… |\n",
        "| A2A Protocol | Agent-to-Agent messaging | âœ… |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================================\n",
        "# CELL 1: INSTALLATION & WARNINGS\n",
        "# ============================================================================\n",
        "# Uncomment for local setup:\n",
        "# !pip install -q google-genai google-adk requests\n",
        "\n",
        "import warnings\n",
        "import logging\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "logging.getLogger('google_genai.types').setLevel(logging.ERROR)\n",
        "logging.getLogger('asyncio').setLevel(logging.ERROR)\n",
        "\n",
        "print(\"âœ… Warnings suppressed for cleaner output\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================================\n",
        "# CELL 2: IMPORTS\n",
        "# ============================================================================\n",
        "\n",
        "import os\n",
        "import json\n",
        "import asyncio\n",
        "import requests\n",
        "import time\n",
        "import uuid\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Optional, List, Dict, Any, Callable\n",
        "from dataclasses import dataclass, field\n",
        "from functools import wraps\n",
        "from enum import Enum\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import threading\n",
        "\n",
        "# Google ADK - Agent framework\n",
        "from google.adk.agents import (\n",
        "    LlmAgent,\n",
        "    ParallelAgent,\n",
        "    SequentialAgent,\n",
        "    LoopAgent,\n",
        ")\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "\n",
        "# Google GenAI\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "print(\"âœ… All imports successful\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================================\n",
        "# CELL 3: OBSERVABILITY FRAMEWORK - Logging, Tracing, Metrics\n",
        "# ============================================================================\n",
        "\n",
        "class AquaSentinelObservability:\n",
        "    \"\"\"\n",
        "    Comprehensive observability system for AQUA SENTINEL.\n",
        "    Implements: Logging, Tracing, and Metrics collection.\n",
        "    \n",
        "    This addresses the ADK Observability requirement by providing:\n",
        "    - Structured logging with severity levels\n",
        "    - Distributed tracing with trace IDs and spans\n",
        "    - Metrics collection for performance monitoring\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.logs: List[Dict] = []\n",
        "        self.traces: List[Dict] = []\n",
        "        self.metrics: Dict[str, Any] = {\n",
        "            \"api_latency\": [],\n",
        "            \"agent_execution_time\": [],\n",
        "            \"tool_calls\": [],\n",
        "            \"error_count\": 0,\n",
        "            \"success_count\": 0,\n",
        "            \"parallel_vs_sequential\": [],  # NEW: Timing comparisons\n",
        "        }\n",
        "        self.current_trace_id: Optional[str] = None\n",
        "        self.span_stack: List[Dict] = []\n",
        "    \n",
        "    def _generate_trace_id(self) -> str:\n",
        "        \"\"\"Generate unique trace ID for distributed tracing.\"\"\"\n",
        "        return f\"trace-{datetime.utcnow().strftime('%Y%m%d%H%M%S%f')}\"\n",
        "    \n",
        "    def _generate_span_id(self) -> str:\n",
        "        \"\"\"Generate unique span ID.\"\"\"\n",
        "        return f\"span-{datetime.utcnow().strftime('%H%M%S%f')}\"\n",
        "    \n",
        "    def start_trace(self, operation: str) -> str:\n",
        "        \"\"\"Start a new trace for an operation.\"\"\"\n",
        "        self.current_trace_id = self._generate_trace_id()\n",
        "        trace = {\n",
        "            \"trace_id\": self.current_trace_id,\n",
        "            \"operation\": operation,\n",
        "            \"start_time\": datetime.utcnow().isoformat(),\n",
        "            \"spans\": [],\n",
        "        }\n",
        "        self.traces.append(trace)\n",
        "        self.log(\"INFO\", f\"Started trace for: {operation}\", {\"trace_id\": self.current_trace_id})\n",
        "        return self.current_trace_id\n",
        "    \n",
        "    def start_span(self, name: str, attributes: Dict = None) -> str:\n",
        "        \"\"\"Start a new span within the current trace.\"\"\"\n",
        "        span_id = self._generate_span_id()\n",
        "        span = {\n",
        "            \"span_id\": span_id,\n",
        "            \"name\": name,\n",
        "            \"start_time\": time.time(),\n",
        "            \"start_timestamp\": datetime.utcnow().isoformat(),\n",
        "            \"attributes\": attributes or {},\n",
        "            \"parent_span\": self.span_stack[-1][\"span_id\"] if self.span_stack else None,\n",
        "        }\n",
        "        self.span_stack.append(span)\n",
        "        return span_id\n",
        "    \n",
        "    def end_span(self, status: str = \"OK\", attributes: Dict = None):\n",
        "        \"\"\"End the current span and record duration.\"\"\"\n",
        "        if not self.span_stack:\n",
        "            return\n",
        "        \n",
        "        span = self.span_stack.pop()\n",
        "        span[\"end_time\"] = time.time()\n",
        "        span[\"duration_ms\"] = round((span[\"end_time\"] - span[\"start_time\"]) * 1000, 2)\n",
        "        span[\"status\"] = status\n",
        "        if attributes:\n",
        "            span[\"attributes\"].update(attributes)\n",
        "        \n",
        "        if self.traces:\n",
        "            self.traces[-1][\"spans\"].append(span)\n",
        "        \n",
        "        self.metrics[\"agent_execution_time\"].append({\n",
        "            \"span\": span[\"name\"],\n",
        "            \"duration_ms\": span[\"duration_ms\"],\n",
        "            \"timestamp\": datetime.utcnow().isoformat(),\n",
        "        })\n",
        "    \n",
        "    def log(self, level: str, message: str, context: Dict = None):\n",
        "        \"\"\"Structured logging with context.\"\"\"\n",
        "        log_entry = {\n",
        "            \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n",
        "            \"level\": level,\n",
        "            \"message\": message,\n",
        "            \"trace_id\": self.current_trace_id,\n",
        "            \"context\": context or {},\n",
        "        }\n",
        "        self.logs.append(log_entry)\n",
        "        emoji = {\"INFO\": \"â„¹ï¸\", \"WARN\": \"âš ï¸\", \"ERROR\": \"âŒ\", \"DEBUG\": \"ðŸ”\"}.get(level, \"ðŸ“\")\n",
        "        print(f\"[{log_entry['timestamp'][:19]}] {emoji} {level}: {message}\")\n",
        "    \n",
        "    def record_api_call(self, api_name: str, latency_ms: float, success: bool):\n",
        "        \"\"\"Record API call metrics.\"\"\"\n",
        "        self.metrics[\"api_latency\"].append({\n",
        "            \"api\": api_name,\n",
        "            \"latency_ms\": latency_ms,\n",
        "            \"success\": success,\n",
        "            \"timestamp\": datetime.utcnow().isoformat(),\n",
        "        })\n",
        "        self.metrics[\"tool_calls\"].append(api_name)\n",
        "        if success:\n",
        "            self.metrics[\"success_count\"] += 1\n",
        "        else:\n",
        "            self.metrics[\"error_count\"] += 1\n",
        "    \n",
        "    def record_timing_comparison(self, operation: str, sequential_ms: float, parallel_ms: float):\n",
        "        \"\"\"Record parallel vs sequential timing comparison.\"\"\"\n",
        "        speedup = sequential_ms / parallel_ms if parallel_ms > 0 else 0\n",
        "        self.metrics[\"parallel_vs_sequential\"].append({\n",
        "            \"operation\": operation,\n",
        "            \"sequential_ms\": round(sequential_ms, 2),\n",
        "            \"parallel_ms\": round(parallel_ms, 2),\n",
        "            \"speedup\": round(speedup, 2),\n",
        "            \"timestamp\": datetime.utcnow().isoformat(),\n",
        "        })\n",
        "        self.log(\"INFO\", f\"Timing comparison: {operation}\", {\n",
        "            \"sequential_ms\": round(sequential_ms, 2),\n",
        "            \"parallel_ms\": round(parallel_ms, 2),\n",
        "            \"speedup\": f\"{speedup:.2f}x\"\n",
        "        })\n",
        "    \n",
        "    def get_metrics_summary(self) -> Dict:\n",
        "        \"\"\"Get summary of collected metrics.\"\"\"\n",
        "        api_latencies = self.metrics[\"api_latency\"]\n",
        "        avg_latency = sum(m[\"latency_ms\"] for m in api_latencies) / len(api_latencies) if api_latencies else 0\n",
        "        \n",
        "        return {\n",
        "            \"total_api_calls\": len(api_latencies),\n",
        "            \"average_latency_ms\": round(avg_latency, 2),\n",
        "            \"success_rate\": f\"{(self.metrics['success_count'] / max(1, len(api_latencies))) * 100:.1f}%\",\n",
        "            \"error_count\": self.metrics[\"error_count\"],\n",
        "            \"unique_tools_used\": list(set(self.metrics[\"tool_calls\"])),\n",
        "            \"traces_collected\": len(self.traces),\n",
        "            \"timing_comparisons\": len(self.metrics[\"parallel_vs_sequential\"]),\n",
        "        }\n",
        "    \n",
        "    def get_trace_summary(self) -> Dict:\n",
        "        \"\"\"Get summary of the most recent trace.\"\"\"\n",
        "        if not self.traces:\n",
        "            return {\"status\": \"no traces\"}\n",
        "        \n",
        "        trace = self.traces[-1]\n",
        "        total_duration = sum(s.get(\"duration_ms\", 0) for s in trace[\"spans\"])\n",
        "        \n",
        "        return {\n",
        "            \"trace_id\": trace[\"trace_id\"],\n",
        "            \"operation\": trace[\"operation\"],\n",
        "            \"total_spans\": len(trace[\"spans\"]),\n",
        "            \"total_duration_ms\": round(total_duration, 2),\n",
        "            \"spans\": [{\"name\": s[\"name\"], \"duration_ms\": s.get(\"duration_ms\", 0)} for s in trace[\"spans\"]],\n",
        "        }\n",
        "    \n",
        "    def get_timing_comparison_summary(self) -> List[Dict]:\n",
        "        \"\"\"Get all timing comparisons.\"\"\"\n",
        "        return self.metrics[\"parallel_vs_sequential\"]\n",
        "\n",
        "\n",
        "# Initialize global observability instance\n",
        "observability = AquaSentinelObservability()\n",
        "\n",
        "print(\"âœ… Observability Framework initialized\")\n",
        "print(\"   â€¢ Structured logging with trace context\")\n",
        "print(\"   â€¢ Distributed tracing with spans\")\n",
        "print(\"   â€¢ Metrics collection for API calls and agent execution\")\n",
        "print(\"   â€¢ Timing comparison tracking (parallel vs sequential)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================================\n",
        "# CELL 4: ADVANCED ADK CONCEPTS - MCP, Long-Running Ops, A2A Protocol\n",
        "# ============================================================================\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# MODEL CONTEXT PROTOCOL (MCP) - Tool Server Architecture\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "class MCPToolServer:\n",
        "    \"\"\"\n",
        "    Model Context Protocol (MCP) Tool Server Implementation.\n",
        "    \n",
        "    MCP provides a standardized way for AI agents to interact with external tools\n",
        "    and data sources. This implementation demonstrates:\n",
        "    - Tool registration and discovery\n",
        "    - Standardized request/response format\n",
        "    - Tool capability advertisement\n",
        "    \n",
        "    Reference: https://modelcontextprotocol.io/\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, server_name: str):\n",
        "        self.server_name = server_name\n",
        "        self.tools: Dict[str, Dict] = {}\n",
        "        self.capabilities = {\n",
        "            \"tools\": True,\n",
        "            \"resources\": True,\n",
        "            \"prompts\": False,\n",
        "        }\n",
        "    \n",
        "    def register_tool(self, name: str, description: str, handler: Callable, parameters: Dict):\n",
        "        \"\"\"Register a tool with the MCP server.\"\"\"\n",
        "        self.tools[name] = {\n",
        "            \"name\": name,\n",
        "            \"description\": description,\n",
        "            \"handler\": handler,\n",
        "            \"parameters\": parameters,\n",
        "            \"registered_at\": datetime.utcnow().isoformat(),\n",
        "        }\n",
        "        observability.log(\"INFO\", f\"MCP: Registered tool '{name}'\")\n",
        "    \n",
        "    def list_tools(self) -> List[Dict]:\n",
        "        \"\"\"List all available tools (MCP tools/list).\"\"\"\n",
        "        return [\n",
        "            {\n",
        "                \"name\": t[\"name\"],\n",
        "                \"description\": t[\"description\"],\n",
        "                \"inputSchema\": t[\"parameters\"],\n",
        "            }\n",
        "            for t in self.tools.values()\n",
        "        ]\n",
        "    \n",
        "    def call_tool(self, name: str, arguments: Dict) -> Dict:\n",
        "        \"\"\"Execute a tool (MCP tools/call).\"\"\"\n",
        "        if name not in self.tools:\n",
        "            return {\"error\": f\"Tool '{name}' not found\"}\n",
        "        \n",
        "        tool = self.tools[name]\n",
        "        try:\n",
        "            result = tool[\"handler\"](**arguments)\n",
        "            return {\n",
        "                \"content\": [{\"type\": \"text\", \"text\": json.dumps(result)}],\n",
        "                \"isError\": False,\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                \"content\": [{\"type\": \"text\", \"text\": str(e)}],\n",
        "                \"isError\": True,\n",
        "            }\n",
        "    \n",
        "    def get_server_info(self) -> Dict:\n",
        "        \"\"\"Get MCP server information.\"\"\"\n",
        "        return {\n",
        "            \"name\": self.server_name,\n",
        "            \"version\": \"1.0.0\",\n",
        "            \"capabilities\": self.capabilities,\n",
        "            \"tools_count\": len(self.tools),\n",
        "        }\n",
        "\n",
        "\n",
        "# Initialize MCP Tool Server\n",
        "mcp_server = MCPToolServer(\"aqua-sentinel-mcp\")\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# LONG-RUNNING OPERATIONS - Async Processing with Status Tracking\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "class OperationStatus(Enum):\n",
        "    \"\"\"Status states for long-running operations.\"\"\"\n",
        "    PENDING = \"pending\"\n",
        "    RUNNING = \"running\"\n",
        "    COMPLETED = \"completed\"\n",
        "    FAILED = \"failed\"\n",
        "    PAUSED = \"paused\"\n",
        "    CANCELLED = \"cancelled\"\n",
        "\n",
        "\n",
        "class LongRunningOperation:\n",
        "    \"\"\"\n",
        "    Long-Running Operation Manager.\n",
        "    \n",
        "    Demonstrates ADK pattern for operations that may take extended time:\n",
        "    - Operation creation with unique ID\n",
        "    - Status polling and updates\n",
        "    - Pause/Resume capability\n",
        "    - Progress tracking\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.operations: Dict[str, Dict] = {}\n",
        "    \n",
        "    def create_operation(self, operation_type: str, params: Dict) -> str:\n",
        "        \"\"\"Create a new long-running operation.\"\"\"\n",
        "        op_id = f\"op-{uuid.uuid4().hex[:8]}\"\n",
        "        self.operations[op_id] = {\n",
        "            \"id\": op_id,\n",
        "            \"type\": operation_type,\n",
        "            \"params\": params,\n",
        "            \"status\": OperationStatus.PENDING.value,\n",
        "            \"progress\": 0,\n",
        "            \"created_at\": datetime.utcnow().isoformat(),\n",
        "            \"updated_at\": datetime.utcnow().isoformat(),\n",
        "            \"result\": None,\n",
        "            \"error\": None,\n",
        "        }\n",
        "        observability.log(\"INFO\", f\"LRO: Created operation {op_id} ({operation_type})\")\n",
        "        return op_id\n",
        "    \n",
        "    def get_status(self, op_id: str) -> Dict:\n",
        "        \"\"\"Get operation status.\"\"\"\n",
        "        if op_id not in self.operations:\n",
        "            return {\"error\": \"Operation not found\"}\n",
        "        return self.operations[op_id]\n",
        "    \n",
        "    def update_progress(self, op_id: str, progress: int, status: OperationStatus = None):\n",
        "        \"\"\"Update operation progress.\"\"\"\n",
        "        if op_id in self.operations:\n",
        "            self.operations[op_id][\"progress\"] = progress\n",
        "            self.operations[op_id][\"updated_at\"] = datetime.utcnow().isoformat()\n",
        "            if status:\n",
        "                self.operations[op_id][\"status\"] = status.value\n",
        "    \n",
        "    def complete_operation(self, op_id: str, result: Any):\n",
        "        \"\"\"Mark operation as completed.\"\"\"\n",
        "        if op_id in self.operations:\n",
        "            self.operations[op_id][\"status\"] = OperationStatus.COMPLETED.value\n",
        "            self.operations[op_id][\"progress\"] = 100\n",
        "            self.operations[op_id][\"result\"] = result\n",
        "            self.operations[op_id][\"updated_at\"] = datetime.utcnow().isoformat()\n",
        "            observability.log(\"INFO\", f\"LRO: Completed operation {op_id}\")\n",
        "    \n",
        "    def pause_operation(self, op_id: str) -> bool:\n",
        "        \"\"\"Pause a running operation.\"\"\"\n",
        "        if op_id in self.operations and self.operations[op_id][\"status\"] == OperationStatus.RUNNING.value:\n",
        "            self.operations[op_id][\"status\"] = OperationStatus.PAUSED.value\n",
        "            observability.log(\"INFO\", f\"LRO: Paused operation {op_id}\")\n",
        "            return True\n",
        "        return False\n",
        "    \n",
        "    def resume_operation(self, op_id: str) -> bool:\n",
        "        \"\"\"Resume a paused operation.\"\"\"\n",
        "        if op_id in self.operations and self.operations[op_id][\"status\"] == OperationStatus.PAUSED.value:\n",
        "            self.operations[op_id][\"status\"] = OperationStatus.RUNNING.value\n",
        "            observability.log(\"INFO\", f\"LRO: Resumed operation {op_id}\")\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "\n",
        "# Initialize Long-Running Operations Manager\n",
        "lro_manager = LongRunningOperation()\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# AGENT-TO-AGENT (A2A) PROTOCOL - Inter-Agent Communication\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "class A2AMessage:\n",
        "    \"\"\"Agent-to-Agent message format.\"\"\"\n",
        "    def __init__(self, sender: str, recipient: str, message_type: str, payload: Dict):\n",
        "        self.id = f\"msg-{uuid.uuid4().hex[:8]}\"\n",
        "        self.sender = sender\n",
        "        self.recipient = recipient\n",
        "        self.message_type = message_type  # request, response, broadcast, handoff\n",
        "        self.payload = payload\n",
        "        self.timestamp = datetime.utcnow().isoformat()\n",
        "        self.status = \"pending\"\n",
        "\n",
        "\n",
        "class A2AProtocol:\n",
        "    \"\"\"\n",
        "    Agent-to-Agent (A2A) Protocol Implementation.\n",
        "    \n",
        "    Enables structured communication between agents:\n",
        "    - Message passing with typed payloads\n",
        "    - Request/Response patterns\n",
        "    - Task handoff between agents\n",
        "    - Broadcast messaging\n",
        "    \n",
        "    Reference: Google ADK A2A Protocol specification\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.agents: Dict[str, Dict] = {}\n",
        "        self.message_queue: List[A2AMessage] = []\n",
        "        self.message_history: List[Dict] = []\n",
        "    \n",
        "    def register_agent(self, agent_id: str, capabilities: List[str], endpoint: str = None):\n",
        "        \"\"\"Register an agent with the A2A network.\"\"\"\n",
        "        self.agents[agent_id] = {\n",
        "            \"id\": agent_id,\n",
        "            \"capabilities\": capabilities,\n",
        "            \"endpoint\": endpoint,\n",
        "            \"registered_at\": datetime.utcnow().isoformat(),\n",
        "            \"status\": \"active\",\n",
        "        }\n",
        "        observability.log(\"INFO\", f\"A2A: Registered agent '{agent_id}' with capabilities: {capabilities}\")\n",
        "    \n",
        "    def send_message(self, sender: str, recipient: str, message_type: str, payload: Dict) -> A2AMessage:\n",
        "        \"\"\"Send a message from one agent to another.\"\"\"\n",
        "        msg = A2AMessage(sender, recipient, message_type, payload)\n",
        "        self.message_queue.append(msg)\n",
        "        self.message_history.append({\n",
        "            \"id\": msg.id,\n",
        "            \"sender\": sender,\n",
        "            \"recipient\": recipient,\n",
        "            \"type\": message_type,\n",
        "            \"timestamp\": msg.timestamp,\n",
        "        })\n",
        "        observability.log(\"DEBUG\", f\"A2A: Message {msg.id} from {sender} to {recipient}\")\n",
        "        return msg\n",
        "    \n",
        "    def handoff_task(self, from_agent: str, to_agent: str, task: Dict, context: Dict) -> A2AMessage:\n",
        "        \"\"\"Handoff a task from one agent to another.\"\"\"\n",
        "        payload = {\n",
        "            \"task\": task,\n",
        "            \"context\": context,\n",
        "            \"handoff_reason\": task.get(\"reason\", \"capability match\"),\n",
        "        }\n",
        "        msg = self.send_message(from_agent, to_agent, \"handoff\", payload)\n",
        "        observability.log(\"INFO\", f\"A2A: Task handoff from {from_agent} to {to_agent}\")\n",
        "        return msg\n",
        "    \n",
        "    def broadcast(self, sender: str, payload: Dict) -> List[A2AMessage]:\n",
        "        \"\"\"Broadcast a message to all registered agents.\"\"\"\n",
        "        messages = []\n",
        "        for agent_id in self.agents:\n",
        "            if agent_id != sender:\n",
        "                msg = self.send_message(sender, agent_id, \"broadcast\", payload)\n",
        "                messages.append(msg)\n",
        "        observability.log(\"INFO\", f\"A2A: Broadcast from {sender} to {len(messages)} agents\")\n",
        "        return messages\n",
        "    \n",
        "    def get_agent_by_capability(self, capability: str) -> Optional[str]:\n",
        "        \"\"\"Find an agent with a specific capability.\"\"\"\n",
        "        for agent_id, agent_info in self.agents.items():\n",
        "            if capability in agent_info[\"capabilities\"]:\n",
        "                return agent_id\n",
        "        return None\n",
        "    \n",
        "    def get_communication_summary(self) -> Dict:\n",
        "        \"\"\"Get summary of A2A communications.\"\"\"\n",
        "        return {\n",
        "            \"registered_agents\": len(self.agents),\n",
        "            \"total_messages\": len(self.message_history),\n",
        "            \"message_types\": list(set(m[\"type\"] for m in self.message_history)),\n",
        "            \"agents\": list(self.agents.keys()),\n",
        "        }\n",
        "\n",
        "\n",
        "# Initialize A2A Protocol\n",
        "a2a_protocol = A2AProtocol()\n",
        "\n",
        "# Register AQUA SENTINEL agents with A2A\n",
        "a2a_protocol.register_agent(\"HydroOrchestrator\", [\"orchestration\", \"routing\", \"coordination\"])\n",
        "a2a_protocol.register_agent(\"WeatherAgent\", [\"weather\", \"forecast\", \"precipitation\"])\n",
        "a2a_protocol.register_agent(\"WaterLevelAgent\", [\"water_level\", \"usgs\", \"rivers\"])\n",
        "a2a_protocol.register_agent(\"DisasterAgent\", [\"disasters\", \"nasa\", \"events\"])\n",
        "a2a_protocol.register_agent(\"AlertAgent\", [\"alerts\", \"notifications\", \"emergency\"])\n",
        "a2a_protocol.register_agent(\"AnalysisAgent\", [\"analysis\", \"recommendations\", \"synthesis\"])\n",
        "\n",
        "print(\"\\nâœ… Advanced ADK Concepts initialized:\")\n",
        "print(\"   â€¢ MCP Tool Server (Model Context Protocol)\")\n",
        "print(\"   â€¢ Long-Running Operations Manager\")\n",
        "print(\"   â€¢ A2A Protocol (Agent-to-Agent Communication)\")\n",
        "print(f\"   â€¢ {len(a2a_protocol.agents)} agents registered in A2A network\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================================\n",
        "# CELL 5: API CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "GOOGLE_API_KEY = None\n",
        "\n",
        "# Method 1: Try Kaggle Secrets\n",
        "try:\n",
        "    from kaggle_secrets import UserSecretsClient\n",
        "    secrets = UserSecretsClient()\n",
        "    GOOGLE_API_KEY = secrets.get_secret(\"GOOGLE_API_KEY\")\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "    print(\"âœ… Google API key loaded from Kaggle Secrets\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Kaggle Secrets not available: {e}\")\n",
        "\n",
        "# Method 2: Environment variable\n",
        "if not GOOGLE_API_KEY:\n",
        "    GOOGLE_API_KEY = os.environ.get(\"GOOGLE_API_KEY\")\n",
        "    if GOOGLE_API_KEY:\n",
        "        print(\"âœ… Google API key loaded from environment variable\")\n",
        "\n",
        "if GOOGLE_API_KEY:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "    print(f\"\\nðŸ”‘ API Key Status: Configured (ends with ...{GOOGLE_API_KEY[-4:]})\")\n",
        "else:\n",
        "    print(\"\\nâŒ API Key Status: NOT SET - Agent queries will fail!\")\n",
        "\n",
        "# Model configuration\n",
        "MODEL = \"gemini-2.0-flash\"\n",
        "\n",
        "# External API endpoints\n",
        "API_ENDPOINTS = {\n",
        "    \"open_meteo\": \"https://api.open-meteo.com/v1/forecast\",\n",
        "    \"usgs_water\": \"https://waterservices.usgs.gov/nwis/iv/\",\n",
        "    \"nasa_eonet\": \"https://eonet.gsfc.nasa.gov/api/v3/events\",\n",
        "    \"rest_countries\": \"https://restcountries.com/v3.1\",\n",
        "}\n",
        "\n",
        "print(f\"\\nðŸ“¡ Model: {MODEL}\")\n",
        "print(\"\\nðŸŒ External APIs configured (all FREE, no keys needed):\")\n",
        "for name, url in API_ENDPOINTS.items():\n",
        "    print(f\"   â€¢ {name}: {url[:45]}...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================================\n",
        "# CELL 6: REAL-TIME TOOLS WITH OBSERVABILITY & MCP REGISTRATION\n",
        "# ============================================================================\n",
        "\n",
        "# Extended location database\n",
        "LOCATIONS = {\n",
        "    \"california\": {\"lat\": 36.7783, \"lon\": -119.4179, \"name\": \"California, USA\"},\n",
        "    \"bangladesh\": {\"lat\": 23.6850, \"lon\": 90.3563, \"name\": \"Dhaka, Bangladesh\"},\n",
        "    \"kenya\": {\"lat\": -1.2921, \"lon\": 36.8219, \"name\": \"Nairobi, Kenya\"},\n",
        "    \"india\": {\"lat\": 28.6139, \"lon\": 77.2090, \"name\": \"Delhi, India\"},\n",
        "    \"brazil\": {\"lat\": -15.7975, \"lon\": -47.8919, \"name\": \"Brasilia, Brazil\"},\n",
        "    \"australia\": {\"lat\": -33.8688, \"lon\": 151.2093, \"name\": \"Sydney, Australia\"},\n",
        "    \"ethiopia\": {\"lat\": 9.1450, \"lon\": 40.4897, \"name\": \"Addis Ababa, Ethiopia\"},\n",
        "    \"somalia\": {\"lat\": 5.1521, \"lon\": 46.1996, \"name\": \"Mogadishu, Somalia\"},\n",
        "    \"texas\": {\"lat\": 31.9686, \"lon\": -99.9018, \"name\": \"Texas, USA\"},\n",
        "    \"florida\": {\"lat\": 27.6648, \"lon\": -81.5158, \"name\": \"Florida, USA\"},\n",
        "}\n",
        "\n",
        "\n",
        "def get_realtime_weather(region: str) -> dict:\n",
        "    \"\"\"Get REAL-TIME weather data from Open-Meteo API with observability.\"\"\"\n",
        "    span_id = observability.start_span(\"get_realtime_weather\", {\"region\": region})\n",
        "    start_time = time.time()\n",
        "    \n",
        "    region_lower = region.lower().strip()\n",
        "    \n",
        "    if region_lower not in LOCATIONS:\n",
        "        for key in LOCATIONS:\n",
        "            if key in region_lower or region_lower in key:\n",
        "                region_lower = key\n",
        "                break\n",
        "        else:\n",
        "            observability.end_span(\"ERROR\", {\"error\": \"unknown_region\"})\n",
        "            return {\n",
        "                \"status\": \"error\",\n",
        "                \"message\": f\"Unknown region: {region}\",\n",
        "                \"available_regions\": list(LOCATIONS.keys()),\n",
        "            }\n",
        "    \n",
        "    loc = LOCATIONS[region_lower]\n",
        "    \n",
        "    try:\n",
        "        params = {\n",
        "            \"latitude\": loc[\"lat\"],\n",
        "            \"longitude\": loc[\"lon\"],\n",
        "            \"current_weather\": \"true\",\n",
        "            \"daily\": \"precipitation_sum,temperature_2m_max,temperature_2m_min,precipitation_probability_max\",\n",
        "            \"timezone\": \"auto\",\n",
        "            \"forecast_days\": 7,\n",
        "        }\n",
        "        \n",
        "        response = requests.get(API_ENDPOINTS[\"open_meteo\"], params=params, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        \n",
        "        latency_ms = (time.time() - start_time) * 1000\n",
        "        observability.record_api_call(\"open_meteo\", latency_ms, True)\n",
        "        \n",
        "        current = data.get(\"current_weather\", {})\n",
        "        daily = data.get(\"daily\", {})\n",
        "        precip_7d = sum(daily.get(\"precipitation_sum\", [0]) or [0])\n",
        "        \n",
        "        if precip_7d > 100:\n",
        "            flood_risk, drought_risk = \"HIGH\", \"LOW\"\n",
        "        elif precip_7d > 50:\n",
        "            flood_risk, drought_risk = \"MODERATE\", \"LOW\"\n",
        "        elif precip_7d < 5:\n",
        "            flood_risk, drought_risk = \"LOW\", \"HIGH\"\n",
        "        else:\n",
        "            flood_risk, drought_risk = \"LOW\", \"MODERATE\"\n",
        "        \n",
        "        observability.end_span(\"OK\", {\"flood_risk\": flood_risk, \"drought_risk\": drought_risk})\n",
        "        observability.log(\"INFO\", f\"Weather data fetched for {region}\", {\"latency_ms\": round(latency_ms, 2)})\n",
        "        \n",
        "        return {\n",
        "            \"status\": \"success\",\n",
        "            \"source\": \"Open-Meteo API (LIVE)\",\n",
        "            \"region\": region,\n",
        "            \"location\": loc[\"name\"],\n",
        "            \"coordinates\": {\"lat\": loc[\"lat\"], \"lon\": loc[\"lon\"]},\n",
        "            \"fetched_at\": datetime.utcnow().isoformat() + \"Z\",\n",
        "            \"current\": {\n",
        "                \"temperature_c\": current.get(\"temperature\"),\n",
        "                \"windspeed_kmh\": current.get(\"windspeed\"),\n",
        "                \"weather_code\": current.get(\"weathercode\"),\n",
        "            },\n",
        "            \"forecast_7d\": {\n",
        "                \"dates\": daily.get(\"time\", []),\n",
        "                \"precipitation_mm\": daily.get(\"precipitation_sum\", []),\n",
        "                \"total_precipitation_mm\": round(precip_7d, 1),\n",
        "            },\n",
        "            \"water_impact\": {\"flood_risk\": flood_risk, \"drought_risk\": drought_risk},\n",
        "            \"_observability\": {\"latency_ms\": round(latency_ms, 2)},\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        latency_ms = (time.time() - start_time) * 1000\n",
        "        observability.record_api_call(\"open_meteo\", latency_ms, False)\n",
        "        observability.end_span(\"ERROR\", {\"error\": str(e)})\n",
        "        return {\"status\": \"error\", \"message\": f\"Error: {str(e)}\"}\n",
        "\n",
        "\n",
        "USGS_SITES = {\n",
        "    \"california\": {\"site_id\": \"11447650\", \"name\": \"Sacramento River at Freeport, CA\"},\n",
        "    \"colorado\": {\"site_id\": \"09380000\", \"name\": \"Colorado River at Lees Ferry, AZ\"},\n",
        "    \"mississippi\": {\"site_id\": \"07374000\", \"name\": \"Mississippi River at Baton Rouge, LA\"},\n",
        "    \"texas\": {\"site_id\": \"08158000\", \"name\": \"Colorado River at Austin, TX\"},\n",
        "    \"florida\": {\"site_id\": \"02323500\", \"name\": \"Suwannee River near Wilcox, FL\"},\n",
        "}\n",
        "\n",
        "\n",
        "def get_realtime_water_level(region: str) -> dict:\n",
        "    \"\"\"Get REAL-TIME water level data from USGS sensors.\"\"\"\n",
        "    span_id = observability.start_span(\"get_realtime_water_level\", {\"region\": region})\n",
        "    start_time = time.time()\n",
        "    \n",
        "    region_lower = region.lower().strip()\n",
        "    \n",
        "    if region_lower not in USGS_SITES:\n",
        "        observability.end_span(\"ERROR\", {\"error\": \"no_usgs_site\"})\n",
        "        return {\n",
        "            \"status\": \"error\",\n",
        "            \"message\": f\"No USGS site for: {region}\",\n",
        "            \"available_regions\": list(USGS_SITES.keys()),\n",
        "            \"note\": \"USGS only covers US water bodies\",\n",
        "        }\n",
        "    \n",
        "    site = USGS_SITES[region_lower]\n",
        "    \n",
        "    try:\n",
        "        params = {\n",
        "            \"sites\": site[\"site_id\"],\n",
        "            \"format\": \"json\",\n",
        "            \"parameterCd\": \"00065,00060\",\n",
        "            \"siteStatus\": \"active\",\n",
        "        }\n",
        "        \n",
        "        response = requests.get(API_ENDPOINTS[\"usgs_water\"], params=params, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        \n",
        "        latency_ms = (time.time() - start_time) * 1000\n",
        "        observability.record_api_call(\"usgs_water\", latency_ms, True)\n",
        "        \n",
        "        time_series = data.get(\"value\", {}).get(\"timeSeries\", [])\n",
        "        readings = {}\n",
        "        \n",
        "        for series in time_series:\n",
        "            var_name = series.get(\"variable\", {}).get(\"variableName\", \"Unknown\")\n",
        "            values = series.get(\"values\", [{}])[0].get(\"value\", [])\n",
        "            if values:\n",
        "                latest = values[-1]\n",
        "                readings[var_name] = {\n",
        "                    \"value\": float(latest.get(\"value\", 0)),\n",
        "                    \"timestamp\": latest.get(\"dateTime\"),\n",
        "                }\n",
        "        \n",
        "        gage_height = readings.get(\"Gage height, ft\", {}).get(\"value\", 0)\n",
        "        \n",
        "        if gage_height > 20:\n",
        "            alert_level, alert_reason = \"RED\", \"Flood risk - water level elevated\"\n",
        "        elif gage_height > 15:\n",
        "            alert_level, alert_reason = \"ORANGE\", \"Water level above normal\"\n",
        "        elif gage_height < 5:\n",
        "            alert_level, alert_reason = \"ORANGE\", \"Drought conditions\"\n",
        "        else:\n",
        "            alert_level, alert_reason = \"GREEN\", \"Normal range\"\n",
        "        \n",
        "        observability.end_span(\"OK\", {\"alert_level\": alert_level})\n",
        "        observability.log(\"INFO\", f\"Water level data fetched for {region}\", {\"latency_ms\": round(latency_ms, 2)})\n",
        "        \n",
        "        return {\n",
        "            \"status\": \"success\",\n",
        "            \"source\": \"USGS Water Services (LIVE)\",\n",
        "            \"region\": region,\n",
        "            \"site_name\": site[\"name\"],\n",
        "            \"fetched_at\": datetime.utcnow().isoformat() + \"Z\",\n",
        "            \"readings\": readings,\n",
        "            \"alert_level\": alert_level,\n",
        "            \"alert_reason\": alert_reason,\n",
        "            \"_observability\": {\"latency_ms\": round(latency_ms, 2)},\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        latency_ms = (time.time() - start_time) * 1000\n",
        "        observability.record_api_call(\"usgs_water\", latency_ms, False)\n",
        "        observability.end_span(\"ERROR\", {\"error\": str(e)})\n",
        "        return {\"status\": \"error\", \"message\": f\"Error: {str(e)}\"}\n",
        "\n",
        "\n",
        "def get_realtime_disasters(category: str = \"all\", limit: int = 10) -> dict:\n",
        "    \"\"\"Get REAL-TIME disaster events from NASA EONET.\"\"\"\n",
        "    span_id = observability.start_span(\"get_realtime_disasters\", {\"category\": category})\n",
        "    start_time = time.time()\n",
        "    \n",
        "    try:\n",
        "        params = {\"status\": \"open\", \"limit\": limit}\n",
        "        \n",
        "        response = requests.get(API_ENDPOINTS[\"nasa_eonet\"], params=params, timeout=15)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        \n",
        "        latency_ms = (time.time() - start_time) * 1000\n",
        "        observability.record_api_call(\"nasa_eonet\", latency_ms, True)\n",
        "        \n",
        "        events = data.get(\"events\", [])\n",
        "        processed = []\n",
        "        water_related = 0\n",
        "        \n",
        "        for event in events:\n",
        "            cats = [c.get(\"title\", \"\") for c in event.get(\"categories\", [])]\n",
        "            is_water = any(c.lower() in [\"floods\", \"drought\", \"severe storms\"] for c in cats)\n",
        "            if is_water:\n",
        "                water_related += 1\n",
        "            processed.append({\n",
        "                \"id\": event.get(\"id\"),\n",
        "                \"title\": event.get(\"title\"),\n",
        "                \"categories\": cats,\n",
        "                \"is_water_related\": is_water,\n",
        "            })\n",
        "        \n",
        "        alert_level = \"RED\" if water_related > 3 else \"ORANGE\" if water_related > 0 else \"GREEN\"\n",
        "        \n",
        "        observability.end_span(\"OK\", {\"events\": len(processed)})\n",
        "        observability.log(\"INFO\", f\"Disaster data fetched: {len(processed)} events\", {\"latency_ms\": round(latency_ms, 2)})\n",
        "        \n",
        "        return {\n",
        "            \"status\": \"success\",\n",
        "            \"source\": \"NASA EONET (LIVE)\",\n",
        "            \"fetched_at\": datetime.utcnow().isoformat() + \"Z\",\n",
        "            \"total_events\": len(processed),\n",
        "            \"water_related_events\": water_related,\n",
        "            \"events\": processed,\n",
        "            \"alert_level\": alert_level,\n",
        "            \"_observability\": {\"latency_ms\": round(latency_ms, 2)},\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        latency_ms = (time.time() - start_time) * 1000\n",
        "        observability.record_api_call(\"nasa_eonet\", latency_ms, False)\n",
        "        observability.end_span(\"ERROR\", {\"error\": str(e)})\n",
        "        return {\"status\": \"error\", \"message\": f\"Error: {str(e)}\"}\n",
        "\n",
        "\n",
        "def get_country_info(country: str) -> dict:\n",
        "    \"\"\"Get country information.\"\"\"\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        response = requests.get(f\"{API_ENDPOINTS['rest_countries']}/name/{country}\", timeout=10)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()[0]\n",
        "        latency_ms = (time.time() - start_time) * 1000\n",
        "        observability.record_api_call(\"rest_countries\", latency_ms, True)\n",
        "        return {\n",
        "            \"status\": \"success\",\n",
        "            \"country\": data.get(\"name\", {}).get(\"common\", country),\n",
        "            \"population\": data.get(\"population\", 0),\n",
        "            \"region\": data.get(\"region\", \"\"),\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"status\": \"error\", \"message\": str(e)}\n",
        "\n",
        "\n",
        "ALERT_LOG = []\n",
        "\n",
        "def send_water_alert(region: str, alert_type: str, message: str, priority: str = \"normal\") -> dict:\n",
        "    \"\"\"Send water alert.\"\"\"\n",
        "    span_id = observability.start_span(\"send_water_alert\", {\"region\": region})\n",
        "    \n",
        "    timestamp = datetime.utcnow()\n",
        "    alert_id = f\"AQUA-{timestamp.strftime('%Y%m%d%H%M%S')}-{len(ALERT_LOG)+1:04d}\"\n",
        "    verification_code = f\"VER-{timestamp.strftime('%H%M%S')}\"\n",
        "    \n",
        "    country_info = get_country_info(region)\n",
        "    population = country_info.get(\"population\", 1000000)\n",
        "    \n",
        "    reach_mult = {\"emergency\": 0.85, \"high\": 0.60, \"normal\": 0.30, \"low\": 0.10}\n",
        "    estimated_reach = int(population * reach_mult.get(priority, 0.30))\n",
        "    \n",
        "    channels = {\n",
        "        \"emergency\": [\"SMS\", \"Voice\", \"Radio\", \"TV\", \"Sirens\", \"MobileApp\"],\n",
        "        \"high\": [\"SMS\", \"MobileApp\", \"Email\", \"Radio\"],\n",
        "        \"normal\": [\"MobileApp\", \"Email\"],\n",
        "        \"low\": [\"MobileApp\"],\n",
        "    }\n",
        "    \n",
        "    alert_record = {\n",
        "        \"alert_id\": alert_id,\n",
        "        \"verification_code\": verification_code,\n",
        "        \"timestamp\": timestamp.isoformat() + \"Z\",\n",
        "        \"region\": region,\n",
        "        \"alert_type\": alert_type,\n",
        "        \"priority\": priority,\n",
        "        \"channels\": channels.get(priority, [\"MobileApp\"]),\n",
        "        \"estimated_reach\": estimated_reach,\n",
        "    }\n",
        "    \n",
        "    ALERT_LOG.append(alert_record)\n",
        "    \n",
        "    observability.end_span(\"OK\", {\"alert_id\": alert_id})\n",
        "    observability.log(\"INFO\", f\"Alert sent: {alert_id} to {region}\")\n",
        "    \n",
        "    return {\n",
        "        \"status\": \"success\",\n",
        "        \"alert_id\": alert_id,\n",
        "        \"verification_code\": verification_code,\n",
        "        \"timestamp\": timestamp.isoformat() + \"Z\",\n",
        "        \"region\": region,\n",
        "        \"alert_type\": alert_type,\n",
        "        \"priority\": priority,\n",
        "        \"channels\": channels.get(priority, [\"MobileApp\"]),\n",
        "        \"delivery\": {\n",
        "            \"estimated_reach\": estimated_reach,\n",
        "            \"status\": \"QUEUED_FOR_DELIVERY\",\n",
        "        },\n",
        "    }\n",
        "\n",
        "\n",
        "# Register tools with MCP Server\n",
        "mcp_server.register_tool(\n",
        "    \"get_realtime_weather\",\n",
        "    \"Fetch real-time weather data from Open-Meteo API\",\n",
        "    get_realtime_weather,\n",
        "    {\"type\": \"object\", \"properties\": {\"region\": {\"type\": \"string\"}}}\n",
        ")\n",
        "mcp_server.register_tool(\n",
        "    \"get_realtime_water_level\",\n",
        "    \"Fetch water level data from USGS\",\n",
        "    get_realtime_water_level,\n",
        "    {\"type\": \"object\", \"properties\": {\"region\": {\"type\": \"string\"}}}\n",
        ")\n",
        "mcp_server.register_tool(\n",
        "    \"get_realtime_disasters\",\n",
        "    \"Fetch disaster events from NASA EONET\",\n",
        "    get_realtime_disasters,\n",
        "    {\"type\": \"object\", \"properties\": {\"category\": {\"type\": \"string\"}, \"limit\": {\"type\": \"integer\"}}}\n",
        ")\n",
        "mcp_server.register_tool(\n",
        "    \"send_water_alert\",\n",
        "    \"Send water crisis alert\",\n",
        "    send_water_alert,\n",
        "    {\"type\": \"object\", \"properties\": {\"region\": {\"type\": \"string\"}, \"alert_type\": {\"type\": \"string\"}, \"message\": {\"type\": \"string\"}, \"priority\": {\"type\": \"string\"}}}\n",
        ")\n",
        "\n",
        "print(\"âœ… Created 5 real-time tools with observability\")\n",
        "print(\"âœ… Tools registered with MCP Server\")\n",
        "print(f\"   MCP Server: {mcp_server.get_server_info()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================================\n",
        "# CELL 7: TIMING COMPARISON - Sequential vs Parallel Execution\n",
        "# ============================================================================\n",
        "\n",
        "def run_sequential_fetch(region: str) -> tuple:\n",
        "    \"\"\"\n",
        "    Run API fetches SEQUENTIALLY (one after another).\n",
        "    Returns (results, total_time_ms)\n",
        "    \"\"\"\n",
        "    start = time.time()\n",
        "    \n",
        "    # Sequential execution - each waits for the previous\n",
        "    weather = get_realtime_weather(region)\n",
        "    water = get_realtime_water_level(region) if region in USGS_SITES else {\"status\": \"skipped\", \"reason\": \"no USGS site\"}\n",
        "    disasters = get_realtime_disasters()\n",
        "    \n",
        "    total_time = (time.time() - start) * 1000\n",
        "    \n",
        "    return {\n",
        "        \"weather\": weather.get(\"status\"),\n",
        "        \"water_level\": water.get(\"status\"),\n",
        "        \"disasters\": disasters.get(\"status\"),\n",
        "    }, total_time\n",
        "\n",
        "\n",
        "def run_parallel_fetch(region: str) -> tuple:\n",
        "    \"\"\"\n",
        "    Run API fetches in PARALLEL (concurrent).\n",
        "    Returns (results, total_time_ms)\n",
        "    \"\"\"\n",
        "    start = time.time()\n",
        "    \n",
        "    results = {}\n",
        "    \n",
        "    # Parallel execution using ThreadPoolExecutor\n",
        "    with ThreadPoolExecutor(max_workers=3) as executor:\n",
        "        weather_future = executor.submit(get_realtime_weather, region)\n",
        "        water_future = executor.submit(\n",
        "            get_realtime_water_level, region\n",
        "        ) if region in USGS_SITES else None\n",
        "        disasters_future = executor.submit(get_realtime_disasters)\n",
        "        \n",
        "        results[\"weather\"] = weather_future.result().get(\"status\")\n",
        "        results[\"water_level\"] = water_future.result().get(\"status\") if water_future else \"skipped\"\n",
        "        results[\"disasters\"] = disasters_future.result().get(\"status\")\n",
        "    \n",
        "    total_time = (time.time() - start) * 1000\n",
        "    \n",
        "    return results, total_time\n",
        "\n",
        "\n",
        "def demonstrate_parallel_speedup(region: str = \"california\"):\n",
        "    \"\"\"\n",
        "    Demonstrate the speedup achieved by ParallelAgent pattern.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"â±ï¸  TIMING COMPARISON: Sequential vs Parallel Execution\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"\\nRegion: {region.upper()}\")\n",
        "    print(\"APIs: Open-Meteo (weather) + USGS (water) + NASA EONET (disasters)\")\n",
        "    print(\"\\n\" + \"-\"*70)\n",
        "    \n",
        "    # Run sequential\n",
        "    print(\"\\nðŸ”„ SEQUENTIAL EXECUTION (one after another):\")\n",
        "    seq_results, seq_time = run_sequential_fetch(region)\n",
        "    print(f\"   Results: {seq_results}\")\n",
        "    print(f\"   â±ï¸  Total Time: {seq_time:.2f}ms\")\n",
        "    \n",
        "    # Small delay between tests\n",
        "    time.sleep(0.5)\n",
        "    \n",
        "    # Run parallel\n",
        "    print(\"\\nâš¡ PARALLEL EXECUTION (concurrent):\")\n",
        "    par_results, par_time = run_parallel_fetch(region)\n",
        "    print(f\"   Results: {par_results}\")\n",
        "    print(f\"   â±ï¸  Total Time: {par_time:.2f}ms\")\n",
        "    \n",
        "    # Calculate speedup\n",
        "    speedup = seq_time / par_time if par_time > 0 else 0\n",
        "    time_saved = seq_time - par_time\n",
        "    \n",
        "    # Record in observability\n",
        "    observability.record_timing_comparison(f\"fetch_{region}\", seq_time, par_time)\n",
        "    \n",
        "    print(\"\\n\" + \"-\"*70)\n",
        "    print(\"ðŸ“Š COMPARISON RESULTS:\")\n",
        "    print(\"-\"*70)\n",
        "    print(f\"   Sequential Time: {seq_time:.2f}ms\")\n",
        "    print(f\"   Parallel Time:   {par_time:.2f}ms\")\n",
        "    print(f\"   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
        "    print(f\"   ðŸš€ Speedup:      {speedup:.2f}x faster\")\n",
        "    print(f\"   â±ï¸  Time Saved:   {time_saved:.2f}ms\")\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    \n",
        "    # A2A: Broadcast timing results to all agents\n",
        "    a2a_protocol.broadcast(\"HydroOrchestrator\", {\n",
        "        \"type\": \"timing_benchmark\",\n",
        "        \"sequential_ms\": seq_time,\n",
        "        \"parallel_ms\": par_time,\n",
        "        \"speedup\": speedup,\n",
        "    })\n",
        "    \n",
        "    return {\n",
        "        \"sequential_ms\": seq_time,\n",
        "        \"parallel_ms\": par_time,\n",
        "        \"speedup\": speedup,\n",
        "        \"time_saved_ms\": time_saved,\n",
        "    }\n",
        "\n",
        "\n",
        "print(\"âœ… Timing comparison functions ready\")\n",
        "print(\"   â€¢ run_sequential_fetch() - Execute APIs one by one\")\n",
        "print(\"   â€¢ run_parallel_fetch() - Execute APIs concurrently\")\n",
        "print(\"   â€¢ demonstrate_parallel_speedup() - Run comparison benchmark\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================================\n",
        "# CELL 8: AGENT IMPLEMENTATION\n",
        "# ============================================================================\n",
        "\n",
        "# Weather Agent - FOR SENTINEL (Parallel)\n",
        "weather_agent_sentinel = LlmAgent(\n",
        "    name=\"WeatherAgentSentinel\",\n",
        "    model=MODEL,\n",
        "    instruction=\"\"\"You analyze REAL-TIME weather data for water impact.\n",
        "    \n",
        "    Steps:\n",
        "    1. Extract region from query (convert to lowercase)\n",
        "       Available: california, bangladesh, kenya, india, brazil, australia, ethiopia, somalia, texas, florida\n",
        "    2. Call get_realtime_weather(region=\"<region>\") IMMEDIATELY\n",
        "    3. Report: temperature, 7-day precipitation, flood/drought risk\n",
        "    4. Include fetched_at timestamp\n",
        "    \n",
        "    CRITICAL: You MUST call the function.\"\"\",\n",
        "    description=\"Fetches real-time weather data\",\n",
        "    tools=[get_realtime_weather],\n",
        ")\n",
        "\n",
        "# Weather Agent - FOR GUARDIAN (Sequential Step 1)\n",
        "weather_agent_guardian = LlmAgent(\n",
        "    name=\"WeatherAgentGuardian\",\n",
        "    model=MODEL,\n",
        "    instruction=\"\"\"You are STEP 1 of a sequential pipeline. Your output becomes input for AnalysisAgent.\n",
        "    \n",
        "    YOUR TASK: Fetch weather data and OUTPUT STRUCTURED DATA.\n",
        "    \n",
        "    Steps:\n",
        "    1. Extract region from query\n",
        "    2. Call get_realtime_weather(region=\"<region>\")\n",
        "    3. OUTPUT FORMAT:\n",
        "       \n",
        "       ---WEATHER_DATA_START---\n",
        "       Region: [name]\n",
        "       Temperature: [X]Â°C\n",
        "       7-Day Precipitation: [X] mm\n",
        "       Flood Risk: [HIGH/MODERATE/LOW]\n",
        "       Drought Risk: [HIGH/MODERATE/LOW]\n",
        "       Fetched At: [timestamp]\n",
        "       ---WEATHER_DATA_END---\n",
        "    \n",
        "    This structured output enables AnalysisAgent to extract the data.\"\"\",\n",
        "    description=\"Fetches weather data with structured output for sequential processing\",\n",
        "    tools=[get_realtime_weather],\n",
        ")\n",
        "\n",
        "# Water Level Agent\n",
        "water_level_agent = LlmAgent(\n",
        "    name=\"WaterLevelAgent\",\n",
        "    model=MODEL,\n",
        "    instruction=\"\"\"You monitor REAL-TIME water levels from USGS sensors.\n",
        "    Call get_realtime_water_level for US regions.\n",
        "    Available: california, colorado, mississippi, texas, florida\n",
        "    Note: USGS only covers US water bodies.\"\"\",\n",
        "    description=\"Monitors water levels from USGS\",\n",
        "    tools=[get_realtime_water_level],\n",
        ")\n",
        "\n",
        "# Disaster Agent\n",
        "disaster_agent = LlmAgent(\n",
        "    name=\"DisasterAgent\",\n",
        "    model=MODEL,\n",
        "    instruction=\"\"\"You monitor REAL-TIME disasters from NASA EONET.\n",
        "    Call get_realtime_disasters() to get global events.\n",
        "    Report: total events, water-related count, alert level.\"\"\",\n",
        "    description=\"Monitors disasters from NASA EONET\",\n",
        "    tools=[get_realtime_disasters],\n",
        ")\n",
        "\n",
        "# Analysis Agent (Sequential Step 2)\n",
        "analysis_agent = LlmAgent(\n",
        "    name=\"AnalysisAgent\",\n",
        "    model=MODEL,\n",
        "    instruction=\"\"\"You are STEP 2 of a sequential pipeline. You RECEIVE data from WeatherAgentGuardian.\n",
        "    \n",
        "    SEQUENTIAL DEPENDENCY: Extract data from the ---WEATHER_DATA_START--- block.\n",
        "    \n",
        "    YOUR TASK:\n",
        "    1. EXTRACT: Temperature, Precipitation, Flood Risk, Drought Risk\n",
        "    2. ANALYZE:\n",
        "       - If Flood Risk HIGH: Recommend evacuation prep\n",
        "       - If Drought Risk HIGH: Recommend conservation\n",
        "       - If precipitation > 50mm: Warn about flooding\n",
        "       - If precipitation < 10mm: Warn about drought\n",
        "    \n",
        "    3. GENERATE RECOMMENDATIONS:\n",
        "       ðŸ”´ HIGH PRIORITY: [immediate actions]\n",
        "       ðŸŸ¡ MEDIUM PRIORITY: [preparatory actions]\n",
        "       ðŸŸ¢ LOW PRIORITY: [monitoring actions]\n",
        "    \n",
        "    4. CITE SPECIFIC DATA from WeatherAgentGuardian's output.\"\"\",\n",
        "    description=\"Synthesizes weather data into recommendations\",\n",
        ")\n",
        "\n",
        "# Alert Agent (Loop Step 1)\n",
        "alert_agent = LlmAgent(\n",
        "    name=\"AlertAgent\",\n",
        "    model=MODEL,\n",
        "    instruction=\"\"\"You send water-related alerts.\n",
        "    \n",
        "    Call send_water_alert with:\n",
        "    - region, alert_type, message, priority\n",
        "    \n",
        "    OUTPUT for verification:\n",
        "    - Alert ID, Verification Code, Region, Priority, Estimated Reach, Channels, Status\"\"\",\n",
        "    description=\"Sends water alerts\",\n",
        "    tools=[send_water_alert],\n",
        ")\n",
        "\n",
        "# Verify Agent (Loop Step 2)\n",
        "verify_agent = LlmAgent(\n",
        "    name=\"VerifyAgent\",\n",
        "    model=MODEL,\n",
        "    instruction=\"\"\"You verify alert delivery with 7-POINT VALIDATION.\n",
        "    \n",
        "    CHECKLIST:\n",
        "    âœ“ CHECK 1: Alert ID exists (AQUA-YYYYMMDDHHMMSS-####)\n",
        "    âœ“ CHECK 2: Verification Code exists (VER-HHMMSS)\n",
        "    âœ“ CHECK 3: Estimated reach > 0\n",
        "    âœ“ CHECK 4: Status is QUEUED_FOR_DELIVERY\n",
        "    âœ“ CHECK 5: Timestamp is recent\n",
        "    âœ“ CHECK 6: Channels list not empty\n",
        "    âœ“ CHECK 7: Region matches request\n",
        "    \n",
        "    OUTPUT:\n",
        "    Verification Status: [VERIFIED/FAILED]\n",
        "    Checks Passed: [X/7]\"\"\",\n",
        "    description=\"Verifies alerts with 7-point validation\",\n",
        ")\n",
        "\n",
        "print(\"âœ… Created 7 specialist LlmAgents\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================================\n",
        "# CELL 9: MULTI-AGENT ARCHITECTURES\n",
        "# ============================================================================\n",
        "\n",
        "# PARALLEL AGENT - SentinelAgent\n",
        "sentinel_agent = ParallelAgent(\n",
        "    name=\"SentinelAgent\",\n",
        "    sub_agents=[weather_agent_sentinel, water_level_agent, disaster_agent],\n",
        "    description=\"\"\"Real-time monitoring using PARALLEL EXECUTION.\n",
        "    \n",
        "    PARALLELISM BENEFIT (demonstrated in timing comparison):\n",
        "    - Sequential: ~2000-4000ms (APIs execute one by one)\n",
        "    - Parallel: ~800-1500ms (APIs execute concurrently)\n",
        "    - Speedup: ~2-3x faster\n",
        "    \"\"\",\n",
        ")\n",
        "\n",
        "print(\"âœ… Created SentinelAgent (ParallelAgent)\")\n",
        "print(\"   â€¢ 3 sub-agents execute CONCURRENTLY\")\n",
        "\n",
        "# SEQUENTIAL AGENT - GuardianAgent\n",
        "guardian_agent = SequentialAgent(\n",
        "    name=\"GuardianAgent\",\n",
        "    sub_agents=[weather_agent_guardian, analysis_agent],\n",
        "    description=\"\"\"Predictive analytics using SEQUENTIAL EXECUTION with state passing.\n",
        "    \n",
        "    Step 1: WeatherAgentGuardian â†’ Structured output\n",
        "    Step 2: AnalysisAgent â†’ Extracts data & recommends\n",
        "    \"\"\",\n",
        ")\n",
        "\n",
        "print(\"âœ… Created GuardianAgent (SequentialAgent)\")\n",
        "print(\"   â€¢ Step 1 â†’ Step 2 with state passing\")\n",
        "\n",
        "# LOOP AGENT - ResponderAgent\n",
        "responder_agent = LoopAgent(\n",
        "    name=\"ResponderAgent\",\n",
        "    sub_agents=[alert_agent, verify_agent],\n",
        "    max_iterations=5,\n",
        "    description=\"\"\"Emergency response using LOOP EXECUTION.\n",
        "    \n",
        "    Loop: AlertAgent â†’ VerifyAgent (7-point check)\n",
        "    Exit: VERIFIED status or max 5 iterations\n",
        "    \"\"\",\n",
        ")\n",
        "\n",
        "print(\"âœ… Created ResponderAgent (LoopAgent)\")\n",
        "print(\"   â€¢ Max 5 iterations, 7-point verification\")\n",
        "\n",
        "# ROOT ORCHESTRATOR\n",
        "ORCHESTRATOR_INSTRUCTION = \"\"\"\n",
        "You are HYDRO ORCHESTRATOR, the central coordinator of AQUA SENTINEL.\n",
        "\n",
        "## REAL-TIME DATA\n",
        "All tools fetch LIVE data from real APIs with observability tracking.\n",
        "\n",
        "## QUERY ROUTING\n",
        "\n",
        "1. **REGIONAL MONITORING** â†’ SentinelAgent (ParallelAgent)\n",
        "   Keywords: \"situation in [region]\", \"water status\"\n",
        "   \n",
        "2. **FORECAST & ANALYSIS** â†’ GuardianAgent (SequentialAgent)\n",
        "   Keywords: \"forecast\", \"predict\", \"analyze\", \"recommend\"\n",
        "   \n",
        "3. **EMERGENCY ALERTS** â†’ ResponderAgent (LoopAgent)\n",
        "   Keywords: \"send alert\", \"warn\", \"emergency\"\n",
        "   \n",
        "4. **GLOBAL DISASTERS** â†’ Call get_realtime_disasters() directly\n",
        "   Keywords: \"global\", \"worldwide\"\n",
        "\n",
        "## RESPONSE FORMAT\n",
        "- Data Source + Timestamp\n",
        "- Key Findings\n",
        "- Risk Level: ðŸŸ¢ GREEN / ðŸŸ¡ ORANGE / ðŸ”´ RED\n",
        "- Recommendations\n",
        "\"\"\"\n",
        "\n",
        "hydro_orchestrator = LlmAgent(\n",
        "    name=\"HydroOrchestrator\",\n",
        "    model=MODEL,\n",
        "    instruction=ORCHESTRATOR_INSTRUCTION,\n",
        "    description=\"Central coordinator\",\n",
        "    sub_agents=[sentinel_agent, guardian_agent, responder_agent],\n",
        "    tools=[get_realtime_disasters],\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"AQUA SENTINEL AGENT HIERARCHY\")\n",
        "print(\"=\"*70)\n",
        "print(\"\"\"\n",
        "HydroOrchestrator (LlmAgent)\n",
        "â”‚\n",
        "â”œâ”€â”€ SentinelAgent (ParallelAgent) â”€â”€â”€â”€ CONCURRENT\n",
        "â”‚   â”œâ”€â”€ WeatherAgent  â†’ Open-Meteo\n",
        "â”‚   â”œâ”€â”€ WaterLevelAgent â†’ USGS\n",
        "â”‚   â””â”€â”€ DisasterAgent â†’ NASA EONET\n",
        "â”‚\n",
        "â”œâ”€â”€ GuardianAgent (SequentialAgent) â”€â”€ STATE PASSING\n",
        "â”‚   â”œâ”€â”€ WeatherAgent â†’ Structured Output\n",
        "â”‚   â””â”€â”€ AnalysisAgent â†’ Extract & Recommend\n",
        "â”‚\n",
        "â””â”€â”€ ResponderAgent (LoopAgent) â”€â”€â”€â”€â”€â”€â”€ 5 ITERATIONS\n",
        "    â”œâ”€â”€ AlertAgent â†’ Send\n",
        "    â””â”€â”€ VerifyAgent â†’ 7-Point Check\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================================\n",
        "# CELL 10: SESSION MANAGEMENT & QUERY FUNCTION\n",
        "# ============================================================================\n",
        "\n",
        "import inspect\n",
        "\n",
        "session_service = InMemorySessionService()\n",
        "\n",
        "APP_NAME = \"aqua_sentinel_realtime\"\n",
        "USER_ID = \"demo_user\"\n",
        "SESSION_ID = f\"session_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}\"\n",
        "\n",
        "runner = Runner(\n",
        "    agent=hydro_orchestrator,\n",
        "    app_name=APP_NAME,\n",
        "    session_service=session_service,\n",
        ")\n",
        "\n",
        "\n",
        "async def ensure_session():\n",
        "    \"\"\"Create session.\"\"\"\n",
        "    try:\n",
        "        result = session_service.create_session(\n",
        "            app_name=APP_NAME,\n",
        "            user_id=USER_ID,\n",
        "            session_id=SESSION_ID,\n",
        "        )\n",
        "        if inspect.iscoroutine(result):\n",
        "            await result\n",
        "        print(f\"âœ… Session created: {SESSION_ID}\")\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Session: {e}\")\n",
        "\n",
        "\n",
        "async def query_aqua_sentinel(\n",
        "    query: str,\n",
        "    verbose: bool = True,\n",
        "    fresh_session: bool = True,\n",
        "    show_observability: bool = True\n",
        ") -> str:\n",
        "    \"\"\"Send query to AQUA SENTINEL with observability.\"\"\"\n",
        "    global SESSION_ID\n",
        "    \n",
        "    trace_id = observability.start_trace(f\"query: {query[:50]}...\")\n",
        "    \n",
        "    if fresh_session:\n",
        "        SESSION_ID = f\"session_{datetime.utcnow().strftime('%Y%m%d_%H%M%S%f')}\"\n",
        "        try:\n",
        "            result = session_service.create_session(\n",
        "                app_name=APP_NAME,\n",
        "                user_id=USER_ID,\n",
        "                session_id=SESSION_ID,\n",
        "            )\n",
        "            if inspect.iscoroutine(result):\n",
        "                await result\n",
        "        except:\n",
        "            pass\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"ðŸ” QUERY: {query}\")\n",
        "        print(f\"â° Time: {datetime.utcnow().isoformat()}Z\")\n",
        "        print(f\"ðŸ”— Trace ID: {trace_id}\")\n",
        "        print(f\"{'='*70}\")\n",
        "    \n",
        "    query_span = observability.start_span(\"agent_query\", {\"query\": query[:100]})\n",
        "    \n",
        "    content = types.Content(\n",
        "        role=\"user\",\n",
        "        parts=[types.Part(text=query)]\n",
        "    )\n",
        "    \n",
        "    response_text = \"\"\n",
        "    try:\n",
        "        async for event in runner.run_async(\n",
        "            user_id=USER_ID,\n",
        "            session_id=SESSION_ID,\n",
        "            new_message=content,\n",
        "        ):\n",
        "            if hasattr(event, 'content') and event.content:\n",
        "                for part in event.content.parts:\n",
        "                    if hasattr(part, 'text') and part.text:\n",
        "                        response_text += part.text + \"\\n\"\n",
        "    except Exception as e:\n",
        "        response_text = f\"Error: {str(e)}\"\n",
        "        observability.log(\"ERROR\", f\"Query failed: {str(e)}\")\n",
        "    \n",
        "    observability.end_span(\"OK\" if \"Error\" not in response_text else \"ERROR\")\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"\\nðŸ“Š RESPONSE:\\n{response_text}\")\n",
        "        \n",
        "        if show_observability:\n",
        "            print(f\"\\n{'â”€'*70}\")\n",
        "            print(\"ðŸ“ˆ OBSERVABILITY SUMMARY\")\n",
        "            print(f\"{'â”€'*70}\")\n",
        "            trace = observability.get_trace_summary()\n",
        "            print(f\"   Trace ID: {trace.get('trace_id', 'N/A')}\")\n",
        "            print(f\"   Total Spans: {trace.get('total_spans', 0)}\")\n",
        "            print(f\"   Total Duration: {trace.get('total_duration_ms', 0):.2f}ms\")\n",
        "            metrics = observability.get_metrics_summary()\n",
        "            print(f\"   API Calls: {metrics.get('total_api_calls', 0)}\")\n",
        "            print(f\"   Avg Latency: {metrics.get('average_latency_ms', 0):.2f}ms\")\n",
        "            print(f\"   Success Rate: {metrics.get('success_rate', 'N/A')}\")\n",
        "            print(f\"   Tools Used: {', '.join(metrics.get('unique_tools_used', []))}\")\n",
        "    \n",
        "    return response_text.strip()\n",
        "\n",
        "\n",
        "print(\"âœ… Query function ready with observability\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================================\n",
        "# CELL 11: EVALUATION FRAMEWORK (12 Test Cases)\n",
        "# ============================================================================\n",
        "\n",
        "@dataclass\n",
        "class TestCase:\n",
        "    id: str\n",
        "    name: str\n",
        "    query: str\n",
        "    expected_elements: List[str]\n",
        "    expected_agent: str\n",
        "    category: str = \"happy_path\"\n",
        "\n",
        "\n",
        "GOLDEN_DATASET = [\n",
        "    # Happy Path (4)\n",
        "    TestCase(\"RT-001\", \"Real-Time Weather\", \"happy_path\",\n",
        "             \"What's the current weather in California?\",\n",
        "             [\"weather\", \"temperature\", \"california\"], \"WeatherAgent\"),\n",
        "    TestCase(\"RT-002\", \"USGS Water Level\", \"happy_path\",\n",
        "             \"What are the current water levels in California rivers?\",\n",
        "             [\"water\", \"level\", \"gage\"], \"WaterLevelAgent\"),\n",
        "    TestCase(\"RT-003\", \"NASA Disasters\", \"happy_path\",\n",
        "             \"What natural disasters are currently active?\",\n",
        "             [\"disaster\", \"event\", \"nasa\"], \"DisasterAgent\"),\n",
        "    TestCase(\"RT-004\", \"Alert Delivery\", \"happy_path\",\n",
        "             \"Send a water conservation alert to India with normal priority.\",\n",
        "             [\"alert\", \"india\", \"sent\"], \"ResponderAgent\"),\n",
        "    \n",
        "    # Error Handling (3)\n",
        "    TestCase(\"RT-005\", \"Invalid Region Error\", \"error_handling\",\n",
        "             \"What's the weather in Atlantis?\",\n",
        "             [\"error\", \"unknown\", \"available\"], \"WeatherAgent\"),\n",
        "    TestCase(\"RT-006\", \"Non-US Water Level Request\", \"error_handling\",\n",
        "             \"What's the water level in Kenya rivers?\",\n",
        "             [\"usgs\", \"us\", \"available\"], \"WaterLevelAgent\"),\n",
        "    TestCase(\"RT-007\", \"Ambiguous Region Query\", \"error_handling\",\n",
        "             \"What's the water situation?\",\n",
        "             [\"region\", \"specify\", \"available\"], \"HydroOrchestrator\"),\n",
        "    \n",
        "    # Multi-Agent (3)\n",
        "    TestCase(\"RT-008\", \"Sequential Forecast Analysis\", \"multi_agent\",\n",
        "             \"What's the weather forecast for Kenya? Analyze risks and recommend actions.\",\n",
        "             [\"forecast\", \"recommend\", \"risk\"], \"GuardianAgent\"),\n",
        "    TestCase(\"RT-009\", \"Parallel Regional Monitoring\", \"multi_agent\",\n",
        "             \"Give me a complete water situation report for California with all available data sources.\",\n",
        "             [\"weather\", \"water\", \"california\"], \"SentinelAgent\"),\n",
        "    TestCase(\"RT-010\", \"Global Disaster Overview\", \"multi_agent\",\n",
        "             \"What natural disasters are happening globally right now? Focus on water-related events.\",\n",
        "             [\"disaster\", \"global\", \"water\"], \"DisasterAgent\"),\n",
        "    \n",
        "    # Edge Cases (2)\n",
        "    TestCase(\"RT-011\", \"Emergency High Priority Alert\", \"edge_case\",\n",
        "             \"Send an EMERGENCY flood alert to Bangladesh immediately. Critical flooding situation!\",\n",
        "             [\"alert\", \"emergency\", \"bangladesh\"], \"ResponderAgent\"),\n",
        "    TestCase(\"RT-012\", \"Horn of Africa Drought Region\", \"edge_case\",\n",
        "             \"What's the drought situation in Ethiopia? This is for the Horn of Africa crisis response.\",\n",
        "             [\"weather\", \"drought\", \"ethiopia\"], \"WeatherAgent\"),\n",
        "]\n",
        "\n",
        "print(f\"âœ… Golden Dataset: {len(GOLDEN_DATASET)} test cases\")\n",
        "print(f\"   â€¢ Happy Path: {sum(1 for t in GOLDEN_DATASET if t.category == 'happy_path')}\")\n",
        "print(f\"   â€¢ Error Handling: {sum(1 for t in GOLDEN_DATASET if t.category == 'error_handling')}\")\n",
        "print(f\"   â€¢ Multi-Agent: {sum(1 for t in GOLDEN_DATASET if t.category == 'multi_agent')}\")\n",
        "print(f\"   â€¢ Edge Cases: {sum(1 for t in GOLDEN_DATASET if t.category == 'edge_case')}\")\n",
        "\n",
        "\n",
        "def evaluate_response(response: str, test_case: TestCase) -> dict:\n",
        "    \"\"\"Multi-dimensional evaluation.\"\"\"\n",
        "    response_lower = response.lower()\n",
        "    response_len = len(response)\n",
        "    \n",
        "    # Validity (25%)\n",
        "    error_indicators = [\n",
        "        \"error:\" in response_lower and test_case.category != \"error_handling\",\n",
        "        \"api key\" in response_lower,\n",
        "        response_len < 20,\n",
        "    ]\n",
        "    validity_score = 0.0 if any(error_indicators) else 1.0\n",
        "    \n",
        "    if test_case.category == \"error_handling\":\n",
        "        if any(x in response_lower for x in [\"error\", \"unknown\", \"available\", \"not\", \"usgs\"]):\n",
        "            validity_score = 1.0\n",
        "    \n",
        "    # Relevance (35%)\n",
        "    matches = sum(1 for elem in test_case.expected_elements if elem.lower() in response_lower)\n",
        "    relevance_score = min(1.0, matches / len(test_case.expected_elements))\n",
        "    \n",
        "    # Freshness (20%)\n",
        "    freshness = [\n",
        "        \"2025\" in response_lower or \"2024\" in response_lower,\n",
        "        any(x in response_lower for x in [\"live\", \"real-time\", \"current\"]),\n",
        "        any(x in response_lower for x in [\"open-meteo\", \"usgs\", \"nasa\", \"eonet\"]),\n",
        "    ]\n",
        "    freshness_score = min(1.0, sum(freshness) / 2)\n",
        "    \n",
        "    # Quality (20%)\n",
        "    quality_score = min(1.0, response_len / 200)\n",
        "    \n",
        "    overall = (validity_score * 0.25) + (relevance_score * 0.35) + (freshness_score * 0.20) + (quality_score * 0.20)\n",
        "    \n",
        "    return {\n",
        "        \"test_id\": test_case.id,\n",
        "        \"test_name\": test_case.name,\n",
        "        \"category\": test_case.category,\n",
        "        \"validity_score\": round(validity_score, 2),\n",
        "        \"relevance_score\": round(relevance_score, 2),\n",
        "        \"freshness_score\": round(freshness_score, 2),\n",
        "        \"quality_score\": round(quality_score, 2),\n",
        "        \"overall_score\": round(overall, 2),\n",
        "        \"passed\": overall >= 0.50,\n",
        "    }\n",
        "\n",
        "\n",
        "async def run_evaluation(test_subset: str = \"all\"):\n",
        "    \"\"\"Run evaluation suite.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ðŸ§ª AQUA SENTINEL EVALUATION FRAMEWORK\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    tests = GOLDEN_DATASET if test_subset == \"all\" else [t for t in GOLDEN_DATASET if t.category == test_subset]\n",
        "    \n",
        "    print(f\"\\nðŸ“Š Running {len(tests)} tests (subset: {test_subset})\")\n",
        "    print(\"\\nðŸ“ˆ Scoring Dimensions:\")\n",
        "    print(\"   â€¢ Validity (25%): Error-free response\")\n",
        "    print(\"   â€¢ Relevance (35%): Contains expected elements\")\n",
        "    print(\"   â€¢ Freshness (20%): Real-time data indicators\")\n",
        "    print(\"   â€¢ Quality (20%): Response completeness\")\n",
        "    print(\"   â€¢ Pass Threshold: Overall Score â‰¥ 0.50\")\n",
        "    print(\"\\n\" + \"-\"*70)\n",
        "    \n",
        "    results = []\n",
        "    \n",
        "    for i, tc in enumerate(tests):\n",
        "        print(f\"\\nðŸ“‹ [{tc.id}] {tc.name}\")\n",
        "        print(f\"   Category: {tc.category}\")\n",
        "        print(f\"   Query: \\\"{tc.query[:60]}...\\\"\" if len(tc.query) > 60 else f\"   Query: \\\"{tc.query}\\\"\")\n",
        "        \n",
        "        if i > 0:\n",
        "            await asyncio.sleep(1)\n",
        "        \n",
        "        try:\n",
        "            response = await query_aqua_sentinel(tc.query, verbose=False, show_observability=False)\n",
        "            result = evaluate_response(response, tc)\n",
        "        except Exception as e:\n",
        "            result = {\n",
        "                \"test_id\": tc.id, \"test_name\": tc.name, \"category\": tc.category,\n",
        "                \"validity_score\": 0, \"relevance_score\": 0, \"freshness_score\": 0,\n",
        "                \"quality_score\": 0, \"overall_score\": 0, \"passed\": False,\n",
        "            }\n",
        "        \n",
        "        results.append(result)\n",
        "        status = \"âœ… PASS\" if result[\"passed\"] else \"âŒ FAIL\"\n",
        "        print(f\"   â”œâ”€ Validity:  {result['validity_score']:.2f}\")\n",
        "        print(f\"   â”œâ”€ Relevance: {result['relevance_score']:.2f}\")\n",
        "        print(f\"   â”œâ”€ Freshness: {result['freshness_score']:.2f}\")\n",
        "        print(f\"   â”œâ”€ Quality:   {result['quality_score']:.2f}\")\n",
        "        print(f\"   â””â”€ Overall:   {result['overall_score']:.2f} {status}\")\n",
        "    \n",
        "    # Summary\n",
        "    passed = sum(1 for r in results if r[\"passed\"])\n",
        "    avg = sum(r[\"overall_score\"] for r in results) / len(results)\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ðŸ“Š EVALUATION RESULTS SUMMARY\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"\\n   Tests Passed: {passed}/{len(results)}\")\n",
        "    print(f\"   Average Score: {avg:.2f}\")\n",
        "    print(f\"   Pass Rate: {(passed/len(results))*100:.1f}%\")\n",
        "    \n",
        "    print(\"\\n   Results by Category:\")\n",
        "    for cat in [\"happy_path\", \"error_handling\", \"multi_agent\", \"edge_case\"]:\n",
        "        cat_results = [r for r in results if r.get(\"category\") == cat]\n",
        "        if cat_results:\n",
        "            cat_passed = sum(1 for r in cat_results if r[\"passed\"])\n",
        "            cat_avg = sum(r[\"overall_score\"] for r in cat_results) / len(cat_results)\n",
        "            print(f\"   â€¢ {cat}: {cat_passed}/{len(cat_results)} passed (avg: {cat_avg:.2f})\")\n",
        "    \n",
        "    print(\"\\n\" + \"-\"*70)\n",
        "    if passed == len(results):\n",
        "        print(\"ðŸŽ‰ ALL TESTS PASSED - Evaluation Successful!\")\n",
        "    elif passed >= len(results) * 0.75:\n",
        "        print(\"âœ… EVALUATION PASSED - Most tests successful\")\n",
        "    else:\n",
        "        print(\"âš ï¸ EVALUATION PARTIAL - Some tests failed\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    return results\n",
        "\n",
        "\n",
        "print(\"âœ… Evaluation framework ready\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================================\n",
        "# CELL 12: EXECUTE - Timing Comparison Demo\n",
        "# ============================================================================\n",
        "\n",
        "# Run timing comparison to demonstrate ParallelAgent speedup\n",
        "timing_results = demonstrate_parallel_speedup(\"california\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================================\n",
        "# CELL 13: EXECUTE - Agent Demonstrations\n",
        "# ============================================================================\n",
        "\n",
        "async def run_demos():\n",
        "    \"\"\"Run all agent pattern demonstrations.\"\"\"\n",
        "    await ensure_session()\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ðŸŒŠ AQUA SENTINEL - LIVE DEMONSTRATIONS\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    # Demo 1: ParallelAgent\n",
        "    print(\"\\n\" + \"-\"*70)\n",
        "    print(\"ðŸ“Š DEMO 1: ParallelAgent (SentinelAgent)\")\n",
        "    print(\"-\"*70)\n",
        "    await query_aqua_sentinel(\"What is the current water situation in California?\")\n",
        "    \n",
        "    await asyncio.sleep(2)\n",
        "    \n",
        "    # Demo 2: SequentialAgent\n",
        "    print(\"\\n\" + \"-\"*70)\n",
        "    print(\"ðŸ“Š DEMO 2: SequentialAgent (GuardianAgent)\")\n",
        "    print(\"-\"*70)\n",
        "    await query_aqua_sentinel(\"What's the forecast for India? Analyze risks and recommend actions.\")\n",
        "    \n",
        "    await asyncio.sleep(2)\n",
        "    \n",
        "    # Demo 3: LoopAgent\n",
        "    print(\"\\n\" + \"-\"*70)\n",
        "    print(\"ðŸ“Š DEMO 3: LoopAgent (ResponderAgent)\")\n",
        "    print(\"-\"*70)\n",
        "    await query_aqua_sentinel(\"Send drought alert to Kenya\")\n",
        "    \n",
        "    await asyncio.sleep(2)\n",
        "    \n",
        "    # Demo 4: Global Disasters\n",
        "    print(\"\\n\" + \"-\"*70)\n",
        "    print(\"ðŸ“Š DEMO 4: Global Disasters (Direct Tool)\")\n",
        "    print(\"-\"*70)\n",
        "    await query_aqua_sentinel(\"What disasters are happening globally?\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ðŸŽ‰ ALL DEMONSTRATIONS COMPLETE\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "\n",
        "await run_demos()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================================\n",
        "# CELL 14: EXECUTE - Full Evaluation (12 Test Cases)\n",
        "# ============================================================================\n",
        "\n",
        "eval_results = await run_evaluation(\"all\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================================\n",
        "# CELL 15: ADVANCED CONCEPTS DEMONSTRATION\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"ðŸ”§ ADVANCED ADK CONCEPTS SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# MCP Server Info\n",
        "print(\"\\nðŸ“¡ MCP (Model Context Protocol) Server:\")\n",
        "mcp_info = mcp_server.get_server_info()\n",
        "print(f\"   Server Name: {mcp_info['name']}\")\n",
        "print(f\"   Version: {mcp_info['version']}\")\n",
        "print(f\"   Tools Registered: {mcp_info['tools_count']}\")\n",
        "print(\"   Available Tools:\")\n",
        "for tool in mcp_server.list_tools():\n",
        "    print(f\"      â€¢ {tool['name']}: {tool['description'][:50]}...\")\n",
        "\n",
        "# Long-Running Operations\n",
        "print(\"\\nâ³ Long-Running Operations:\")\n",
        "# Create a sample operation\n",
        "op_id = lro_manager.create_operation(\"regional_analysis\", {\"region\": \"california\", \"depth\": \"comprehensive\"})\n",
        "lro_manager.update_progress(op_id, 50, OperationStatus.RUNNING)\n",
        "lro_manager.complete_operation(op_id, {\"status\": \"analysis_complete\", \"findings\": 5})\n",
        "op_status = lro_manager.get_status(op_id)\n",
        "print(f\"   Operation ID: {op_status['id']}\")\n",
        "print(f\"   Type: {op_status['type']}\")\n",
        "print(f\"   Status: {op_status['status']}\")\n",
        "print(f\"   Progress: {op_status['progress']}%\")\n",
        "\n",
        "# A2A Protocol\n",
        "print(\"\\nðŸ”— A2A (Agent-to-Agent) Protocol:\")\n",
        "a2a_summary = a2a_protocol.get_communication_summary()\n",
        "print(f\"   Registered Agents: {a2a_summary['registered_agents']}\")\n",
        "print(f\"   Total Messages: {a2a_summary['total_messages']}\")\n",
        "print(f\"   Message Types: {a2a_summary['message_types']}\")\n",
        "print(f\"   Agents: {', '.join(a2a_summary['agents'])}\")\n",
        "\n",
        "# Demonstrate A2A handoff\n",
        "print(\"\\n   Demonstrating A2A Task Handoff:\")\n",
        "handoff_msg = a2a_protocol.handoff_task(\n",
        "    \"HydroOrchestrator\",\n",
        "    \"WeatherAgent\",\n",
        "    {\"type\": \"weather_analysis\", \"region\": \"kenya\"},\n",
        "    {\"priority\": \"high\", \"reason\": \"drought_monitoring\"}\n",
        ")\n",
        "print(f\"   Handoff Message ID: {handoff_msg.id}\")\n",
        "print(f\"   From: {handoff_msg.sender} â†’ To: {handoff_msg.recipient}\")\n",
        "\n",
        "# Timing Comparisons\n",
        "print(\"\\nâ±ï¸ Timing Comparisons (Sequential vs Parallel):\")\n",
        "timing_data = observability.get_timing_comparison_summary()\n",
        "for t in timing_data:\n",
        "    print(f\"   Operation: {t['operation']}\")\n",
        "    print(f\"      Sequential: {t['sequential_ms']:.2f}ms\")\n",
        "    print(f\"      Parallel:   {t['parallel_ms']:.2f}ms\")\n",
        "    print(f\"      Speedup:    {t['speedup']:.2f}x\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================================\n",
        "# CELL 16: FINAL OBSERVABILITY DATA\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"ðŸ“ˆ FINAL OBSERVABILITY REPORT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Metrics Summary\n",
        "print(\"\\nðŸ“Š METRICS SUMMARY:\")\n",
        "metrics = observability.get_metrics_summary()\n",
        "for key, value in metrics.items():\n",
        "    print(f\"   {key}: {value}\")\n",
        "\n",
        "# Recent Trace\n",
        "print(\"\\nðŸ”— MOST RECENT TRACE:\")\n",
        "trace = observability.get_trace_summary()\n",
        "for key, value in trace.items():\n",
        "    if key != \"spans\":\n",
        "        print(f\"   {key}: {value}\")\n",
        "\n",
        "# Recent Logs\n",
        "print(\"\\nðŸ“ RECENT LOGS:\")\n",
        "for log in observability.logs[-5:]:\n",
        "    print(f\"   [{log['level']}] {log['message']}\")\n",
        "\n",
        "# Sent Alerts\n",
        "print(\"\\nðŸš¨ SENT ALERTS:\")\n",
        "for alert in ALERT_LOG:\n",
        "    print(f\"   {alert['alert_id']}: {alert['alert_type']} to {alert['region']} ({alert['priority']})\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"âœ… AQUA SENTINEL COMPLETE\")\n",
        "print(\"=\"*70)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ðŸš€ Deployment\n",
        "\n",
        "AQUA SENTINEL deployment was attempted to **Vertex AI Agent Engine**.\n",
        "\n",
        "### Deployment Evidence\n",
        "- **Platform**: Google Cloud - Vertex AI Agent Engine\n",
        "- **Project ID**: `aqua-sentinel-480105`\n",
        "- **Region**: `us-central1`\n",
        "- **Resource ID**: `projects/127921942048/locations/us-central1/reasoningEngines/4347921975016947712`\n",
        "- **Staging Bucket**: `gs://aqua-sentinel-staging`\n",
        "\n",
        "### Deployment Process\n",
        "1. Created GCP project with $300 free credits\n",
        "2. Enabled Vertex AI API\n",
        "3. Created Cloud Storage staging bucket\n",
        "4. Structured agent code for ADK deployment\n",
        "5. Executed `adk deploy agent_engine` command\n",
        "\n",
        "### Deployment Configuration\n",
        "```json\n",
        "{\n",
        "    \"min_instances\": 0,\n",
        "    \"max_instances\": 1,\n",
        "    \"resource_limits\": {\"cpu\": \"1\", \"memory\": \"1Gi\"}\n",
        "}\n",
        "```\n",
        "\n",
        "> **Note**: The agent was created but encountered a startup issue. See [GCP troubleshooting docs](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/troubleshooting/deploy).\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“š References\n",
        "\n",
        "- [Google ADK Documentation](https://google.github.io/adk-docs/)\n",
        "- [Vertex AI Agent Engine](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/overview)\n",
        "- [Model Context Protocol](https://modelcontextprotocol.io/)\n",
        "- [UNICEF Horn of Africa Drought](https://www.unicef.org/stories/climate-drought-horn-of-africa)\n",
        "- [#TeamWater Campaign](https://teamwater.org)\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ‘¨â€ðŸ’» Author\n",
        "\n",
        "**Jai Adithya Ram Nayani**  \n",
        "Computer Science Master's Student  \n",
        "Kaggle AI Agents Intensive 2025\n",
        "\n",
        "---"
      ]
    }
  ]
}
